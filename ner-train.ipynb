{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323f080",
   "metadata": {
    "papermill": {
     "duration": 0.010691,
     "end_time": "2023-12-02T02:57:16.307466",
     "exception": false,
     "start_time": "2023-12-02T02:57:16.296775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0345ea44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:16.329820Z",
     "iopub.status.busy": "2023-12-02T02:57:16.329416Z",
     "iopub.status.idle": "2023-12-02T02:57:21.271770Z",
     "shell.execute_reply": "2023-12-02T02:57:21.270799Z"
    },
    "papermill": {
     "duration": 4.956248,
     "end_time": "2023-12-02T02:57:21.274137",
     "exception": false,
     "start_time": "2023-12-02T02:57:16.317889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import sys\n",
    "import math\n",
    "from math import ceil, floor\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f11a2",
   "metadata": {
    "papermill": {
     "duration": 0.009947,
     "end_time": "2023-12-02T02:57:21.294562",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.284615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334755aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.317107Z",
     "iopub.status.busy": "2023-12-02T02:57:21.316250Z",
     "iopub.status.idle": "2023-12-02T02:57:21.330321Z",
     "shell.execute_reply": "2023-12-02T02:57:21.329545Z"
    },
    "papermill": {
     "duration": 0.027506,
     "end_time": "2023-12-02T02:57:21.332206",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.304700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info(t, name=''):\n",
    "    print(name, '|', t.type(), '|', t.shape)\n",
    "\n",
    "\n",
    "def flatten(list_in):\n",
    "    return [list(itertools.chain.from_iterable(list_item)) for list_item in list_in]\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_words_num(word_sequences):\n",
    "    return sum(len(word_seq) for word_seq in word_sequences)\n",
    "\n",
    "\n",
    "def get_datetime_str():\n",
    "    d = datetime.datetime.now()\n",
    "    return '%02d_%02d_%02d_%02d-%02d_%02d' % (d.year, d.month, d.day, d.hour, d.minute, d.second)\n",
    "\n",
    "\n",
    "def get_sequences_by_indices(sequences, indices):\n",
    "    return [sequences[i] for i in indices]\n",
    "\n",
    "\n",
    "def argsort(seq):\n",
    "    return sorted(range(len(seq)), key=seq.__getitem__)\n",
    "\n",
    "\n",
    "def argsort_sequences_by_lens(list_in):\n",
    "    data_num = len(list_in)\n",
    "    sort_indices = argsort([-len(item) for item in list_in])\n",
    "    reverse_sort_indices = [-1 for _ in range(data_num)]\n",
    "    for i in range(data_num):\n",
    "        reverse_sort_indices[sort_indices[i]] = i\n",
    "    return sort_indices, reverse_sort_indices\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_score, _ = torch.max(x, -1)\n",
    "    max_score_broadcast = max_score.unsqueeze(-1).expand_as(x)\n",
    "    return max_score + torch.log(torch.sum(torch.exp(x - max_score_broadcast), -1))\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def get_input_arguments():\n",
    "    return 'python3 main.py ' + ' '.join([arg for arg in sys.argv[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c19a4",
   "metadata": {
    "papermill": {
     "duration": 0.010032,
     "end_time": "2023-12-02T02:57:21.352571",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.342539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4299307f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.374044Z",
     "iopub.status.busy": "2023-12-02T02:57:21.373763Z",
     "iopub.status.idle": "2023-12-02T02:57:21.383452Z",
     "shell.execute_reply": "2023-12-02T02:57:21.382627Z"
    },
    "papermill": {
     "duration": 0.022611,
     "end_time": "2023-12-02T02:57:21.385260",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.362649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataIONCBI():\n",
    "    \"\"\"\n",
    "    DataIONCBI is an input/output data wrapper for NCBI dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_name='ncbi_disease', train_no=None, dev_no=None, test_no=None):\n",
    "        self.NCBIDataset = load_dataset(dataset_name)\n",
    "        self.train_no = train_no\n",
    "        self.dev_no = dev_no\n",
    "        self.test_no = test_no\n",
    "    \n",
    "    def read_train_dev_test(self, args):\n",
    "        word_sequences_train, tag_sequences_train = self.read_data('train', verbose=args.verbose, exp_no=self.train_no)\n",
    "        word_sequences_dev, tag_sequences_dev = self.read_data('validation', verbose=args.verbose, exp_no=self.dev_no)\n",
    "        word_sequences_test, tag_sequences_test = self.read_data('test', verbose=args.verbose, exp_no=self.test_no)\n",
    "        return word_sequences_train, tag_sequences_train, word_sequences_dev, tag_sequences_dev, word_sequences_test, tag_sequences_test\n",
    "\n",
    "    def read_data(self, mode, verbose=True, exp_no=None):\n",
    "        dataset = self.NCBIDataset[mode]\n",
    "        word_sequences = list()\n",
    "        tag_sequences = list()\n",
    "        for i, row in enumerate(dataset):\n",
    "            if len(row['tokens']) == 0 or len(row['ner_tags']) == 0:\n",
    "                continue\n",
    "            word_sequences.append(row['tokens'])\n",
    "            tag_sequences.append(row['ner_tags'])\n",
    "            if exp_no:\n",
    "                if i>= exp_no-1:\n",
    "                    break\n",
    "            \n",
    "        if verbose:\n",
    "            print('Loading from %s: %d samples, %d words.' % (mode, len(word_sequences), get_words_num(word_sequences)))\n",
    "        return word_sequences, tag_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd8295",
   "metadata": {
    "papermill": {
     "duration": 0.010239,
     "end_time": "2023-12-02T02:57:21.405779",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.395540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c24ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.428064Z",
     "iopub.status.busy": "2023-12-02T02:57:21.427785Z",
     "iopub.status.idle": "2023-12-02T02:57:21.449513Z",
     "shell.execute_reply": "2023-12-02T02:57:21.448662Z"
    },
    "papermill": {
     "duration": 0.035064,
     "end_time": "2023-12-02T02:57:21.451311",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.416247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetsBank():\n",
    "    \"\"\"DatasetsBank provides storing the train/dev/test data subsets and sampling batches from the train dataset.\"\"\"\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.unique_words_list = list()\n",
    "\n",
    "    def __add_to_unique_words_list(self, word_sequences):\n",
    "        for word_seq in word_sequences:\n",
    "            for word in word_seq:\n",
    "                if word not in self.unique_words_list:\n",
    "                    self.unique_words_list.append(word)\n",
    "        if self.verbose:\n",
    "            print('DatasetsBank: len(unique_words_list) = %d unique words.' % (len(self.unique_words_list)))\n",
    "\n",
    "    def add_train_sequences(self, word_sequences_train, tag_sequences_train):\n",
    "        self.train_data_num = len(word_sequences_train)\n",
    "        self.word_sequences_train = word_sequences_train\n",
    "        self.tag_sequences_train = tag_sequences_train\n",
    "        self.__add_to_unique_words_list(word_sequences_train)\n",
    "\n",
    "    def add_dev_sequences(self, word_sequences_dev, tag_sequences_dev):\n",
    "        self.word_sequences_dev = word_sequences_dev\n",
    "        self.tag_sequences_dev = tag_sequences_dev\n",
    "        self.__add_to_unique_words_list(word_sequences_dev)\n",
    "\n",
    "    def add_test_sequences(self, word_sequences_test, tag_sequences_test):\n",
    "        self.word_sequences_test = word_sequences_test\n",
    "        self.tag_sequences_test = tag_sequences_test\n",
    "        self.__add_to_unique_words_list(word_sequences_test)\n",
    "\n",
    "    def __get_train_batch(self, batch_indices):\n",
    "        word_sequences_train_batch = [self.word_sequences_train[i] for i in batch_indices]\n",
    "        tag_sequences_train_batch = [self.tag_sequences_train[i] for i in batch_indices]\n",
    "        return word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "    def get_train_batches(self, batch_size):\n",
    "        random_indices = np.random.permutation(np.arange(self.train_data_num))\n",
    "        for k in range(self.train_data_num // batch_size): # oh yes, we drop the last batch\n",
    "            batch_indices = random_indices[k:k + batch_size].tolist()\n",
    "            word_sequences_train_batch, tag_sequences_train_batch = self.__get_train_batch(batch_indices)\n",
    "            yield word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "\n",
    "class DatasetsBankSorted():\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.unique_words_list = list()\n",
    "\n",
    "    def __add_to_unique_words_list(self, word_sequences):\n",
    "        for word_seq in word_sequences:\n",
    "            for word in word_seq:\n",
    "                if word not in self.unique_words_list:\n",
    "                    self.unique_words_list.append(word)\n",
    "        if self.verbose:\n",
    "            print('DatasetsBank: len(unique_words_list) = %d unique words.' % (len(self.unique_words_list)))\n",
    "\n",
    "    def add_train_sequences(self, word_sequences_train, tag_sequences_train):\n",
    "        sort_indices, _ = argsort_sequences_by_lens(word_sequences_train)\n",
    "        self.word_sequences_train = get_sequences_by_indices(word_sequences_train, sort_indices)\n",
    "        self.tag_sequences_train = get_sequences_by_indices(tag_sequences_train, sort_indices)\n",
    "        self.train_data_num = len(word_sequences_train)\n",
    "        self.__add_to_unique_words_list(word_sequences_train)\n",
    "\n",
    "    def add_dev_sequences(self, word_sequences_dev, tag_sequences_dev):\n",
    "        self.word_sequences_dev = word_sequences_dev\n",
    "        self.tag_sequences_dev = tag_sequences_dev\n",
    "        self.__add_to_unique_words_list(word_sequences_dev)\n",
    "\n",
    "    def add_test_sequences(self, word_sequences_test, tag_sequences_test):\n",
    "        self.word_sequences_test = word_sequences_test\n",
    "        self.tag_sequences_test = tag_sequences_test\n",
    "        self.__add_to_unique_words_list(word_sequences_test)\n",
    "\n",
    "    def __get_train_batch(self, batch_size, batch_no, rand_seed=0):\n",
    "        i = batch_no * batch_size + rand_seed\n",
    "        j = min((batch_no + 1) * batch_size, self.train_data_num + 1) + rand_seed\n",
    "        return self.word_sequences_train[i:j], self.tag_sequences_train[i:j]\n",
    "\n",
    "    def get_train_batches(self, batch_size):\n",
    "        rand_seed = randint(0, batch_size - 1)\n",
    "        batch_num = self.train_data_num // batch_size\n",
    "        random_indices = np.random.permutation(np.arange(batch_num - 1)).tolist()\n",
    "        for k in random_indices:\n",
    "            yield self.__get_train_batch(batch_size, batch_no=k, rand_seed=rand_seed)\n",
    "\n",
    "    def __get_train_batch_regularized(self, batch_size, rand_batch_size, batch_no):\n",
    "        i = batch_no * batch_size\n",
    "        j = min((batch_no + 1) * batch_size, self.train_data_num + 1)\n",
    "        word_sequences_train_batch = self.word_sequences_train[i:j]\n",
    "        tag_sequences_train_batch = self.tag_sequences_train[i:j]\n",
    "        for k in range(rand_batch_size):\n",
    "            r = randint(0, self.train_data_num)\n",
    "            word_sequences_train_batch.append(self.word_sequences_train[r])\n",
    "            tag_sequences_train_batch.append(self.tag_sequences_train[r])\n",
    "        return word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "    def get_train_batches_regularized(self, batch_size):\n",
    "        batch_num = self.train_data_num // batch_size\n",
    "        random_indices = np.random.permutation(np.arange(batch_num)).tolist()\n",
    "        for k in random_indices:\n",
    "            yield self.__get_train_batch_regularized(batch_size-2, rand_batch_size=2, batch_no=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486ca0c",
   "metadata": {
    "papermill": {
     "duration": 0.010046,
     "end_time": "2023-12-02T02:57:21.471590",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.461544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sequence Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc1ea3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.493712Z",
     "iopub.status.busy": "2023-12-02T02:57:21.493078Z",
     "iopub.status.idle": "2023-12-02T02:57:21.513452Z",
     "shell.execute_reply": "2023-12-02T02:57:21.512272Z"
    },
    "papermill": {
     "duration": 0.034507,
     "end_time": "2023-12-02T02:57:21.516370",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.481863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBase():\n",
    "    \"\"\"\n",
    "    SeqIndexerBase is a base abstract class for sequence indexers. It converts list of lists of string items\n",
    "    to the list of lists of integer indices and back. Items could be either words, tags or characters.\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu=-1, check_for_lowercase=True, zero_digits=False, pad='<pad>', unk='<unk>',\n",
    "                 load_embeddings=False, embeddings_dim=0, verbose=False):\n",
    "        self.gpu = gpu\n",
    "        self.check_for_lowercase = check_for_lowercase\n",
    "        self.zero_digits = zero_digits\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.load_embeddings = load_embeddings\n",
    "        self.embeddings_dim = embeddings_dim\n",
    "        self.verbose = verbose\n",
    "        self.out_of_vocabulary_list = list()\n",
    "        self.item2idx_dict = dict()\n",
    "        self.idx2item_dict = dict()\n",
    "        if load_embeddings:\n",
    "            self.embeddings_loaded = False\n",
    "            self.embedding_vectors_list = list()\n",
    "        if pad is not None:\n",
    "            self.pad_idx = self.add_item(pad)\n",
    "            if load_embeddings:\n",
    "                self.add_emb_vector(self.generate_zero_emb_vector())\n",
    "        if unk is not None:\n",
    "            self.unk_idx = self.add_item(unk)\n",
    "            if load_embeddings:\n",
    "                self.add_emb_vector(self.generate_random_emb_vector())\n",
    "\n",
    "    def get_items_list(self):\n",
    "        return list(self.item2idx_dict.keys())\n",
    "\n",
    "    def get_items_count(self):\n",
    "        return len(self.get_items_list())\n",
    "\n",
    "    def item_exists(self, item):\n",
    "        return item in self.item2idx_dict.keys()\n",
    "\n",
    "    def add_item(self, item):\n",
    "        idx = len(self.get_items_list())\n",
    "        self.item2idx_dict[item] = idx\n",
    "        self.idx2item_dict[idx] = item\n",
    "        return idx\n",
    "\n",
    "    def get_class_num(self):\n",
    "        if self.pad is not None and self.unk is not None:\n",
    "            return self.get_items_count() - 2\n",
    "        if self.pad is not None or self.unk is not None:\n",
    "            return self.get_items_count() - 1\n",
    "        return self.get_items_count()\n",
    "\n",
    "    def items2idx(self, item_sequences):\n",
    "        idx_sequences = []\n",
    "        for item_seq in item_sequences:\n",
    "            idx_seq = list()\n",
    "            for item in item_seq:\n",
    "                if item in self.item2idx_dict:\n",
    "                    idx_seq.append(self.item2idx_dict[item])\n",
    "                else:\n",
    "                    if self.unk is not None:\n",
    "                        idx_seq.append(self.item2idx_dict[self.unk])\n",
    "                    else:\n",
    "                        idx_seq.append(self.item2idx_dict[self.pad])\n",
    "            idx_sequences.append(idx_seq)\n",
    "        return idx_sequences\n",
    "\n",
    "    def idx2items(self, idx_sequences):\n",
    "        item_sequences = []\n",
    "        for idx_seq in idx_sequences:\n",
    "            item_seq = [self.idx2item_dict[idx] for idx in idx_seq]\n",
    "            item_sequences.append(item_seq)\n",
    "        return item_sequences\n",
    "\n",
    "    def items2tensor(self, item_sequences, align='left', word_len=-1):\n",
    "        idx = self.items2idx(item_sequences)\n",
    "        return self.idx2tensor(idx, align, word_len)\n",
    "\n",
    "    def idx2tensor(self, idx_sequences, align='left', word_len=-1):\n",
    "        batch_size = len(idx_sequences)\n",
    "        if word_len == -1:\n",
    "            word_len = max([len(idx_seq) for idx_seq in idx_sequences])\n",
    "        tensor = torch.zeros(batch_size, word_len, dtype=torch.long)\n",
    "        for k, idx_seq in enumerate(idx_sequences):\n",
    "            curr_seq_len = len(idx_seq)\n",
    "            if curr_seq_len > word_len:\n",
    "                idx_seq = [idx_seq[i] for i in range(word_len)]\n",
    "                curr_seq_len = word_len\n",
    "            if align == 'left':\n",
    "                tensor[k, :curr_seq_len] = torch.LongTensor(np.asarray(idx_seq))\n",
    "            elif align == 'center':\n",
    "                start_idx = (word_len - curr_seq_len) // 2\n",
    "                tensor[k, start_idx:start_idx+curr_seq_len] = torch.LongTensor(np.asarray(idx_seq))\n",
    "            else:\n",
    "                raise ValueError('Unknown align string.')\n",
    "        if self.gpu >= 0:\n",
    "            tensor = tensor.cuda(device=self.gpu)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d6bb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.542970Z",
     "iopub.status.busy": "2023-12-02T02:57:21.542683Z",
     "iopub.status.idle": "2023-12-02T02:57:21.553500Z",
     "shell.execute_reply": "2023-12-02T02:57:21.552790Z"
    },
    "papermill": {
     "duration": 0.02635,
     "end_time": "2023-12-02T02:57:21.555452",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.529102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBaseEmbeddings(SeqIndexerBase):\n",
    "    \"\"\"\n",
    "    SeqIndexerBaseEmbeddings is a basic abstract sequence indexers class that implements work qith embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu, check_for_lowercase, zero_digits, pad, unk, load_embeddings, embeddings_dim, verbose):\n",
    "        SeqIndexerBase.__init__(self, gpu, check_for_lowercase, zero_digits, pad, unk, load_embeddings, embeddings_dim,\n",
    "                                verbose)\n",
    "    @staticmethod\n",
    "    def load_embeddings_from_file(emb_fn, emb_delimiter, verbose=True):\n",
    "        for k, line in enumerate(open(emb_fn, 'r')):\n",
    "            values = line.split(emb_delimiter)\n",
    "            if len(values) < 5:\n",
    "                continue\n",
    "            word = values[0]\n",
    "            emb_vector = list(map(lambda t: float(t), filter(lambda n: n and not n.isspace(), values[1:])))\n",
    "            if verbose:\n",
    "                if k % 100000 == 0:\n",
    "                    print('Reading embeddings file %s, line = %d' % (emb_fn, k))\n",
    "            yield word, emb_vector\n",
    "\n",
    "    def generate_zero_emb_vector(self):\n",
    "        if self.embeddings_dim == 0:\n",
    "            raise ValueError('embeddings_dim is not known.')\n",
    "        return [0 for _ in range(self.embeddings_dim)]\n",
    "\n",
    "    def generate_random_emb_vector(self):\n",
    "        if self.embeddings_dim == 0:\n",
    "            raise ValueError('embeddings_dim is not known.')\n",
    "        return np.random.uniform(-np.sqrt(3.0 / self.embeddings_dim), np.sqrt(3.0 / self.embeddings_dim),\n",
    "                                 self.embeddings_dim).tolist()\n",
    "\n",
    "    def add_emb_vector(self, emb_vector):\n",
    "        self.embedding_vectors_list.append(emb_vector)\n",
    "\n",
    "    def get_loaded_embeddings_tensor(self):\n",
    "        return torch.FloatTensor(np.asarray(self.embedding_vectors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45744ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.577779Z",
     "iopub.status.busy": "2023-12-02T02:57:21.577497Z",
     "iopub.status.idle": "2023-12-02T02:57:21.599136Z",
     "shell.execute_reply": "2023-12-02T02:57:21.598388Z"
    },
    "papermill": {
     "duration": 0.034911,
     "end_time": "2023-12-02T02:57:21.601043",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.566132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerWord(SeqIndexerBaseEmbeddings):\n",
    "    \"\"\"SeqIndexerWord converts list of lists of words as strings to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu=-1, check_for_lowercase=True, embeddings_dim=0, verbose=True):\n",
    "        SeqIndexerBaseEmbeddings.__init__(self, gpu=gpu, check_for_lowercase=check_for_lowercase, zero_digits=True,\n",
    "                                          pad='<pad>', unk='<unk>', load_embeddings=True, embeddings_dim=embeddings_dim,\n",
    "                                          verbose=verbose)\n",
    "        self.original_words_num = 0\n",
    "        self.lowercase_words_num = 0\n",
    "        self.zero_digits_replaced_num = 0\n",
    "        self.zero_digits_replaced_lowercase_num = 0\n",
    "        self.capitalize_word_num = 0\n",
    "        self.uppercase_word_num = 0\n",
    "\n",
    "    def load_items_from_embeddings_file_and_unique_words_list(self, emb_fn, emb_delimiter, emb_load_all,\n",
    "                                                              unique_words_list):\n",
    "        embeddings_full_list = SeqIndexerBaseEmbeddings.load_embeddings_from_file(emb_fn,emb_delimiter,verbose=True)\n",
    "        # Get the full list of available case-sensitive words from text file with pretrained embeddings\n",
    "        \n",
    "        embeddings_words_list = [emb_word for emb_word, _ in embeddings_full_list]\n",
    "        # Create reverse mapping word from the embeddings file -> list of unique words from the dataset\n",
    "        emb_word_dict2unique_word_list = dict()\n",
    "        out_of_vocabulary_words_list = list()\n",
    "        for unique_word in unique_words_list:\n",
    "            emb_word = self.get_embeddings_word(unique_word, embeddings_words_list)\n",
    "            if emb_word is None:\n",
    "                out_of_vocabulary_words_list.append(unique_word)\n",
    "            else:\n",
    "                if emb_word not in emb_word_dict2unique_word_list:\n",
    "                    emb_word_dict2unique_word_list[emb_word] = [unique_word]\n",
    "                else:\n",
    "                    emb_word_dict2unique_word_list[emb_word].append(unique_word)\n",
    "        # Add pretrained embeddings for unique_words\n",
    "        for emb_word, emb_vec in embeddings_full_list:\n",
    "            if emb_word in emb_word_dict2unique_word_list:\n",
    "                for unique_word in emb_word_dict2unique_word_list[emb_word]:\n",
    "                    self.add_word_emb_vec(unique_word, emb_vec)\n",
    "        if self.verbose:\n",
    "            print('\\nload_vocabulary_from_embeddings_file_and_unique_words_list:')\n",
    "            print('    First 50 OOV words:')\n",
    "            for i, oov_word in enumerate(out_of_vocabulary_words_list):\n",
    "                print('        out_of_vocabulary_words_list[%d] = %s' % (i, oov_word))\n",
    "                if i > 49:\n",
    "                    break\n",
    "            print(' -- len(out_of_vocabulary_words_list) = %d' % len(out_of_vocabulary_words_list))\n",
    "            print(' -- original_words_num = %d' % self.original_words_num)\n",
    "            print(' -- lowercase_words_num = %d' % self.lowercase_words_num)\n",
    "            print(' -- zero_digits_replaced_num = %d' % self.zero_digits_replaced_num)\n",
    "            print(' -- zero_digits_replaced_lowercase_num = %d' % self.zero_digits_replaced_lowercase_num)\n",
    "        # Load all embeddings\n",
    "        if emb_load_all:\n",
    "            loaded_words_list = self.get_items_list()\n",
    "            load_all_words_num_before = len(loaded_words_list)\n",
    "            load_all_words_lower_num = 0\n",
    "            load_all_words_upper_num = 0\n",
    "            load_all_words_capitalize_num = 0\n",
    "            for emb_word, emb_vec in embeddings_full_list:\n",
    "                if emb_word in loaded_words_list:\n",
    "                    continue\n",
    "                if emb_word.lower() not in loaded_words_list and emb_word.lower() not in embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.lower(), emb_vec)\n",
    "                    load_all_words_lower_num += 1\n",
    "                if emb_word.upper() not in loaded_words_list and emb_word.upper() not in embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.upper(), emb_vec)\n",
    "                    load_all_words_upper_num += 1\n",
    "                if emb_word.capitalize() not in loaded_words_list and emb_word.capitalize() not in \\\n",
    "                        embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.capitalize(), emb_vec)\n",
    "                    load_all_words_capitalize_num += 1\n",
    "                self.add_item(emb_word)\n",
    "                self.add_emb_vector(emb_vec)\n",
    "            load_all_words_num_after = len(self.get_items_list())\n",
    "            if self.verbose:\n",
    "                print(' ++ load_all_words_num_before = %d ' % load_all_words_num_before)\n",
    "                print(' ++ load_all_words_lower_num = %d ' % load_all_words_lower_num)\n",
    "                print(' ++ load_all_words_num_after = %d ' % load_all_words_num_after)\n",
    "\n",
    "    def get_embeddings_word(self, word, embeddings_word_list):\n",
    "        if word in embeddings_word_list:\n",
    "            self.original_words_num += 1\n",
    "            return word\n",
    "        elif self.check_for_lowercase and word.lower() in embeddings_word_list:\n",
    "            self.lowercase_words_num += 1\n",
    "            return word.lower()\n",
    "        elif self.zero_digits and re.sub('\\d', '0', word) in embeddings_word_list:\n",
    "            self.zero_digits_replaced_num += 1\n",
    "            return re.sub('\\d', '0', word)\n",
    "        elif self.check_for_lowercase and self.zero_digits and re.sub('\\d', '0', word.lower()) in embeddings_word_list:\n",
    "            self.zero_digits_replaced_lowercase_num += 1\n",
    "            return re.sub('\\d', '0', word.lower())\n",
    "        return None\n",
    "\n",
    "    def add_word_emb_vec(self, word, emb_vec):\n",
    "        self.add_item(word)\n",
    "        self.add_emb_vector(emb_vec)\n",
    "\n",
    "    def get_unique_characters_list(self, verbose=False, init_by_printable_characters=True):\n",
    "        if init_by_printable_characters:\n",
    "            unique_characters_set = set(string.printable)\n",
    "        else:\n",
    "            unique_characters_set = set()\n",
    "        if verbose:\n",
    "            cnt = 0\n",
    "        for n, word in enumerate(self.get_items_list()):\n",
    "            len_delta = len(unique_characters_set)\n",
    "            unique_characters_set = unique_characters_set.union(set(word))\n",
    "            if verbose and len(unique_characters_set) > len_delta:\n",
    "                cnt += 1\n",
    "                print('n = %d/%d (%d) %s' % (n, len(self.get_items_list), cnt, word))\n",
    "        return list(unique_characters_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bcd29e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.622915Z",
     "iopub.status.busy": "2023-12-02T02:57:21.622642Z",
     "iopub.status.idle": "2023-12-02T02:57:21.629468Z",
     "shell.execute_reply": "2023-12-02T02:57:21.628613Z"
    },
    "papermill": {
     "duration": 0.019881,
     "end_time": "2023-12-02T02:57:21.631410",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.611529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerTag(SeqIndexerBase):\n",
    "    \"\"\"SeqIndexerTag converts list of lists of string tags to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        SeqIndexerBase.__init__(self, gpu=gpu, check_for_lowercase=False, zero_digits=False,\n",
    "                                      pad='<pad>', unk=None, load_embeddings=False, verbose=True)\n",
    "\n",
    "    def add_tag(self, tag):\n",
    "        if not self.item_exists(tag):\n",
    "            self.add_item(tag)\n",
    "\n",
    "    def load_items_from_tag_sequences(self, tag_sequences):\n",
    "        assert self.load_embeddings == False\n",
    "        for tag_seq in tag_sequences:\n",
    "            for tag in tag_seq:\n",
    "                self.add_tag(tag)\n",
    "        if self.verbose:\n",
    "            print('\\nload_vocabulary_from_tag_sequences:')\n",
    "            print(' -- class_num = %d' % self.get_class_num())\n",
    "            print(' --', self.item2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1400e03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.653529Z",
     "iopub.status.busy": "2023-12-02T02:57:21.652979Z",
     "iopub.status.idle": "2023-12-02T02:57:21.659963Z",
     "shell.execute_reply": "2023-12-02T02:57:21.659307Z"
    },
    "papermill": {
     "duration": 0.020038,
     "end_time": "2023-12-02T02:57:21.661836",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.641798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBaseChar(SeqIndexerBaseEmbeddings):\n",
    "    \"\"\"SeqIndexerBaseChar converts list of lists of characters to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        SeqIndexerBaseEmbeddings.__init__(self, gpu=gpu, check_for_lowercase=False, zero_digits=False, pad='<pad>',\n",
    "                                          unk='<unk>', load_embeddings=False, embeddings_dim=0, verbose=True)\n",
    "\n",
    "    def add_char(self, c):\n",
    "        if not self.item_exists(c):\n",
    "            self.add_item(c)\n",
    "\n",
    "    def get_char_tensor(self, curr_char_seq, word_len):\n",
    "        return SeqIndexerBaseEmbeddings.items2tensor(self, curr_char_seq, align='center', word_len=word_len)  # curr_seq_len x word_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf51bf",
   "metadata": {
    "papermill": {
     "duration": 0.010149,
     "end_time": "2023-12-02T02:57:21.682460",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.672311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c69698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.704689Z",
     "iopub.status.busy": "2023-12-02T02:57:21.704216Z",
     "iopub.status.idle": "2023-12-02T02:57:21.711428Z",
     "shell.execute_reply": "2023-12-02T02:57:21.710589Z"
    },
    "papermill": {
     "duration": 0.020421,
     "end_time": "2023-12-02T02:57:21.713300",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.692879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBase(nn.Module):\n",
    "    \"\"\"Abstract base class for all type of layers.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        super(LayerBase, self).__init__()\n",
    "        self.gpu = gpu\n",
    "\n",
    "    def tensor_ensure_gpu(self, tensor):\n",
    "        if self.is_cuda():\n",
    "            return tensor.cuda(device=self.gpu)\n",
    "        else:\n",
    "            return tensor.cpu()\n",
    "\n",
    "    def apply_mask(self, input_tensor, mask_tensor):\n",
    "        input_tensor = self.tensor_ensure_gpu(input_tensor)\n",
    "        mask_tensor = self.tensor_ensure_gpu(mask_tensor)\n",
    "        return input_tensor*mask_tensor.unsqueeze(-1).expand_as(input_tensor)\n",
    "\n",
    "    def get_seq_len_list_from_mask_tensor(self, mask_tensor):\n",
    "        batch_size = mask_tensor.shape[0]\n",
    "        return [int(mask_tensor[k].sum().item()) for k in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80b7cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.735349Z",
     "iopub.status.busy": "2023-12-02T02:57:21.735104Z",
     "iopub.status.idle": "2023-12-02T02:57:21.744949Z",
     "shell.execute_reply": "2023-12-02T02:57:21.744293Z"
    },
    "papermill": {
     "duration": 0.022962,
     "end_time": "2023-12-02T02:57:21.746814",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.723852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBiRNNBase(LayerBase):\n",
    "    \"\"\"LayerBiRNNBase is abstract base class for all bidirectional recurrent layers.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, gpu):\n",
    "        super(LayerBiRNNBase, self).__init__(gpu)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = hidden_dim * 2\n",
    "\n",
    "    def sort_by_seq_len_list(self, seq_len_list):\n",
    "        data_num = len(seq_len_list)\n",
    "        sort_indices = sorted(range(len(seq_len_list)), key=seq_len_list.__getitem__, reverse=True)\n",
    "        reverse_sort_indices = [-1 for _ in range(data_num)]\n",
    "        for i in range(data_num):\n",
    "            reverse_sort_indices[sort_indices[i]] = i\n",
    "        sort_index = self.tensor_ensure_gpu(torch.tensor(sort_indices, dtype=torch.long))\n",
    "        reverse_sort_index = self.tensor_ensure_gpu(torch.tensor(reverse_sort_indices, dtype=torch.long))\n",
    "        return sorted(seq_len_list, reverse=True), sort_index, reverse_sort_index\n",
    "\n",
    "    def pack(self, input_tensor, mask_tensor):\n",
    "        seq_len_list = self.get_seq_len_list_from_mask_tensor(mask_tensor)\n",
    "        sorted_seq_len_list, sort_index, reverse_sort_index = self.sort_by_seq_len_list(seq_len_list)\n",
    "        input_tensor_sorted = torch.index_select(input_tensor, dim=0, index=sort_index)\n",
    "        return pack_padded_sequence(input_tensor_sorted, lengths=sorted_seq_len_list, batch_first=True), \\\n",
    "               reverse_sort_index\n",
    "\n",
    "    def unpack(self, output_packed, max_seq_len, reverse_sort_index):\n",
    "        output_tensor_sorted, _ = pad_packed_sequence(output_packed, batch_first=True, total_length=max_seq_len)\n",
    "        output_tensor = torch.index_select(output_tensor_sorted, dim=0, index=reverse_sort_index)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3d591e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.769352Z",
     "iopub.status.busy": "2023-12-02T02:57:21.769093Z",
     "iopub.status.idle": "2023-12-02T02:57:21.776068Z",
     "shell.execute_reply": "2023-12-02T02:57:21.775265Z"
    },
    "papermill": {
     "duration": 0.020434,
     "end_time": "2023-12-02T02:57:21.777957",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.757523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerWordEmbeddings(LayerBase):\n",
    "    \"\"\"LayerWordEmbeddings implements word embeddings.\"\"\"\n",
    "    def __init__(self, word_seq_indexer, gpu, freeze_word_embeddings=False, pad_idx=0):\n",
    "        super(LayerWordEmbeddings, self).__init__(gpu)\n",
    "        embeddings_tensor = word_seq_indexer.get_loaded_embeddings_tensor()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=embeddings_tensor, freeze=freeze_word_embeddings)\n",
    "        self.embeddings.padding_idx = pad_idx\n",
    "        self.word_seq_indexer = word_seq_indexer\n",
    "        self.freeze_embeddings = freeze_word_embeddings\n",
    "        self.embeddings_num = embeddings_tensor.shape[0]\n",
    "        self.embeddings_dim = embeddings_tensor.shape[1]\n",
    "        self.output_dim = self.embeddings_dim\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.embeddings.weight.is_cuda\n",
    "\n",
    "    def forward(self, word_sequences):\n",
    "        input_tensor = self.tensor_ensure_gpu(self.word_seq_indexer.items2tensor(word_sequences)) # shape: batch_size x max_seq_len\n",
    "        word_embeddings_feature = self.embeddings(input_tensor) # shape: batch_size x max_seq_len x output_dim\n",
    "        return word_embeddings_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "029301ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.800612Z",
     "iopub.status.busy": "2023-12-02T02:57:21.799965Z",
     "iopub.status.idle": "2023-12-02T02:57:21.809857Z",
     "shell.execute_reply": "2023-12-02T02:57:21.809053Z"
    },
    "papermill": {
     "duration": 0.023123,
     "end_time": "2023-12-02T02:57:21.811677",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.788554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharEmbeddings(LayerBase):\n",
    "    \"\"\"LayerCharEmbeddings implements character-level embeddings.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, freeze_char_embeddings=False, word_len=20, unique_characters_list=None):\n",
    "        super(LayerCharEmbeddings, self).__init__(gpu)\n",
    "        self.gpu = gpu\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.freeze_char_embeddings = freeze_char_embeddings\n",
    "        self.word_len = word_len # standard len to pad\n",
    "        # Init character sequences indexer\n",
    "        self.char_seq_indexer = SeqIndexerBaseChar(gpu=gpu)\n",
    "        if unique_characters_list is None:\n",
    "            unique_characters_list = list(string.printable)\n",
    "        for c in unique_characters_list:\n",
    "            self.char_seq_indexer.add_char(c)\n",
    "        # Init character embedding\n",
    "        self.embeddings = nn.Embedding(num_embeddings=self.char_seq_indexer.get_items_count(),\n",
    "                                       embedding_dim=char_embeddings_dim,\n",
    "                                       padding_idx=0)\n",
    "        # nn.init.uniform_(self.embeddings.weight, -0.5, 0.5) # Option: Ma, 2016\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.embeddings.weight.is_cuda\n",
    "\n",
    "    def forward(self, word_sequences):\n",
    "        batch_num = len(word_sequences)\n",
    "        max_seq_len = max([len(word_seq) for word_seq in word_sequences])\n",
    "        char_sequences = [[[c for c in word] for word in word_seq] for word_seq in word_sequences]\n",
    "        input_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.word_len, dtype=torch.long))\n",
    "        for n, curr_char_seq in enumerate(char_sequences):\n",
    "            curr_seq_len = len(curr_char_seq)\n",
    "            curr_char_seq_tensor = self.char_seq_indexer.get_char_tensor(curr_char_seq, self.word_len) # curr_seq_len x word_len\n",
    "            input_tensor[n, :curr_seq_len, :] = curr_char_seq_tensor\n",
    "        char_embeddings_feature = self.embeddings(input_tensor)\n",
    "        return char_embeddings_feature.permute(0, 1, 3, 2) # shape: batch_num x max_seq_len x char_embeddings_dim x word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738771d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.837046Z",
     "iopub.status.busy": "2023-12-02T02:57:21.836312Z",
     "iopub.status.idle": "2023-12-02T02:57:21.851856Z",
     "shell.execute_reply": "2023-12-02T02:57:21.850831Z"
    },
    "papermill": {
     "duration": 0.030835,
     "end_time": "2023-12-02T02:57:21.853838",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.823003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharCNN(LayerBase):\n",
    "    \"\"\"LayerCharCNN implements character-level convolutional 1D layer.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, filter_num, char_window_size, word_len):\n",
    "        super(LayerCharCNN, self).__init__(gpu)\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.char_cnn_filter_num = filter_num\n",
    "        self.char_window_size = char_window_size\n",
    "        self.word_len = word_len\n",
    "        self.output_dim = char_embeddings_dim * filter_num\n",
    "        self.conv1 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[0],\n",
    "                               groups=char_embeddings_dim,\n",
    "                               padding=\"same\")\n",
    "        self.conv2 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[1],\n",
    "                               groups=char_embeddings_dim, \n",
    "                               padding=\"same\")\n",
    "        self.conv3 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[2],\n",
    "                               groups=char_embeddings_dim, \n",
    "                               padding=\"same\")\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.conv1.weight.is_cuda\n",
    "\n",
    "    def forward(self, char_embeddings_feature): # batch_num x max_seq_len x char_embeddings_dim x word_len\n",
    "        batch_num, max_seq_len, char_embeddings_dim, word_len = char_embeddings_feature.shape\n",
    "        max_pooling_out = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.output_dim, dtype=torch.float))\n",
    "        for k in range(max_seq_len):\n",
    "            conv_out1 = self.conv1(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out2 = self.conv2(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out3 = self.conv3(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out = torch.cat((conv_out1, conv_out2, conv_out3), dim=1)\n",
    "            max_pooling_out[:, k, :], _ = torch.max(conv_out, dim=2)\n",
    "        return max_pooling_out # shape: batch_num x max_seq_len x filter_num*char_embeddings_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e0febb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.876772Z",
     "iopub.status.busy": "2023-12-02T02:57:21.876496Z",
     "iopub.status.idle": "2023-12-02T02:57:21.885955Z",
     "shell.execute_reply": "2023-12-02T02:57:21.884932Z"
    },
    "papermill": {
     "duration": 0.023016,
     "end_time": "2023-12-02T02:57:21.887864",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.864848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharBiLSTM(LayerBase):\n",
    "    \"\"\"LayerCharCNN implements character-level convolutional 1D layer.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, char_hidden_dim):\n",
    "        super(LayerCharBiLSTM, self).__init__(gpu)\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.char_hidden_dim = char_hidden_dim\n",
    "        self.output_dim = 2 * char_hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=char_embeddings_dim,\n",
    "                            hidden_size=char_hidden_dim,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.lstm.weight_hh_l0.is_cuda\n",
    "\n",
    "    def forward(self, char_embeddings_feature): # batch_num x max_seq_len x char_embeddings_dim x word_len\n",
    "        batch_num, max_seq_len, char_embeddings_dim, word_len = char_embeddings_feature.shape\n",
    "        output_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.output_dim, dtype=torch.float))\n",
    "        for k in range(max_seq_len):\n",
    "            input_packed = char_embeddings_feature[:,k,:,:].permute(0,2,1)\n",
    "            output_pack, _ =  self.lstm(input_packed)\n",
    "            output_tensor[:,k,:] = output_pack[:,-1,:]\n",
    "        return output_tensor  # shape: batch_size x max_seq_len x hidden_dim*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efd4c48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.910567Z",
     "iopub.status.busy": "2023-12-02T02:57:21.910296Z",
     "iopub.status.idle": "2023-12-02T02:57:21.921544Z",
     "shell.execute_reply": "2023-12-02T02:57:21.920738Z"
    },
    "papermill": {
     "duration": 0.02462,
     "end_time": "2023-12-02T02:57:21.923343",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.898723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBiLSTM(LayerBiRNNBase):\n",
    "    \"\"\"BiLSTM layer implements standard bidirectional LSTM recurrent layer\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, gpu):\n",
    "        super(LayerBiLSTM, self).__init__(input_dim, hidden_dim, gpu)\n",
    "        self.num_layers = 1\n",
    "        self.num_directions = 2\n",
    "        rnn = nn.LSTM(input_size=input_dim,\n",
    "                      hidden_size=hidden_dim,\n",
    "                      num_layers=1,\n",
    "                      batch_first=True,\n",
    "                      bidirectional=True)\n",
    "        self.rnn = rnn\n",
    "\n",
    "    def lstm_custom_init(self):\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_hh_l0)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_hh_l0_reverse)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_ih_l0_reverse)\n",
    "        self.rnn.bias_hh_l0.data.fill_(0)\n",
    "        self.rnn.bias_hh_l0_reverse.data.fill_(0)\n",
    "        self.rnn.bias_ih_l0.data.fill_(0)\n",
    "        self.rnn.bias_ih_l0_reverse.data.fill_(0)\n",
    "        # Init forget gates to 1\n",
    "        for names in self.rnn._all_weights:\n",
    "            for name in filter(lambda n: 'bias' in n, names):\n",
    "                bias = getattr(self.rnn, name)\n",
    "                n = bias.size(0)\n",
    "                start, end = n // 4, n // 2\n",
    "                bias.data[start:end].fill_(1.)\n",
    "\n",
    "    def forward(self, input_tensor, mask_tensor): #input_tensor shape: batch_size x max_seq_len x dim\n",
    "        batch_size, max_seq_len, _ = input_tensor.shape\n",
    "        input_packed, reverse_sort_index = self.pack(input_tensor, mask_tensor)\n",
    "        h0 = self.tensor_ensure_gpu(torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim))\n",
    "        c0 = self.tensor_ensure_gpu(torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim))\n",
    "        output_packed, _ = self.rnn(input_packed, (h0, c0))\n",
    "        output_tensor = self.unpack(output_packed, max_seq_len, reverse_sort_index)\n",
    "        return output_tensor  # shape: batch_size x max_seq_len x hidden_dim*2\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.rnn.weight_hh_l0.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a6f1e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.945971Z",
     "iopub.status.busy": "2023-12-02T02:57:21.945706Z",
     "iopub.status.idle": "2023-12-02T02:57:21.954645Z",
     "shell.execute_reply": "2023-12-02T02:57:21.953868Z"
    },
    "papermill": {
     "duration": 0.02244,
     "end_time": "2023-12-02T02:57:21.956569",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.934129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerAttention(LayerBase):\n",
    "    def __init__(self, gpu, hidden_dim):\n",
    "        super(LayerAttention, self).__init__(gpu)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.att_weights = nn.Parameter(torch.Tensor(1, self.hidden_dim))\n",
    "        self.output_dim = hidden_dim\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_dim)\n",
    "        for weight in self.att_weights:\n",
    "            nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.att_weights.is_cuda\n",
    "\n",
    "    def forward(self, input_tensor, mask_tensor):\n",
    "        batch_size, max_len = input_tensor.size()[:2]\n",
    "        # apply attention layer\n",
    "        weights = torch.bmm(input_tensor,\n",
    "                            self.att_weights  # (1, hidden_dim)\n",
    "                            .permute(1, 0)  # (hidden_dim, 1)\n",
    "                            .unsqueeze(0)  # (1, hidden_dim, 1)\n",
    "                            .repeat(batch_size, 1, 1) # (batch_size, hidden_dim, 1)\n",
    "                            ) # (batch_size, max_seq_len, 1)\n",
    "        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-1)\n",
    "        # apply mask and renormalize attention scores (weights)\n",
    "        masked = attentions * mask_tensor\n",
    "        _sums = masked.sum(-1).unsqueeze(-1)  # sums per row\n",
    "        attentions = masked.div(_sums)\n",
    "        # apply attention weights\n",
    "        weighted = torch.mul(input_tensor, attentions.unsqueeze(-1).expand_as(input_tensor))\n",
    "        # get the final fixed vector representations of the sentences\n",
    "        representations = weighted.sum(1).squeeze()\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4960bcd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:21.979673Z",
     "iopub.status.busy": "2023-12-02T02:57:21.979396Z",
     "iopub.status.idle": "2023-12-02T02:57:22.010457Z",
     "shell.execute_reply": "2023-12-02T02:57:22.009677Z"
    },
    "papermill": {
     "duration": 0.044993,
     "end_time": "2023-12-02T02:57:22.012408",
     "exception": false,
     "start_time": "2023-12-02T02:57:21.967415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCRF(LayerBase):\n",
    "    \"\"\"LayerCRF implements Conditional Random Fields (Ma.et.al., 2016 style)\"\"\"\n",
    "    def __init__(self, gpu, states_num, pad_idx, sos_idx, tag_seq_indexer, verbose=True):\n",
    "        super(LayerCRF, self).__init__(gpu)\n",
    "        self.states_num = states_num\n",
    "        self.pad_idx = pad_idx\n",
    "        self.sos_idx = sos_idx\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.tag_seq_indexer.add_tag('<sos>')\n",
    "        self.verbose = verbose\n",
    "        # Transition matrix contains log probabilities from state j to state i\n",
    "        self.transition_matrix = nn.Parameter(torch.zeros(states_num, states_num, dtype=torch.float))\n",
    "        nn.init.normal_(self.transition_matrix, -1, 0.1)\n",
    "        # Default initialization\n",
    "        self.transition_matrix.data[self.sos_idx, :] = -9999.0\n",
    "        self.transition_matrix.data[:, self.pad_idx] = -9999.0\n",
    "        self.transition_matrix.data[self.pad_idx, :] = -9999.0\n",
    "        self.transition_matrix.data[self.pad_idx, self.pad_idx] = 0.0\n",
    "\n",
    "    def get_empirical_transition_matrix(self, tag_sequences_train, tag_seq_indexer=None):\n",
    "        if tag_seq_indexer is None:\n",
    "            tag_seq_indexer = self.tag_seq_indexer\n",
    "        empirical_transition_matrix = torch.zeros(self.states_num, self.states_num, dtype=torch.long)\n",
    "        for tag_seq in tag_sequences_train:\n",
    "            try:\n",
    "                s = tag_seq_indexer.item2idx_dict[tag_seq[0]]\n",
    "            except:\n",
    "                print(tag_seq)\n",
    "            empirical_transition_matrix[s, self.sos_idx] += 1\n",
    "            for n, tag in enumerate(tag_seq):\n",
    "                if n + 1 >= len(tag_seq):\n",
    "                    break\n",
    "                next_tag = tag_seq[n + 1]\n",
    "                j = tag_seq_indexer.item2idx_dict[tag]\n",
    "                i = tag_seq_indexer.item2idx_dict[next_tag]\n",
    "                empirical_transition_matrix[i, j] += 1\n",
    "        return empirical_transition_matrix\n",
    "\n",
    "    def init_transition_matrix_empirical(self, tag_sequences_train):\n",
    "        # Calculate statistics for tag transitions\n",
    "        empirical_transition_matrix = self.get_empirical_transition_matrix(tag_sequences_train)\n",
    "        # Initialize\n",
    "        for i in range(self.tag_seq_indexer.get_items_count()):\n",
    "            for j in range(self.tag_seq_indexer.get_items_count()):\n",
    "                if empirical_transition_matrix[i, j] == 0:\n",
    "                    self.transition_matrix.data[i, j] = -9999.0\n",
    "                #self.transition_matrix.data[i, j] = torch.log(empirical_transition_matrix[i, j].float() + 10**-32)\n",
    "        if self.verbose:\n",
    "            print('Empirical transition matrix from the train dataset:')\n",
    "            self.pretty_print_transition_matrix(empirical_transition_matrix)\n",
    "            print('\\nInitialized transition matrix:')\n",
    "            self.pretty_print_transition_matrix(self.transition_matrix.data)\n",
    "\n",
    "    def pretty_print_transition_matrix(self, transition_matrix, tag_seq_indexer=None):\n",
    "        if tag_seq_indexer is None:\n",
    "            tag_seq_indexer = self.tag_seq_indexer\n",
    "        str = '%10s' % ''\n",
    "        for i in range(tag_seq_indexer.get_items_count()):\n",
    "            str += '%10s' % tag_seq_indexer.idx2item_dict[i]\n",
    "        str += '\\n'\n",
    "        for i in range(tag_seq_indexer.get_items_count()):\n",
    "            str += '\\n%10s' % tag_seq_indexer.idx2item_dict[i]\n",
    "            for j in range(tag_seq_indexer.get_items_count()):\n",
    "                str += '%10s' % ('%1.1f' % transition_matrix[i, j])\n",
    "        print(str)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.transition_matrix.is_cuda\n",
    "\n",
    "    def numerator(self, features_rnn_compressed, states_tensor, mask_tensor):\n",
    "        # features_input_tensor: batch_num x max_seq_len x states_num\n",
    "        # states_tensor: batch_num x max_seq_len\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_num, max_seq_len = mask_tensor.shape\n",
    "        score = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "        start_states_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, 1, dtype=torch.long).fill_(self.sos_idx))\n",
    "        states_tensor = torch.cat([start_states_tensor, states_tensor], 1)\n",
    "        for n in range(max_seq_len):\n",
    "            curr_mask = mask_tensor[:, n]\n",
    "            curr_emission = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "            curr_transition = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "            for k in range(batch_num):\n",
    "                curr_emission[k] = features_rnn_compressed[k, n, states_tensor[k, n + 1]].unsqueeze(0)\n",
    "                curr_states_seq = states_tensor[k]\n",
    "                curr_transition[k] = self.transition_matrix[curr_states_seq[n + 1], curr_states_seq[n]].unsqueeze(0)\n",
    "            score = score + curr_emission*curr_mask + curr_transition*curr_mask\n",
    "        return score\n",
    "\n",
    "    def denominator(self, features_rnn_compressed, mask_tensor):\n",
    "        # features_rnn_compressed: batch x max_seq_len x states_num\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_num, max_seq_len = mask_tensor.shape\n",
    "        score = self.tensor_ensure_gpu(torch.zeros(batch_num, self.states_num, dtype=torch.float).fill_(-9999.0))\n",
    "        score[:, self.sos_idx] = 0.\n",
    "        for n in range(max_seq_len):\n",
    "            curr_mask = mask_tensor[:, n].unsqueeze(-1).expand_as(score)\n",
    "            curr_score = score.unsqueeze(1).expand(-1, *self.transition_matrix.size())\n",
    "            curr_emission = features_rnn_compressed[:, n].unsqueeze(-1).expand_as(curr_score)\n",
    "            curr_transition = self.transition_matrix.unsqueeze(0).expand_as(curr_score)\n",
    "            #curr_score = torch.logsumexp(curr_score + curr_emission + curr_transition, dim=2)\n",
    "            curr_score = log_sum_exp(curr_score + curr_emission + curr_transition)\n",
    "            score = curr_score * curr_mask + score * (1 - curr_mask)\n",
    "        #score = torch.logsumexp(score, dim=1)\n",
    "        score = log_sum_exp(score)\n",
    "        return score\n",
    "\n",
    "    def decode_viterbi(self, features_rnn_compressed, mask_tensor):\n",
    "        # features_rnn_compressed: batch x max_seq_len x states_num\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_size, max_seq_len = mask_tensor.shape\n",
    "        seq_len_list = [int(mask_tensor[k].sum().item()) for k in range(batch_size)]\n",
    "        # Step 1. Calculate scores & backpointers\n",
    "        score = self.tensor_ensure_gpu(torch.Tensor(batch_size, self.states_num).fill_(-9999.))\n",
    "        score[:, self.sos_idx] = 0.0\n",
    "        backpointers = self.tensor_ensure_gpu(torch.LongTensor(batch_size, max_seq_len, self.states_num))\n",
    "        for n in range(max_seq_len):\n",
    "            curr_emissions = features_rnn_compressed[:, n]\n",
    "            curr_score = self.tensor_ensure_gpu(torch.Tensor(batch_size, self.states_num))\n",
    "            curr_backpointers = self.tensor_ensure_gpu(torch.LongTensor(batch_size, self.states_num))\n",
    "            for curr_state in range(self.states_num):\n",
    "                T = self.transition_matrix[curr_state, :].unsqueeze(0).expand(batch_size, self.states_num)\n",
    "                max_values, max_indices = torch.max(score + T, 1)\n",
    "                curr_score[:, curr_state] = max_values\n",
    "                curr_backpointers[:, curr_state] = max_indices\n",
    "            curr_mask = mask_tensor[:, n].unsqueeze(1).expand(batch_size, self.states_num)\n",
    "            score = score * (1 - curr_mask) + (curr_score + curr_emissions) * curr_mask\n",
    "            backpointers[:, n, :] = curr_backpointers # shape: batch_size x max_seq_len x state_num\n",
    "        best_score_batch, last_best_state_batch = torch.max(score, 1)\n",
    "        # Step 2. Find the best path\n",
    "        best_path_batch = [[state] for state in last_best_state_batch.tolist()]\n",
    "        for k in range(batch_size):\n",
    "            curr_best_state = last_best_state_batch[k]\n",
    "            curr_seq_len = seq_len_list[k]\n",
    "            for n in reversed(range(1, curr_seq_len)):\n",
    "                curr_best_state = backpointers[k, n, curr_best_state].item()\n",
    "                best_path_batch[k].insert(0, curr_best_state)\n",
    "        return best_path_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaf565",
   "metadata": {
    "papermill": {
     "duration": 0.010898,
     "end_time": "2023-12-02T02:57:22.077267",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.066369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22b1693f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.100948Z",
     "iopub.status.busy": "2023-12-02T02:57:22.100596Z",
     "iopub.status.idle": "2023-12-02T02:57:22.117138Z",
     "shell.execute_reply": "2023-12-02T02:57:22.116265Z"
    },
    "papermill": {
     "duration": 0.031006,
     "end_time": "2023-12-02T02:57:22.119215",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.088209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerBase(nn.Module):\n",
    "    \"\"\"TaggerBase is an abstract class for tagger models. It implements the tagging functionality for\n",
    "    different types of inputs (sequences of tokens, sequences of integer indices, tensors). Auxiliary class\n",
    "    SequencesIndexer is used for input and output data formats conversions. Abstract method `forward` is used in order\n",
    "    to make these predictions, it have to be implemented in ancestors.\"\"\"\n",
    "    def __init__(self,  word_seq_indexer, tag_seq_indexer, gpu, batch_size):\n",
    "        super(TaggerBase, self).__init__()\n",
    "        self.word_seq_indexer = word_seq_indexer\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.gpu = gpu\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def tensor_ensure_gpu(self, tensor):\n",
    "        if self.gpu >= 0:\n",
    "            return tensor.cuda(device=self.gpu)\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def self_ensure_gpu(self):\n",
    "        if self.gpu >= 0:\n",
    "            self.cuda(device=self.gpu)\n",
    "        else:\n",
    "            self.cpu()\n",
    "\n",
    "    def save_tagger(self, checkpoint_fn):\n",
    "        self.cpu()\n",
    "        torch.save(self, checkpoint_fn)\n",
    "        self.self_ensure_gpu()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        pass\n",
    "\n",
    "    def predict_idx_from_words(self, word_sequences):\n",
    "        self.eval()\n",
    "        outputs_tensor = self.forward(word_sequences) # batch_size x num_class+1 x max_seq_len\n",
    "        output_idx_sequences = list()\n",
    "        for k in range(len(word_sequences)):\n",
    "            idx_seq = list()\n",
    "            for l in range(len(word_sequences[k])):\n",
    "                curr_output = outputs_tensor[k, 1:, l] # ignore the first component of output\n",
    "                max_no = curr_output.argmax(dim=0)\n",
    "                idx_seq.append(max_no.item() + 1)\n",
    "            output_idx_sequences.append(idx_seq)\n",
    "        return output_idx_sequences\n",
    "\n",
    "    def predict_tags_from_words(self, word_sequences, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = self.batch_size\n",
    "        print('\\n')\n",
    "        batch_num = math.floor(len(word_sequences) / batch_size)\n",
    "        if len(word_sequences) > 0 and len(word_sequences) < batch_size:\n",
    "            batch_num = 1\n",
    "        output_tag_sequences = list()\n",
    "        for n in range(batch_num):\n",
    "            i = n*batch_size\n",
    "            if n < batch_num - 1:\n",
    "                j = (n + 1)*batch_size\n",
    "            else:\n",
    "                j = len(word_sequences)\n",
    "            curr_output_idx = self.predict_idx_from_words(word_sequences[i:j])\n",
    "            curr_output_tag_sequences = self.tag_seq_indexer.idx2items(curr_output_idx)\n",
    "            output_tag_sequences.extend(curr_output_tag_sequences)\n",
    "            print('\\r++ predicting, batch %d/%d (%1.2f%%).' % (n + 1, batch_num, math.ceil(n * 100.0 / batch_num)),\n",
    "                  end='', flush=True)\n",
    "        return output_tag_sequences\n",
    "\n",
    "    def get_mask_from_word_sequences(self, word_sequences):\n",
    "        batch_num = len(word_sequences)\n",
    "        max_seq_len = max([len(word_seq) for word_seq in word_sequences])\n",
    "        mask_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, dtype=torch.float))\n",
    "        for k, word_seq in enumerate(word_sequences):\n",
    "            mask_tensor[k, :len(word_seq)] = 1\n",
    "        return mask_tensor # batch_size x max_seq_len\n",
    "\n",
    "    def apply_mask(self, input_tensor, mask_tensor):\n",
    "        input_tensor = self.tensor_ensure_gpu(input_tensor)\n",
    "        mask_tensor = self.tensor_ensure_gpu(mask_tensor)\n",
    "        return input_tensor*mask_tensor.unsqueeze(-1).expand_as(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31d189c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.142738Z",
     "iopub.status.busy": "2023-12-02T02:57:22.142436Z",
     "iopub.status.idle": "2023-12-02T02:57:22.165491Z",
     "shell.execute_reply": "2023-12-02T02:57:22.164629Z"
    },
    "papermill": {
     "duration": 0.037272,
     "end_time": "2023-12-02T02:57:22.167570",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.130298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerBiRNNCNNCRF(TaggerBase):\n",
    "    \"\"\"TaggerBiRNNCNNCRF is a model for sequences tagging that includes recurrent network + conv layer + CRF.\"\"\"\n",
    "    def __init__(self, word_seq_indexer, tag_seq_indexer, class_num, batch_size=1, rnn_hidden_dim=100,\n",
    "                 emb_dim = 200, freeze_word_embeddings=False, dropout_ratio=0.5, rnn_type='GRU', gpu=-1,\n",
    "                 freeze_char_embeddings = False, char_embeddings_dim=100, word_len=20, char_cnn_filter_num=30,\n",
    "                 char_window_size=3):\n",
    "        super(TaggerBiRNNCNNCRF, self).__init__(word_seq_indexer, tag_seq_indexer, gpu, batch_size)\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.class_num = class_num\n",
    "        self.rnn_hidden_dim = rnn_hidden_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.freeze_embeddings = freeze_word_embeddings\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.rnn_type = rnn_type\n",
    "        self.gpu = gpu\n",
    "        self.word_embeddings_layer = LayerWordEmbeddings(word_seq_indexer, gpu, freeze_word_embeddings)\n",
    "        self.freeze_char_embeddings = freeze_char_embeddings\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.word_len = word_len\n",
    "        self.char_cnn_filter_num = char_cnn_filter_num\n",
    "        self.char_window_size = char_window_size\n",
    "        self.word_embeddings_layer = LayerWordEmbeddings(word_seq_indexer, gpu, freeze_word_embeddings)\n",
    "        self.char_embeddings_layer = LayerCharEmbeddings(gpu, char_embeddings_dim, freeze_char_embeddings,\n",
    "                                                         word_len, word_seq_indexer.get_unique_characters_list())\n",
    "        self.char_cnn_layer = LayerCharCNN(gpu, char_embeddings_dim, char_cnn_filter_num, char_window_size,\n",
    "                                           word_len)\n",
    "        self.char_lstm_layer = LayerCharBiLSTM(gpu,char_embeddings_dim,char_embeddings_dim)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "        if rnn_type == 'GRU':\n",
    "            self.birnn_layer = LayerBiGRU(input_dim=self.emb_dim,\n",
    "                                          hidden_dim=rnn_hidden_dim,\n",
    "                                          gpu=gpu)\n",
    "        elif rnn_type == 'LSTM':\n",
    "            self.birnn_layer = LayerBiLSTM(input_dim=self.emb_dim,\n",
    "                                           hidden_dim=rnn_hidden_dim,\n",
    "                                           gpu=gpu)\n",
    "        else:\n",
    "            raise ValueError('Unknown rnn_type = %s, must be either \"LSTM\" or \"GRU\"')\n",
    "        self.lin_layer1 = nn.Linear(in_features=self.word_embeddings_layer.output_dim + self.char_cnn_layer.output_dim + self.char_lstm_layer.output_dim, \n",
    "                                    out_features=self.emb_dim)\n",
    "        self.att_layer = LayerAttention(gpu=gpu, hidden_dim=self.birnn_layer.output_dim)\n",
    "        self.lin_layer2 = nn.Linear(in_features=self.birnn_layer.output_dim + self.att_layer.output_dim, out_features=class_num + 2)\n",
    "        self.crf_layer = LayerCRF(gpu, states_num=class_num + 2, pad_idx=tag_seq_indexer.pad_idx, sos_idx=class_num + 1,\n",
    "                                  tag_seq_indexer=tag_seq_indexer)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        if gpu >= 0:\n",
    "            self.cuda(device=self.gpu)\n",
    "\n",
    "    def _forward_birnn(self, word_sequences):\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences)\n",
    "        z_word_embed = self.word_embeddings_layer(word_sequences)\n",
    "        z_word_embed_d = self.dropout(z_word_embed)\n",
    "        z_char_embed = self.char_embeddings_layer(word_sequences)\n",
    "        z_char_cnn = self.char_cnn_layer(z_char_embed)\n",
    "        z_char_cnn_d = self.dropout(z_char_cnn)\n",
    "        z_char_lstm = self.char_lstm_layer(z_char_embed)\n",
    "        z_char_lstm_d = self.dropout(z_char_lstm)\n",
    "        z = torch.cat((z_word_embed_d, z_char_cnn_d, z_char_lstm_d), dim=2)\n",
    "        z = self.lin_layer1(z)\n",
    "        rnn_output_h = self.apply_mask(self.birnn_layer(z, mask), mask)\n",
    "        att_rnn_output = self.att_layer(rnn_output_h, mask)\n",
    "        features_rnn_att = torch.cat((rnn_output_h, att_rnn_output), dim=2)\n",
    "        features_rnn_compressed = self.lin_layer2(features_rnn_att)\n",
    "        return self.apply_mask(features_rnn_compressed, mask)\n",
    "\n",
    "    def get_loss(self, word_sequences_train_batch, tag_sequences_train_batch):\n",
    "        targets_tensor_train_batch = self.tag_seq_indexer.items2tensor(tag_sequences_train_batch)\n",
    "        features_rnn = self._forward_birnn(word_sequences_train_batch) # batch_num x max_seq_len x class_num\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences_train_batch)  # batch_num x max_seq_len\n",
    "        numerator = self.crf_layer.numerator(features_rnn, targets_tensor_train_batch, mask)\n",
    "        denominator = self.crf_layer.denominator(features_rnn, mask)\n",
    "        nll_loss = -torch.mean(numerator - denominator)\n",
    "        return nll_loss\n",
    "\n",
    "    def predict_idx_from_words(self, word_sequences, no=-1):\n",
    "        self.eval()\n",
    "        features_rnn_compressed_masked  = self._forward_birnn(word_sequences)\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences)\n",
    "        idx_sequences = self.crf_layer.decode_viterbi(features_rnn_compressed_masked, mask)\n",
    "        return idx_sequences\n",
    "\n",
    "    def predict_tags_from_words(self, word_sequences, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = self.batch_size\n",
    "        print('\\n')\n",
    "        batch_num = math.floor(len(word_sequences) / batch_size)\n",
    "        if len(word_sequences) > 0 and len(word_sequences) < batch_size:\n",
    "            batch_num = 1\n",
    "        output_tag_sequences = list()\n",
    "        for n in range(batch_num):\n",
    "            i = n*batch_size\n",
    "            if n < batch_num - 1:\n",
    "                j = (n + 1)*batch_size\n",
    "            else:\n",
    "                j = len(word_sequences)\n",
    "            if batch_size == 1:\n",
    "                curr_output_idx = self.predict_idx_from_words(word_sequences[i:j], n)\n",
    "            else:\n",
    "                curr_output_idx = self.predict_idx_from_words(word_sequences[i:j], -1)\n",
    "            curr_output_tag_sequences = self.tag_seq_indexer.idx2items(curr_output_idx)\n",
    "            output_tag_sequences.extend(curr_output_tag_sequences)\n",
    "            print('\\r++ predicting, batch %d/%d (%1.2f%%).' % (n + 1, batch_num, math.ceil(n * 100.0 / batch_num)),\n",
    "                  end='', flush=True)\n",
    "        return output_tag_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957cb5f",
   "metadata": {
    "papermill": {
     "duration": 0.010753,
     "end_time": "2023-12-02T02:57:22.189550",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.178797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44fa1789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.212814Z",
     "iopub.status.busy": "2023-12-02T02:57:22.212540Z",
     "iopub.status.idle": "2023-12-02T02:57:22.220089Z",
     "shell.execute_reply": "2023-12-02T02:57:22.219213Z"
    },
    "papermill": {
     "duration": 0.021326,
     "end_time": "2023-12-02T02:57:22.221940",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.200614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorBase():\n",
    "    \"\"\"EvaluatorBase is abstract base class for all evaluators\"\"\"\n",
    "    def get_evaluation_score_train_dev_test(self, tagger, datasets_bank, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = tagger.batch_size\n",
    "        score_train, _ = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                       word_sequences=datasets_bank.word_sequences_train,\n",
    "                                                       targets_tag_sequences=datasets_bank.tag_sequences_train,\n",
    "                                                       batch_size=batch_size)\n",
    "        score_dev, _ = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                     word_sequences=datasets_bank.word_sequences_dev,\n",
    "                                                     targets_tag_sequences=datasets_bank.tag_sequences_dev,\n",
    "                                                     batch_size=batch_size)\n",
    "        score_test, msg_test = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                             word_sequences=datasets_bank.word_sequences_test,\n",
    "                                                             targets_tag_sequences=datasets_bank.tag_sequences_test,\n",
    "                                                             batch_size=batch_size)\n",
    "        return score_train, score_dev, score_test, msg_test\n",
    "\n",
    "    def predict_evaluation_score(self, tagger, word_sequences, targets_tag_sequences, batch_size):\n",
    "        outputs_tag_sequences = tagger.predict_tags_from_words(word_sequences, batch_size)\n",
    "        return self.get_evaluation_score(targets_tag_sequences, outputs_tag_sequences, word_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffaea5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.245857Z",
     "iopub.status.busy": "2023-12-02T02:57:22.245071Z",
     "iopub.status.idle": "2023-12-02T02:57:22.259793Z",
     "shell.execute_reply": "2023-12-02T02:57:22.259054Z"
    },
    "papermill": {
     "duration": 0.028572,
     "end_time": "2023-12-02T02:57:22.261612",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.233040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorF1MacroTokenLevel(EvaluatorBase):\n",
    "    def __init__(self):\n",
    "        self.tag_list = None\n",
    "        self.tag2idx = dict()\n",
    "\n",
    "    def __init_tag_list(self, targets_tag_sequences):\n",
    "        if self.tag_list is not None:\n",
    "            return\n",
    "        self.tag_list = list()\n",
    "        for tag_seq in targets_tag_sequences:\n",
    "            for t in tag_seq:\n",
    "                if t not in self.tag_list:\n",
    "                    self.tag_list.append(t)\n",
    "                    self.tag2idx[t] = len(self.tag_list)\n",
    "        self.tag_list.sort()\n",
    "\n",
    "    def tag_seq_2_idx_list(self, tag_seq):\n",
    "        return [self.tag2idx[t] for t in tag_seq]\n",
    "\n",
    "    def __get_zeros_tag_dict(self):\n",
    "        return {tag: 0 for tag in self.tag_list}\n",
    "\n",
    "    def __add_dict(self, dict1, dict2):\n",
    "        for tag in self.tag_list:\n",
    "            dict1[tag] += dict2[tag]\n",
    "        return dict1\n",
    "\n",
    "    def __div_dict(self, dict, d):\n",
    "        for tag in self.tag_list:\n",
    "            dict[tag] /= d\n",
    "        return dict\n",
    "\n",
    "    def __get_M_F1_msg(self, F1):\n",
    "        msg = '\\nF1 scores\\n'\n",
    "        msg += '-' * 24 + '\\n'\n",
    "        sum_M_F1 = 0\n",
    "        for tag in self.tag_list:\n",
    "            sum_M_F1 += F1[tag]\n",
    "            msg += '%15s = %1.2f\\n' % (tag, F1[tag])\n",
    "        M_F1 = sum_M_F1 / len(F1)\n",
    "        msg += '-'*24 + '\\n'\n",
    "        msg += 'Macro-F1 = %1.3f' % M_F1\n",
    "        return M_F1, msg\n",
    "\n",
    "    def __add_to_dict(self, dict_in, tag, val):\n",
    "        if tag in dict_in:\n",
    "            dict_in[tag] += val\n",
    "        else:\n",
    "            dict_in[tag] = val\n",
    "        return dict_in\n",
    "\n",
    "    \"\"\"EvaluatorF1MacroTagComponents is macro-F1 scores evaluator for each class of BOI-like tags.\"\"\"\n",
    "    def get_evaluation_score(self, targets_tag_sequences, outputs_tag_sequences, word_sequences=None):\n",
    "        # Create list of tags\n",
    "        self.__init_tag_list(targets_tag_sequences)\n",
    "        # Init values\n",
    "        TP = self.__get_zeros_tag_dict()\n",
    "        FP = self.__get_zeros_tag_dict()\n",
    "        FN = self.__get_zeros_tag_dict()\n",
    "        F1 = self.__get_zeros_tag_dict()\n",
    "        for targets_seq, outputs_tag_seq in zip(targets_tag_sequences, outputs_tag_sequences):\n",
    "            for t, o in zip(targets_seq, outputs_tag_seq):\n",
    "                if t == o:\n",
    "                    TP = self.__add_to_dict(TP, t, 1)\n",
    "                else:\n",
    "                    FN = self.__add_to_dict(FN, t, 1)\n",
    "                    FP = self.__add_to_dict(FP, o, 1)\n",
    "        # Calculate F1 for each tag\n",
    "        for tag in self.tag_list:\n",
    "            F1[tag] = (2 * TP[tag] / max(2 * TP[tag] + FP[tag] + FN[tag], 1)) * 100\n",
    "        # Calculate Macro-F1 score and prepare the message\n",
    "        M_F1, msg = self.__get_M_F1_msg(F1)\n",
    "        print(msg)\n",
    "        #self.validate_M_F1_scikitlearn( targets_tag_sequences, outputs_tag_sequences)\n",
    "        return M_F1, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f8b142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.285783Z",
     "iopub.status.busy": "2023-12-02T02:57:22.285162Z",
     "iopub.status.idle": "2023-12-02T02:57:22.290956Z",
     "shell.execute_reply": "2023-12-02T02:57:22.290101Z"
    },
    "papermill": {
     "duration": 0.020092,
     "end_time": "2023-12-02T02:57:22.292902",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.272810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorAccuracyTokenLevel(EvaluatorBase):\n",
    "    \"\"\"EvaluatorAccuracyTokenLevel is token-level accuracy evaluator for each class of BOI-like tags.\"\"\"\n",
    "    def get_evaluation_score(self, targets_tag_sequences, outputs_tag_sequences, word_sequences=None):\n",
    "        cnt = 0\n",
    "        match = 0\n",
    "        for target_seq, output_seq in zip(targets_tag_sequences, outputs_tag_sequences):\n",
    "            for t, o in zip(target_seq, output_seq):\n",
    "                cnt += 1\n",
    "                if t == o:\n",
    "                    match += 1\n",
    "        acc = match*100.0/cnt\n",
    "        msg = '*** Token-level accuracy: %1.2f%% ***' % acc\n",
    "        return acc, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac8922",
   "metadata": {
    "papermill": {
     "duration": 0.010911,
     "end_time": "2023-12-02T02:57:22.315052",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.304141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa876619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.338582Z",
     "iopub.status.busy": "2023-12-02T02:57:22.338256Z",
     "iopub.status.idle": "2023-12-02T02:57:22.349995Z",
     "shell.execute_reply": "2023-12-02T02:57:22.349268Z"
    },
    "papermill": {
     "duration": 0.025695,
     "end_time": "2023-12-02T02:57:22.351921",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.326226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Report():\n",
    "    def __init__(self, fn, args, score_names):\n",
    "        \"\"\"Report stores evaluation results during the training process as text files.\"\"\"\n",
    "        self.fn = fn\n",
    "        self.args = args\n",
    "        self.score_num = len(score_names)\n",
    "        self.text = 'Evaluation\\n\\n'\n",
    "        self.text += '\\n'.join([hp for hp in str(args).replace('Namespace(', '').replace(')', '').split(', ')])\n",
    "        header = '\\n\\n %14s |' % 'epoch '\n",
    "        for n, score_name in enumerate(score_names):\n",
    "            header += ' %14s ' % score_name\n",
    "            if n < len(score_names) - 1: header += '|'\n",
    "        self.text += header\n",
    "        self.blank_line = '\\n' + '-' * len(header)\n",
    "        self.text += self.blank_line\n",
    "\n",
    "    def write_epoch_scores(self, epoch, scores):\n",
    "        self.text += '\\n %14s |' % ('%d'% epoch)\n",
    "        for n, score in enumerate(scores):\n",
    "            self.text += ' %14s ' % ('%1.2f' % score)\n",
    "            if n < len(scores) - 1: self.text += '|'\n",
    "        self.__save()\n",
    "\n",
    "    def write_final_score(self, final_score_str):\n",
    "        self.text += self.blank_line\n",
    "        self.text += '\\n%s' % final_score_str\n",
    "        self.__save()\n",
    "\n",
    "    def write_msg(self, msg):\n",
    "        self.text += self.blank_line\n",
    "        self.text += msg\n",
    "        self.__save()\n",
    "\n",
    "    def write_input_arguments(self):\n",
    "        self.text += '\\nInput arguments:\\n%s' % get_input_arguments()\n",
    "        self.__save()\n",
    "\n",
    "    def write_final_line_score(self, final_score):\n",
    "        self.text += '\\n\\n%1.4f' % final_score\n",
    "        self.__save()\n",
    "\n",
    "    def __save(self):\n",
    "        if self.fn is not None:\n",
    "            with open(self.fn, mode='w') as text_file:\n",
    "                text_file.write(self.text)\n",
    "\n",
    "    def make_print(self):\n",
    "        print(self.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bf4da",
   "metadata": {
    "papermill": {
     "duration": 0.011264,
     "end_time": "2023-12-02T02:57:22.374631",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.363367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb41ea3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.398565Z",
     "iopub.status.busy": "2023-12-02T02:57:22.398247Z",
     "iopub.status.idle": "2023-12-02T02:57:22.403832Z",
     "shell.execute_reply": "2023-12-02T02:57:22.402950Z"
    },
    "papermill": {
     "duration": 0.019846,
     "end_time": "2023-12-02T02:57:22.405836",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.385990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataIOFactory():\n",
    "    \"\"\"DataIOFactory contains wrappers to create various data readers/writers.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.data_io == 'ncbi_disease':\n",
    "            return DataIONCBI(dataset_name = args.data_io, \n",
    "                              train_no = args.train_no, \n",
    "                              dev_no = args.dev_no,\n",
    "                              test_no = args.test_no\n",
    "                             )\n",
    "        else:\n",
    "            raise ValueError('Unknown DataIO %s.' % args.data_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d5831d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.430381Z",
     "iopub.status.busy": "2023-12-02T02:57:22.430117Z",
     "iopub.status.idle": "2023-12-02T02:57:22.434893Z",
     "shell.execute_reply": "2023-12-02T02:57:22.434099Z"
    },
    "papermill": {
     "duration": 0.018721,
     "end_time": "2023-12-02T02:57:22.436698",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.417977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetsBankFactory():\n",
    "    \"\"\"DatasetsBankFactory contains wrappers to create various datasets banks.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.dataset_sort:\n",
    "            datasets_bank = DatasetsBankSorted(verbose=True)\n",
    "        else:\n",
    "            datasets_bank = DatasetsBank(verbose=True)\n",
    "        return datasets_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0de7838f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.460972Z",
     "iopub.status.busy": "2023-12-02T02:57:22.460369Z",
     "iopub.status.idle": "2023-12-02T02:57:22.469693Z",
     "shell.execute_reply": "2023-12-02T02:57:22.468856Z"
    },
    "papermill": {
     "duration": 0.023526,
     "end_time": "2023-12-02T02:57:22.471590",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.448064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerFactory():\n",
    "    \"\"\"TaggerFactory contains wrappers to create various tagger models.\"\"\"\n",
    "    @staticmethod\n",
    "    def load(checkpoint_fn, gpu=-1):\n",
    "        if not os.path.isfile(checkpoint_fn):\n",
    "            raise ValueError('Can''t find tagger in file \"%s\". Please, run the main script with non-empty \\\n",
    "                             \"--save-best-path\" param to create it.' % checkpoint_fn)\n",
    "        tagger = torch.load(checkpoint_fn)\n",
    "        tagger.gpu = gpu\n",
    "\n",
    "        tagger.word_seq_indexer.gpu = gpu # hotfix\n",
    "        tagger.tag_seq_indexer.gpu = gpu # hotfix\n",
    "        if hasattr(tagger, 'char_embeddings_layer'):# very hot hotfix\n",
    "            tagger.char_embeddings_layer.char_seq_indexer.gpu = gpu # hotfix\n",
    "        tagger.self_ensure_gpu()\n",
    "        return tagger\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create(args, word_seq_indexer, tag_seq_indexer, tag_sequences_train):\n",
    "        if args.model == 'BiRNNCNNCRF':\n",
    "            tagger = TaggerBiRNNCNNCRF(word_seq_indexer=word_seq_indexer,\n",
    "                                       tag_seq_indexer=tag_seq_indexer,\n",
    "                                       class_num=tag_seq_indexer.get_class_num(),\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       rnn_hidden_dim=args.rnn_hidden_dim,\n",
    "                                       emb_dim=args.emb_dim,\n",
    "                                       freeze_word_embeddings=args.freeze_word_embeddings,\n",
    "                                       dropout_ratio=args.dropout_ratio,\n",
    "                                       rnn_type=args.rnn_type,\n",
    "                                       gpu=args.gpu,\n",
    "                                       freeze_char_embeddings=args.freeze_char_embeddings,\n",
    "                                       char_embeddings_dim=args.char_embeddings_dim,\n",
    "                                       word_len=args.word_len,\n",
    "                                       char_cnn_filter_num=args.char_cnn_filter_num,\n",
    "                                       char_window_size=args.char_window_size)\n",
    "            tagger.crf_layer.init_transition_matrix_empirical(tag_sequences_train)\n",
    "        else:\n",
    "            raise ValueError('Unknown tagger model')\n",
    "        return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd7ec951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.495689Z",
     "iopub.status.busy": "2023-12-02T02:57:22.495384Z",
     "iopub.status.idle": "2023-12-02T02:57:22.501565Z",
     "shell.execute_reply": "2023-12-02T02:57:22.500705Z"
    },
    "papermill": {
     "duration": 0.020334,
     "end_time": "2023-12-02T02:57:22.503397",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.483063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorFactory():\n",
    "    \"\"\"EvaluatorFactory contains wrappers to create various evaluators.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.evaluator == 'f1-connl':\n",
    "            return EvaluatorF1MicroSpansConnl()\n",
    "        elif args.evaluator == 'f1-alpha-match-10':\n",
    "            return EvaluatorF1MicroSpansAlphaMatch10()\n",
    "        elif args.evaluator == 'f1-alpha-match-05':\n",
    "            return EvaluatorF1MicroSpansAlphaMatch05()\n",
    "        elif args.evaluator == 'f1-macro':\n",
    "            return EvaluatorF1MacroTokenLevel()\n",
    "        elif args.evaluator == 'f05-macro':\n",
    "            return EvaluatorF05MacroTokenLevel()\n",
    "        elif args.evaluator == 'token-acc':\n",
    "            return EvaluatorAccuracyTokenLevel()\n",
    "        else:\n",
    "            raise ValueError('Unknown evaluator %s.' % args.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a76d6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.527775Z",
     "iopub.status.busy": "2023-12-02T02:57:22.527434Z",
     "iopub.status.idle": "2023-12-02T02:57:22.533873Z",
     "shell.execute_reply": "2023-12-02T02:57:22.532986Z"
    },
    "papermill": {
     "duration": 0.020848,
     "end_time": "2023-12-02T02:57:22.535792",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.514944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptimizerFactory():\n",
    "    \"\"\"OptimizerFactory contains wrappers to create various optimizers.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args, tagger):\n",
    "        if args.opt == 'sgd':\n",
    "            optimizer = optim.SGD(list(tagger.parameters()), lr=args.lr, momentum=args.momentum)\n",
    "        elif args.opt == 'adam':\n",
    "            optimizer = optim.Adam(list(tagger.parameters()), lr=args.lr, \n",
    "                                   betas=(0.9, 0.999),\n",
    "                                   weight_decay = args.weight_decay\n",
    "                                  )\n",
    "        else:\n",
    "            raise ValueError('Unknown optimizer, must be one of \"sgd\"/\"adam\".')\n",
    "        scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: args.lr_decay ** epoch)\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e212da",
   "metadata": {
    "papermill": {
     "duration": 0.011308,
     "end_time": "2023-12-02T02:57:22.559015",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.547707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba109de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.583903Z",
     "iopub.status.busy": "2023-12-02T02:57:22.583060Z",
     "iopub.status.idle": "2023-12-02T02:57:22.592118Z",
     "shell.execute_reply": "2023-12-02T02:57:22.591188Z"
    },
    "papermill": {
     "duration": 0.023474,
     "end_time": "2023-12-02T02:57:22.594037",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.570563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> CONFIG DONE\n"
     ]
    }
   ],
   "source": [
    "class ARGS:\n",
    "    seed = 101\n",
    "    verbose = True\n",
    "    debug = False\n",
    "    data_io = \"ncbi_disease\"\n",
    "    train_no = None\n",
    "    dev_no = None\n",
    "    test_no = None\n",
    "    model = 'BiRNNCNNCRF'\n",
    "    rnn_type = 'LSTM'\n",
    "    load = None\n",
    "    epoch_num = 40\n",
    "    min_epoch_num = 1\n",
    "    batch_size = 16\n",
    "    gpu = 0\n",
    "    check_for_lowercase = True\n",
    "    emb_fn = \"/kaggle/input/glove6b/glove.6B.200d.txt\"\n",
    "    emb_dim = 200\n",
    "    emb_delimiter = ' '\n",
    "    emb_load_all = False\n",
    "    freeze_word_embeddings = False\n",
    "    rnn_hidden_dim = 200\n",
    "    ## Character CNN config\n",
    "    word_len = 20\n",
    "    char_embeddings_dim = 100\n",
    "    freeze_char_embeddings = False\n",
    "    char_window_size = [2,3,4]\n",
    "    char_cnn_filter_num =len(char_window_size)\n",
    "    \n",
    "    dropout_ratio = 0.5\n",
    "    dataset_sort = False\n",
    "    word_seq_indexer = None\n",
    "    evaluator = 'f1-macro'\n",
    "    opt = 'adam'\n",
    "    lr = 0.001 # in paper\n",
    "    lr_decay = 0.95\n",
    "    weight_decay = 5e-4\n",
    "    momentum = 0.95\n",
    "    patience = 4 # in paper\n",
    "    report_fn = '%s_report.txt' % get_datetime_str()\n",
    "    clip_grad = 5\n",
    "    save = '%s_tagger.hdf5' % get_datetime_str()\n",
    "    save_best = True\n",
    "    \n",
    "args = ARGS()\n",
    "print('> CONFIG DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b871186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.618732Z",
     "iopub.status.busy": "2023-12-02T02:57:22.618435Z",
     "iopub.status.idle": "2023-12-02T02:57:22.629299Z",
     "shell.execute_reply": "2023-12-02T02:57:22.628264Z"
    },
    "papermill": {
     "duration": 0.025432,
     "end_time": "2023-12-02T02:57:22.631251",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.605819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = args.seed):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c8db9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.656408Z",
     "iopub.status.busy": "2023-12-02T02:57:22.656122Z",
     "iopub.status.idle": "2023-12-02T02:57:22.677127Z",
     "shell.execute_reply": "2023-12-02T02:57:22.676319Z"
    },
    "papermill": {
     "duration": 0.035826,
     "end_time": "2023-12-02T02:57:22.679003",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.643177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if args.gpu >= 0:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "    \n",
    "    # Load text data as lists of lists of words (sequences) and corresponding list of lists of tags\n",
    "    data_io = DataIOFactory.create(args)\n",
    "    word_sequences_train, tag_sequences_train, word_sequences_dev, tag_sequences_dev, word_sequences_test, tag_sequences_test = data_io.read_train_dev_test(args)\n",
    "    \n",
    "    ## Dataset\n",
    "    datasets_bank = DatasetsBankFactory.create(args)\n",
    "    datasets_bank.add_train_sequences(word_sequences_train, tag_sequences_train)\n",
    "    datasets_bank.add_dev_sequences(word_sequences_dev, tag_sequences_dev)\n",
    "    datasets_bank.add_test_sequences(word_sequences_test, tag_sequences_test)\n",
    "    \n",
    "    # Word_seq_indexer converts lists of lists of words to lists of lists of integer indices and back\n",
    "    word_seq_indexer = SeqIndexerWord(gpu=args.gpu, check_for_lowercase=args.check_for_lowercase,\n",
    "                                      embeddings_dim=args.emb_dim, verbose=True)\n",
    "    word_seq_indexer.load_items_from_embeddings_file_and_unique_words_list(emb_fn=args.emb_fn,\n",
    "                                                                           emb_delimiter=args.emb_delimiter,\n",
    "                                                                           emb_load_all=args.emb_load_all,\n",
    "                                                                           unique_words_list=datasets_bank.unique_words_list)\n",
    "\n",
    "    \n",
    "    if args.word_seq_indexer is not None and not isfile(args.word_seq_indexer):\n",
    "        torch.save(word_seq_indexer, args.word_seq_indexer)\n",
    "    # Tag_seq_indexer converts lists of lists of tags to lists of lists of integer indices and back\n",
    "    tag_seq_indexer = SeqIndexerTag(gpu=args.gpu)\n",
    "    tag_seq_indexer.load_items_from_tag_sequences(tag_sequences_train)\n",
    "    # Create or load pre-trained tagger\n",
    "    if args.load is None:\n",
    "        tagger = TaggerFactory.create(args, word_seq_indexer, tag_seq_indexer, tag_sequences_train)\n",
    "    else:\n",
    "        tagger = TaggerFactory.load(args.load, args.gpu)\n",
    "    # Create evaluator\n",
    "    evaluator = EvaluatorFactory.create(args)\n",
    "    # Create optimizer\n",
    "    optimizer, scheduler = OptimizerFactory.create(args, tagger)\n",
    "    # Prepare report and temporary variables for \"save best\" strategy\n",
    "    report = Report(args.report_fn, args, score_names=('train loss', '%s-train' % args.evaluator,\n",
    "                                                       '%s-dev' % args.evaluator, '%s-test' % args.evaluator))\n",
    "    # Initialize training variables\n",
    "    iterations_num = floor(datasets_bank.train_data_num / args.batch_size)\n",
    "    best_dev_score = -1\n",
    "    best_epoch = -1\n",
    "    best_test_score = -1\n",
    "    best_test_msg = 'N\\A'\n",
    "    patience_counter = 0\n",
    "    print('\\nStart training...\\n')\n",
    "    for epoch in range(0, args.epoch_num + 1):\n",
    "        time_start = time.time()\n",
    "        loss_sum = 0\n",
    "        if epoch > 0:\n",
    "            tagger.train()\n",
    "            if args.lr_decay > 0:\n",
    "                scheduler.step()\n",
    "            for i, (word_sequences_train_batch, tag_sequences_train_batch) in \\\n",
    "                    enumerate(datasets_bank.get_train_batches(args.batch_size)):\n",
    "                tagger.train()\n",
    "                tagger.zero_grad()\n",
    "                loss = tagger.get_loss(word_sequences_train_batch, tag_sequences_train_batch)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(tagger.parameters(), args.clip_grad)\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item()\n",
    "                if i % 1 == 0:\n",
    "                    print('\\r-- train epoch %d/%d, batch %d/%d (%1.2f%%), loss = %1.2f.' % (epoch, args.epoch_num,\n",
    "                                                                                         i + 1, iterations_num,\n",
    "                                                                                         ceil(i*100.0/iterations_num),\n",
    "                                                                                         loss_sum*100 / iterations_num),\n",
    "                                                                                         end='', flush=True)\n",
    "        # Evaluate tagger\n",
    "        train_score, dev_score, test_score, test_msg = evaluator.get_evaluation_score_train_dev_test(tagger,\n",
    "                                                                                                     datasets_bank,\n",
    "                                                                                                     batch_size=100)\n",
    "        print('\\n== eval epoch %d/%d \"%s\" train / dev / test | %1.2f / %1.2f / %1.2f.' % (epoch, args.epoch_num,\n",
    "                                                                                        args.evaluator, train_score,\n",
    "                                                                                        dev_score, test_score))\n",
    "        report.write_epoch_scores(epoch, (loss_sum*100 / iterations_num, train_score, dev_score, test_score))\n",
    "        # Early stopping\n",
    "        if dev_score > best_dev_score:\n",
    "            best_dev_score = dev_score\n",
    "            best_test_score = test_score\n",
    "            best_epoch = epoch\n",
    "            best_test_msg = test_msg\n",
    "            patience_counter = 0\n",
    "            if args.save is not None and args.save_best:\n",
    "                tagger.save_tagger(args.save)\n",
    "            print('## [BEST epoch], %d seconds.\\n' % (time.time() - time_start))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print('## [no improvement micro-f1 on DEV during the last %d epochs (best_f1_dev=%1.2f), %d seconds].\\n' %\n",
    "                                                                                            (patience_counter,\n",
    "                                                                                             best_dev_score,\n",
    "                                                                                             (time.time()-time_start)))\n",
    "        if patience_counter > args.patience and epoch > args.min_epoch_num:\n",
    "            break\n",
    "    # Save final trained tagger to disk, if it is not already saved according to \"save best\"\n",
    "    if args.save is not None and not args.save_best:\n",
    "        tagger.save_tagger(args.save)\n",
    "    # Show and save the final scores\n",
    "    if args.save_best:\n",
    "        report.write_final_score('Final eval on test, \"save best\", best epoch on dev %d, %s, test = %1.2f)' %\n",
    "                                 (best_epoch, args.evaluator, best_test_score))\n",
    "        report.write_msg(best_test_msg)\n",
    "        report.write_input_arguments()\n",
    "        report.write_final_line_score(best_test_score)\n",
    "    else:\n",
    "        report.write_final_score('Final eval on test, %s test = %1.2f)' % (args.evaluator, test_score))\n",
    "        report.write_msg(test_msg)\n",
    "        report.write_input_arguments()\n",
    "        report.write_final_line_score(test_score)\n",
    "    if args.verbose:\n",
    "        report.make_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26c4da5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:57:22.703905Z",
     "iopub.status.busy": "2023-12-02T02:57:22.703613Z",
     "iopub.status.idle": "2023-12-02T06:11:55.910582Z",
     "shell.execute_reply": "2023-12-02T06:11:55.909629Z"
    },
    "papermill": {
     "duration": 11673.222047,
     "end_time": "2023-12-02T06:11:55.913033",
     "exception": false,
     "start_time": "2023-12-02T02:57:22.690986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c1a5aea6464fa384fb4f4dbf344041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b2d1c988c94e3195e09b3ea86ba923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ncbi_disease/ncbi_disease (download: 1.47 MiB, generated: 3.04 MiB, post-processed: Unknown size, total: 4.52 MiB) to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898f44ae973e48dbaf00c135b28779a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a305f2fb78470cbfdd61481c97a855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53abf1d1e6244f3bcf64d98e8c27313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1c6cc49cfb478f92dd30d9a72e8347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a1844794dd40b38e98865c6d61caef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab713d1a9aa24cc386a42f60b8ffc63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d20499968946d1a5f1ef242825f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/924 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75759dcb170a4cbca55381eadcacbc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ncbi_disease downloaded and prepared to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df814bd695f341f9808e7459a9f3919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from train: 5432 samples, 136086 words.\n",
      "Loading from validation: 923 samples, 23969 words.\n",
      "Loading from test: 940 samples, 24497 words.\n",
      "DatasetsBank: len(unique_words_list) = 9284 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 10056 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 10818 unique words.\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 0\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 100000\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 200000\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 300000\n",
      "\n",
      "load_vocabulary_from_embeddings_file_and_unique_words_list:\n",
      "    First 50 OOV words:\n",
      "        out_of_vocabulary_words_list[0] = APC2\n",
      "        out_of_vocabulary_words_list[1] = 3beta\n",
      "        out_of_vocabulary_words_list[2] = axin\n",
      "        out_of_vocabulary_words_list[3] = conductin\n",
      "        out_of_vocabulary_words_list[4] = betacatenin\n",
      "        out_of_vocabulary_words_list[5] = 19p13\n",
      "        out_of_vocabulary_words_list[6] = MSH2\n",
      "        out_of_vocabulary_words_list[7] = nt943\n",
      "        out_of_vocabulary_words_list[8] = D2S288\n",
      "        out_of_vocabulary_words_list[9] = penetrances\n",
      "        out_of_vocabulary_words_list[10] = epsilon2epsilon3\n",
      "        out_of_vocabulary_words_list[11] = bacteremic\n",
      "        out_of_vocabulary_words_list[12] = gonococcal\n",
      "        out_of_vocabulary_words_list[13] = immunochemical\n",
      "        out_of_vocabulary_words_list[14] = Opsonization\n",
      "        out_of_vocabulary_words_list[15] = nonaffected\n",
      "        out_of_vocabulary_words_list[16] = dihydropyrimidine\n",
      "        out_of_vocabulary_words_list[17] = Dihydropyrimidine\n",
      "        out_of_vocabulary_words_list[18] = uraciluria\n",
      "        out_of_vocabulary_words_list[19] = 298delTCAT\n",
      "        out_of_vocabulary_words_list[20] = 1897delC\n",
      "        out_of_vocabulary_words_list[21] = IVS14\n",
      "        out_of_vocabulary_words_list[22] = 85T\n",
      "        out_of_vocabulary_words_list[23] = 703C\n",
      "        out_of_vocabulary_words_list[24] = 2658G\n",
      "        out_of_vocabulary_words_list[25] = 2983G\n",
      "        out_of_vocabulary_words_list[26] = FHF2\n",
      "        out_of_vocabulary_words_list[27] = Borjeson\n",
      "        out_of_vocabulary_words_list[28] = Forssman\n",
      "        out_of_vocabulary_words_list[29] = Xq26\n",
      "        out_of_vocabulary_words_list[30] = BFLS\n",
      "        out_of_vocabulary_words_list[31] = syndromal\n",
      "        out_of_vocabulary_words_list[32] = q26\n",
      "        out_of_vocabulary_words_list[33] = q26q28\n",
      "        out_of_vocabulary_words_list[34] = DXS155\n",
      "        out_of_vocabulary_words_list[35] = DXS294\n",
      "        out_of_vocabulary_words_list[36] = DXS730\n",
      "        out_of_vocabulary_words_list[37] = SSCP\n",
      "        out_of_vocabulary_words_list[38] = Drash\n",
      "        out_of_vocabulary_words_list[39] = nonneoplastic\n",
      "        out_of_vocabulary_words_list[40] = pseudohermaphroditism\n",
      "        out_of_vocabulary_words_list[41] = exonic\n",
      "        out_of_vocabulary_words_list[42] = tmT396\n",
      "        out_of_vocabulary_words_list[43] = ZF3\n",
      "        out_of_vocabulary_words_list[44] = nontargeted\n",
      "        out_of_vocabulary_words_list[45] = DMT1\n",
      "        out_of_vocabulary_words_list[46] = saturations\n",
      "        out_of_vocabulary_words_list[47] = quantitated\n",
      "        out_of_vocabulary_words_list[48] = Neurophysiologic\n",
      "        out_of_vocabulary_words_list[49] = axonopathy\n",
      "        out_of_vocabulary_words_list[50] = Lorenzos\n",
      " -- len(out_of_vocabulary_words_list) = 2179\n",
      " -- original_words_num = 6458\n",
      " -- lowercase_words_num = 2138\n",
      " -- zero_digits_replaced_num = 42\n",
      " -- zero_digits_replaced_lowercase_num = 1\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 3\n",
      " -- {'<pad>': 0, 0: 1, 1: 2, 2: 3}\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         0         1         2     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0\n",
      "         0       0.0  114616.0    2263.0    2859.0    5081.0\n",
      "         1       0.0    4780.0       1.0      13.0     351.0\n",
      "         2       0.0       0.0    2879.0    3243.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         0         1         2     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         0   -9999.0      -1.1      -1.0      -1.1      -1.1\n",
      "         1   -9999.0      -0.8      -1.1      -0.9      -1.1\n",
      "         2   -9999.0   -9999.0      -0.9      -1.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 60.89\n",
      "              1 = 7.05\n",
      "              2 = 1.50\n",
      "------------------------\n",
      "Macro-F1 = 23.144\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 61.23\n",
      "              1 = 6.25\n",
      "              2 = 1.35\n",
      "------------------------\n",
      "Macro-F1 = 22.943\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 61.09\n",
      "              1 = 7.54\n",
      "              2 = 2.62\n",
      "------------------------\n",
      "Macro-F1 = 23.749\n",
      "\n",
      "== eval epoch 0/40 \"f1-macro\" train / dev / test | 23.14 / 22.94 / 23.75.\n",
      "## [BEST epoch], 24 seconds.\n",
      "\n",
      "-- train epoch 1/40, batch 339/339 (100.00%), loss = 349.11.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.03\n",
      "              1 = 20.90\n",
      "              2 = 11.98\n",
      "------------------------\n",
      "Macro-F1 = 42.971\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.10\n",
      "              1 = 13.57\n",
      "              2 = 7.22\n",
      "------------------------\n",
      "Macro-F1 = 38.963\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 95.98\n",
      "              1 = 19.38\n",
      "              2 = 12.96\n",
      "------------------------\n",
      "Macro-F1 = 42.775\n",
      "\n",
      "== eval epoch 1/40 \"f1-macro\" train / dev / test | 42.97 / 38.96 / 42.77.\n",
      "## [BEST epoch], 272 seconds.\n",
      "\n",
      "-- train epoch 2/40, batch 339/339 (100.00%), loss = 203.55.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.79\n",
      "              1 = 57.42\n",
      "              2 = 52.45\n",
      "------------------------\n",
      "Macro-F1 = 68.886\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.18\n",
      "              1 = 52.12\n",
      "              2 = 60.64\n",
      "------------------------\n",
      "Macro-F1 = 69.980\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.64\n",
      "              1 = 54.45\n",
      "              2 = 51.70\n",
      "------------------------\n",
      "Macro-F1 = 67.593\n",
      "\n",
      "== eval epoch 2/40 \"f1-macro\" train / dev / test | 68.89 / 69.98 / 67.59.\n",
      "## [BEST epoch], 261 seconds.\n",
      "\n",
      "-- train epoch 3/40, batch 339/339 (100.00%), loss = 165.07.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.40\n",
      "              1 = 55.50\n",
      "              2 = 51.48\n",
      "------------------------\n",
      "Macro-F1 = 68.127\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.70\n",
      "              1 = 50.63\n",
      "              2 = 56.02\n",
      "------------------------\n",
      "Macro-F1 = 68.114\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.33\n",
      "              1 = 53.51\n",
      "              2 = 49.32\n",
      "------------------------\n",
      "Macro-F1 = 66.720\n",
      "\n",
      "== eval epoch 3/40 \"f1-macro\" train / dev / test | 68.13 / 68.11 / 66.72.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=69.98), 270 seconds].\n",
      "\n",
      "-- train epoch 4/40, batch 339/339 (100.00%), loss = 151.14.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.36\n",
      "              1 = 56.42\n",
      "              2 = 56.21\n",
      "------------------------\n",
      "Macro-F1 = 69.995\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.69\n",
      "              1 = 52.36\n",
      "              2 = 59.61\n",
      "------------------------\n",
      "Macro-F1 = 69.889\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.41\n",
      "              1 = 54.69\n",
      "              2 = 57.34\n",
      "------------------------\n",
      "Macro-F1 = 69.812\n",
      "\n",
      "== eval epoch 4/40 \"f1-macro\" train / dev / test | 70.00 / 69.89 / 69.81.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=69.98), 284 seconds].\n",
      "\n",
      "-- train epoch 5/40, batch 339/339 (100.00%), loss = 140.66.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.74\n",
      "              1 = 65.23\n",
      "              2 = 60.91\n",
      "------------------------\n",
      "Macro-F1 = 74.625\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.96\n",
      "              1 = 58.93\n",
      "              2 = 60.62\n",
      "------------------------\n",
      "Macro-F1 = 72.503\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.60\n",
      "              1 = 62.18\n",
      "              2 = 58.88\n",
      "------------------------\n",
      "Macro-F1 = 72.887\n",
      "\n",
      "== eval epoch 5/40 \"f1-macro\" train / dev / test | 74.62 / 72.50 / 72.89.\n",
      "## [BEST epoch], 302 seconds.\n",
      "\n",
      "-- train epoch 6/40, batch 339/339 (100.00%), loss = 103.58.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.48\n",
      "              1 = 65.09\n",
      "              2 = 61.17\n",
      "------------------------\n",
      "Macro-F1 = 74.580\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.41\n",
      "              1 = 55.63\n",
      "              2 = 60.62\n",
      "------------------------\n",
      "Macro-F1 = 71.220\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.32\n",
      "              1 = 61.63\n",
      "              2 = 56.87\n",
      "------------------------\n",
      "Macro-F1 = 71.939\n",
      "\n",
      "== eval epoch 6/40 \"f1-macro\" train / dev / test | 74.58 / 71.22 / 71.94.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=72.50), 275 seconds].\n",
      "\n",
      "-- train epoch 7/40, batch 339/339 (100.00%), loss = 147.55.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.53\n",
      "              1 = 68.68\n",
      "              2 = 63.30\n",
      "------------------------\n",
      "Macro-F1 = 76.507\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.63\n",
      "              1 = 59.47\n",
      "              2 = 66.27\n",
      "------------------------\n",
      "Macro-F1 = 74.459\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.42\n",
      "              1 = 64.08\n",
      "              2 = 60.59\n",
      "------------------------\n",
      "Macro-F1 = 74.028\n",
      "\n",
      "== eval epoch 7/40 \"f1-macro\" train / dev / test | 76.51 / 74.46 / 74.03.\n",
      "## [BEST epoch], 312 seconds.\n",
      "\n",
      "-- train epoch 8/40, batch 339/339 (100.00%), loss = 121.09.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.02\n",
      "              1 = 71.62\n",
      "              2 = 64.09\n",
      "------------------------\n",
      "Macro-F1 = 77.912\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.13\n",
      "              1 = 64.78\n",
      "              2 = 66.32\n",
      "------------------------\n",
      "Macro-F1 = 76.410\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.76\n",
      "              1 = 65.66\n",
      "              2 = 59.68\n",
      "------------------------\n",
      "Macro-F1 = 74.366\n",
      "\n",
      "== eval epoch 8/40 \"f1-macro\" train / dev / test | 77.91 / 76.41 / 74.37.\n",
      "## [BEST epoch], 272 seconds.\n",
      "\n",
      "-- train epoch 9/40, batch 339/339 (100.00%), loss = 120.97.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.44\n",
      "              1 = 60.88\n",
      "              2 = 63.63\n",
      "------------------------\n",
      "Macro-F1 = 73.984\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.30\n",
      "              1 = 54.12\n",
      "              2 = 61.92\n",
      "------------------------\n",
      "Macro-F1 = 71.109\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.29\n",
      "              1 = 61.59\n",
      "              2 = 62.33\n",
      "------------------------\n",
      "Macro-F1 = 73.737\n",
      "\n",
      "== eval epoch 9/40 \"f1-macro\" train / dev / test | 73.98 / 71.11 / 73.74.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.41), 275 seconds].\n",
      "\n",
      "-- train epoch 10/40, batch 339/339 (100.00%), loss = 120.89.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.67\n",
      "              1 = 69.21\n",
      "              2 = 64.08\n",
      "------------------------\n",
      "Macro-F1 = 76.988\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.79\n",
      "              1 = 63.42\n",
      "              2 = 67.82\n",
      "------------------------\n",
      "Macro-F1 = 76.341\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.17\n",
      "              1 = 62.44\n",
      "              2 = 57.37\n",
      "------------------------\n",
      "Macro-F1 = 72.323\n",
      "\n",
      "== eval epoch 10/40 \"f1-macro\" train / dev / test | 76.99 / 76.34 / 72.32.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=76.41), 284 seconds].\n",
      "\n",
      "-- train epoch 11/40, batch 339/339 (100.00%), loss = 113.42.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.83\n",
      "              1 = 70.96\n",
      "              2 = 66.62\n",
      "------------------------\n",
      "Macro-F1 = 78.471\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.15\n",
      "              1 = 68.77\n",
      "              2 = 73.26\n",
      "------------------------\n",
      "Macro-F1 = 80.062\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.79\n",
      "              1 = 68.20\n",
      "              2 = 64.21\n",
      "------------------------\n",
      "Macro-F1 = 76.735\n",
      "\n",
      "== eval epoch 11/40 \"f1-macro\" train / dev / test | 78.47 / 80.06 / 76.74.\n",
      "## [BEST epoch], 283 seconds.\n",
      "\n",
      "-- train epoch 12/40, batch 339/339 (100.00%), loss = 86.82.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.97\n",
      "              1 = 70.86\n",
      "              2 = 63.73\n",
      "------------------------\n",
      "Macro-F1 = 77.519\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.22\n",
      "              1 = 65.51\n",
      "              2 = 66.13\n",
      "------------------------\n",
      "Macro-F1 = 76.622\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.85\n",
      "              1 = 67.95\n",
      "              2 = 61.58\n",
      "------------------------\n",
      "Macro-F1 = 75.793\n",
      "\n",
      "== eval epoch 12/40 \"f1-macro\" train / dev / test | 77.52 / 76.62 / 75.79.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.06), 299 seconds].\n",
      "\n",
      "-- train epoch 13/40, batch 339/339 (100.00%), loss = 110.25.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.09\n",
      "              1 = 75.19\n",
      "              2 = 71.64\n",
      "------------------------\n",
      "Macro-F1 = 81.637\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.42\n",
      "              1 = 71.09\n",
      "              2 = 76.83\n",
      "------------------------\n",
      "Macro-F1 = 82.112\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.03\n",
      "              1 = 72.35\n",
      "              2 = 70.77\n",
      "------------------------\n",
      "Macro-F1 = 80.386\n",
      "\n",
      "== eval epoch 13/40 \"f1-macro\" train / dev / test | 81.64 / 82.11 / 80.39.\n",
      "## [BEST epoch], 278 seconds.\n",
      "\n",
      "-- train epoch 14/40, batch 339/339 (100.00%), loss = 93.98.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.20\n",
      "              1 = 73.24\n",
      "              2 = 61.48\n",
      "------------------------\n",
      "Macro-F1 = 77.305\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.62\n",
      "              1 = 70.63\n",
      "              2 = 65.74\n",
      "------------------------\n",
      "Macro-F1 = 77.995\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.47\n",
      "              1 = 70.42\n",
      "              2 = 61.51\n",
      "------------------------\n",
      "Macro-F1 = 76.469\n",
      "\n",
      "== eval epoch 14/40 \"f1-macro\" train / dev / test | 77.30 / 78.00 / 76.47.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.11), 278 seconds].\n",
      "\n",
      "-- train epoch 15/40, batch 339/339 (100.00%), loss = 85.22.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.11\n",
      "              1 = 73.97\n",
      "              2 = 73.32\n",
      "------------------------\n",
      "Macro-F1 = 81.801\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.18\n",
      "              1 = 65.24\n",
      "              2 = 74.05\n",
      "------------------------\n",
      "Macro-F1 = 79.155\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.83\n",
      "              1 = 69.31\n",
      "              2 = 66.76\n",
      "------------------------\n",
      "Macro-F1 = 77.966\n",
      "\n",
      "== eval epoch 15/40 \"f1-macro\" train / dev / test | 81.80 / 79.15 / 77.97.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.11), 308 seconds].\n",
      "\n",
      "-- train epoch 16/40, batch 339/339 (100.00%), loss = 89.44.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.62\n",
      "              1 = 73.56\n",
      "              2 = 68.36\n",
      "------------------------\n",
      "Macro-F1 = 79.844\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.61\n",
      "              1 = 67.78\n",
      "              2 = 65.60\n",
      "------------------------\n",
      "Macro-F1 = 76.998\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.20\n",
      "              1 = 67.67\n",
      "              2 = 63.13\n",
      "------------------------\n",
      "Macro-F1 = 76.002\n",
      "\n",
      "== eval epoch 16/40 \"f1-macro\" train / dev / test | 79.84 / 77.00 / 76.00.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.11), 307 seconds].\n",
      "\n",
      "-- train epoch 17/40, batch 339/339 (100.00%), loss = 70.55.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.14\n",
      "              1 = 74.20\n",
      "              2 = 70.62\n",
      "------------------------\n",
      "Macro-F1 = 80.985\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.18\n",
      "              1 = 68.79\n",
      "              2 = 70.47\n",
      "------------------------\n",
      "Macro-F1 = 79.143\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.91\n",
      "              1 = 70.15\n",
      "              2 = 66.06\n",
      "------------------------\n",
      "Macro-F1 = 78.041\n",
      "\n",
      "== eval epoch 17/40 \"f1-macro\" train / dev / test | 80.99 / 79.14 / 78.04.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.11), 271 seconds].\n",
      "\n",
      "-- train epoch 18/40, batch 339/339 (100.00%), loss = 75.42.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.29\n",
      "              1 = 76.34\n",
      "              2 = 73.75\n",
      "------------------------\n",
      "Macro-F1 = 82.795\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.51\n",
      "              1 = 74.61\n",
      "              2 = 77.49\n",
      "------------------------\n",
      "Macro-F1 = 83.536\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.01\n",
      "              1 = 70.59\n",
      "              2 = 69.82\n",
      "------------------------\n",
      "Macro-F1 = 79.477\n",
      "\n",
      "== eval epoch 18/40 \"f1-macro\" train / dev / test | 82.80 / 83.54 / 79.48.\n",
      "## [BEST epoch], 295 seconds.\n",
      "\n",
      "-- train epoch 19/40, batch 339/339 (100.00%), loss = 90.05.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.54\n",
      "              1 = 79.04\n",
      "              2 = 76.25\n",
      "------------------------\n",
      "Macro-F1 = 84.608\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.60\n",
      "              1 = 73.04\n",
      "              2 = 76.79\n",
      "------------------------\n",
      "Macro-F1 = 82.809\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.19\n",
      "              1 = 70.59\n",
      "              2 = 70.88\n",
      "------------------------\n",
      "Macro-F1 = 79.889\n",
      "\n",
      "== eval epoch 19/40 \"f1-macro\" train / dev / test | 84.61 / 82.81 / 79.89.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.54), 317 seconds].\n",
      "\n",
      "-- train epoch 20/40, batch 339/339 (100.00%), loss = 84.65.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.89\n",
      "              1 = 77.48\n",
      "              2 = 71.37\n",
      "------------------------\n",
      "Macro-F1 = 82.249\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.05\n",
      "              1 = 72.91\n",
      "              2 = 74.17\n",
      "------------------------\n",
      "Macro-F1 = 81.710\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.49\n",
      "              1 = 73.45\n",
      "              2 = 65.96\n",
      "------------------------\n",
      "Macro-F1 = 78.969\n",
      "\n",
      "== eval epoch 20/40 \"f1-macro\" train / dev / test | 82.25 / 81.71 / 78.97.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.54), 278 seconds].\n",
      "\n",
      "-- train epoch 21/40, batch 339/339 (100.00%), loss = 64.07.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.68\n",
      "              1 = 81.78\n",
      "              2 = 79.16\n",
      "------------------------\n",
      "Macro-F1 = 86.538\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.60\n",
      "              1 = 74.56\n",
      "              2 = 76.92\n",
      "------------------------\n",
      "Macro-F1 = 83.359\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.39\n",
      "              1 = 75.35\n",
      "              2 = 74.32\n",
      "------------------------\n",
      "Macro-F1 = 82.688\n",
      "\n",
      "== eval epoch 21/40 \"f1-macro\" train / dev / test | 86.54 / 83.36 / 82.69.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=83.54), 289 seconds].\n",
      "\n",
      "-- train epoch 22/40, batch 339/339 (100.00%), loss = 81.76.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.68\n",
      "              1 = 81.64\n",
      "              2 = 79.98\n",
      "------------------------\n",
      "Macro-F1 = 86.769\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.62\n",
      "              1 = 73.53\n",
      "              2 = 79.40\n",
      "------------------------\n",
      "Macro-F1 = 83.851\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.30\n",
      "              1 = 74.45\n",
      "              2 = 74.68\n",
      "------------------------\n",
      "Macro-F1 = 82.475\n",
      "\n",
      "== eval epoch 22/40 \"f1-macro\" train / dev / test | 86.77 / 83.85 / 82.48.\n",
      "## [BEST epoch], 311 seconds.\n",
      "\n",
      "-- train epoch 23/40, batch 339/339 (100.00%), loss = 80.23.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.48\n",
      "              1 = 78.70\n",
      "              2 = 75.20\n",
      "------------------------\n",
      "Macro-F1 = 84.128\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.62\n",
      "              1 = 75.12\n",
      "              2 = 77.53\n",
      "------------------------\n",
      "Macro-F1 = 83.755\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.18\n",
      "              1 = 72.24\n",
      "              2 = 69.36\n",
      "------------------------\n",
      "Macro-F1 = 79.928\n",
      "\n",
      "== eval epoch 23/40 \"f1-macro\" train / dev / test | 84.13 / 83.76 / 79.93.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.85), 297 seconds].\n",
      "\n",
      "-- train epoch 24/40, batch 339/339 (100.00%), loss = 63.96.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.54\n",
      "              1 = 77.90\n",
      "              2 = 78.82\n",
      "------------------------\n",
      "Macro-F1 = 85.088\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.48\n",
      "              1 = 69.90\n",
      "              2 = 77.76\n",
      "------------------------\n",
      "Macro-F1 = 82.046\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.05\n",
      "              1 = 68.95\n",
      "              2 = 71.58\n",
      "------------------------\n",
      "Macro-F1 = 79.529\n",
      "\n",
      "== eval epoch 24/40 \"f1-macro\" train / dev / test | 85.09 / 82.05 / 79.53.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.85), 296 seconds].\n",
      "\n",
      "-- train epoch 25/40, batch 339/339 (100.00%), loss = 56.99.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.32\n",
      "              1 = 76.72\n",
      "              2 = 71.39\n",
      "------------------------\n",
      "Macro-F1 = 82.143\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.44\n",
      "              1 = 69.72\n",
      "              2 = 72.60\n",
      "------------------------\n",
      "Macro-F1 = 80.250\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.13\n",
      "              1 = 72.82\n",
      "              2 = 68.47\n",
      "------------------------\n",
      "Macro-F1 = 79.805\n",
      "\n",
      "== eval epoch 25/40 \"f1-macro\" train / dev / test | 82.14 / 80.25 / 79.80.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=83.85), 285 seconds].\n",
      "\n",
      "-- train epoch 26/40, batch 339/339 (100.00%), loss = 51.88.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.68\n",
      "              1 = 81.37\n",
      "              2 = 80.13\n",
      "------------------------\n",
      "Macro-F1 = 86.728\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.67\n",
      "              1 = 76.27\n",
      "              2 = 79.92\n",
      "------------------------\n",
      "Macro-F1 = 84.955\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.15\n",
      "              1 = 73.60\n",
      "              2 = 72.69\n",
      "------------------------\n",
      "Macro-F1 = 81.480\n",
      "\n",
      "== eval epoch 26/40 \"f1-macro\" train / dev / test | 86.73 / 84.95 / 81.48.\n",
      "## [BEST epoch], 291 seconds.\n",
      "\n",
      "-- train epoch 27/40, batch 339/339 (100.00%), loss = 52.14.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.45\n",
      "              1 = 80.21\n",
      "              2 = 74.49\n",
      "------------------------\n",
      "Macro-F1 = 84.383\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.63\n",
      "              1 = 76.85\n",
      "              2 = 78.77\n",
      "------------------------\n",
      "Macro-F1 = 84.752\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.15\n",
      "              1 = 73.30\n",
      "              2 = 69.95\n",
      "------------------------\n",
      "Macro-F1 = 80.467\n",
      "\n",
      "== eval epoch 27/40 \"f1-macro\" train / dev / test | 84.38 / 84.75 / 80.47.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=84.95), 292 seconds].\n",
      "\n",
      "-- train epoch 28/40, batch 339/339 (100.00%), loss = 69.62.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.72\n",
      "              1 = 81.98\n",
      "              2 = 79.58\n",
      "------------------------\n",
      "Macro-F1 = 86.762\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.73\n",
      "              1 = 76.56\n",
      "              2 = 78.62\n",
      "------------------------\n",
      "Macro-F1 = 84.636\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.43\n",
      "              1 = 76.58\n",
      "              2 = 74.33\n",
      "------------------------\n",
      "Macro-F1 = 83.112\n",
      "\n",
      "== eval epoch 28/40 \"f1-macro\" train / dev / test | 86.76 / 84.64 / 83.11.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=84.95), 291 seconds].\n",
      "\n",
      "-- train epoch 29/40, batch 339/339 (100.00%), loss = 58.78.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.63\n",
      "              1 = 80.30\n",
      "              2 = 77.18\n",
      "------------------------\n",
      "Macro-F1 = 85.368\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.62\n",
      "              1 = 72.18\n",
      "              2 = 75.43\n",
      "------------------------\n",
      "Macro-F1 = 82.076\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.40\n",
      "              1 = 74.91\n",
      "              2 = 74.11\n",
      "------------------------\n",
      "Macro-F1 = 82.471\n",
      "\n",
      "== eval epoch 29/40 \"f1-macro\" train / dev / test | 85.37 / 82.08 / 82.47.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=84.95), 261 seconds].\n",
      "\n",
      "-- train epoch 30/40, batch 339/339 (100.00%), loss = 57.39.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.72\n",
      "              1 = 81.86\n",
      "              2 = 80.18\n",
      "------------------------\n",
      "Macro-F1 = 86.922\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.60\n",
      "              1 = 74.04\n",
      "              2 = 77.67\n",
      "------------------------\n",
      "Macro-F1 = 83.437\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.23\n",
      "              1 = 73.56\n",
      "              2 = 72.30\n",
      "------------------------\n",
      "Macro-F1 = 81.363\n",
      "\n",
      "== eval epoch 30/40 \"f1-macro\" train / dev / test | 86.92 / 83.44 / 81.36.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=84.95), 308 seconds].\n",
      "\n",
      "-- train epoch 31/40, batch 339/339 (100.00%), loss = 63.50.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.67\n",
      "              1 = 80.36\n",
      "              2 = 81.42\n",
      "------------------------\n",
      "Macro-F1 = 86.815\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.79\n",
      "              1 = 77.09\n",
      "              2 = 82.70\n",
      "------------------------\n",
      "Macro-F1 = 86.195\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.28\n",
      "              1 = 72.69\n",
      "              2 = 76.52\n",
      "------------------------\n",
      "Macro-F1 = 82.492\n",
      "\n",
      "== eval epoch 31/40 \"f1-macro\" train / dev / test | 86.81 / 86.19 / 82.49.\n",
      "## [BEST epoch], 288 seconds.\n",
      "\n",
      "-- train epoch 32/40, batch 339/339 (100.00%), loss = 44.75.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.86\n",
      "              1 = 84.24\n",
      "              2 = 81.46\n",
      "------------------------\n",
      "Macro-F1 = 88.190\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.79\n",
      "              1 = 76.80\n",
      "              2 = 80.08\n",
      "------------------------\n",
      "Macro-F1 = 85.226\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.44\n",
      "              1 = 76.00\n",
      "              2 = 74.02\n",
      "------------------------\n",
      "Macro-F1 = 82.822\n",
      "\n",
      "== eval epoch 32/40 \"f1-macro\" train / dev / test | 88.19 / 85.23 / 82.82.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=86.19), 287 seconds].\n",
      "\n",
      "-- train epoch 33/40, batch 339/339 (100.00%), loss = 54.94.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.93\n",
      "              1 = 84.44\n",
      "              2 = 84.61\n",
      "------------------------\n",
      "Macro-F1 = 89.326\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.77\n",
      "              1 = 77.56\n",
      "              2 = 83.16\n",
      "------------------------\n",
      "Macro-F1 = 86.495\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.24\n",
      "              1 = 76.02\n",
      "              2 = 75.54\n",
      "------------------------\n",
      "Macro-F1 = 83.265\n",
      "\n",
      "== eval epoch 33/40 \"f1-macro\" train / dev / test | 89.33 / 86.50 / 83.26.\n",
      "## [BEST epoch], 277 seconds.\n",
      "\n",
      "-- train epoch 34/40, batch 339/339 (100.00%), loss = 54.41.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.93\n",
      "              1 = 84.70\n",
      "              2 = 83.66\n",
      "------------------------\n",
      "Macro-F1 = 89.095\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.84\n",
      "              1 = 77.14\n",
      "              2 = 82.65\n",
      "------------------------\n",
      "Macro-F1 = 86.212\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.51\n",
      "              1 = 77.55\n",
      "              2 = 76.58\n",
      "------------------------\n",
      "Macro-F1 = 84.212\n",
      "\n",
      "== eval epoch 34/40 \"f1-macro\" train / dev / test | 89.10 / 86.21 / 84.21.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=86.50), 273 seconds].\n",
      "\n",
      "-- train epoch 35/40, batch 339/339 (100.00%), loss = 55.63.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.95\n",
      "              1 = 85.25\n",
      "              2 = 84.15\n",
      "------------------------\n",
      "Macro-F1 = 89.451\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.88\n",
      "              1 = 77.14\n",
      "              2 = 83.21\n",
      "------------------------\n",
      "Macro-F1 = 86.407\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.57\n",
      "              1 = 78.47\n",
      "              2 = 78.99\n",
      "------------------------\n",
      "Macro-F1 = 85.342\n",
      "\n",
      "== eval epoch 35/40 \"f1-macro\" train / dev / test | 89.45 / 86.41 / 85.34.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=86.50), 278 seconds].\n",
      "\n",
      "-- train epoch 36/40, batch 339/339 (100.00%), loss = 51.09.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.97\n",
      "              1 = 84.55\n",
      "              2 = 84.41\n",
      "------------------------\n",
      "Macro-F1 = 89.311\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.86\n",
      "              1 = 76.45\n",
      "              2 = 82.44\n",
      "------------------------\n",
      "Macro-F1 = 85.917\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.57\n",
      "              1 = 78.13\n",
      "              2 = 78.31\n",
      "------------------------\n",
      "Macro-F1 = 85.004\n",
      "\n",
      "== eval epoch 36/40 \"f1-macro\" train / dev / test | 89.31 / 85.92 / 85.00.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=86.50), 281 seconds].\n",
      "\n",
      "-- train epoch 37/40, batch 339/339 (100.00%), loss = 61.96.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 99.03\n",
      "              1 = 86.27\n",
      "              2 = 84.90\n",
      "------------------------\n",
      "Macro-F1 = 90.070\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.87\n",
      "              1 = 77.47\n",
      "              2 = 82.12\n",
      "------------------------\n",
      "Macro-F1 = 86.154\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.63\n",
      "              1 = 78.11\n",
      "              2 = 78.53\n",
      "------------------------\n",
      "Macro-F1 = 85.090\n",
      "\n",
      "== eval epoch 37/40 \"f1-macro\" train / dev / test | 90.07 / 86.15 / 85.09.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=86.50), 289 seconds].\n",
      "\n",
      "-- train epoch 38/40, batch 339/339 (100.00%), loss = 59.13.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 99.06\n",
      "              1 = 87.12\n",
      "              2 = 85.86\n",
      "------------------------\n",
      "Macro-F1 = 90.682\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.92\n",
      "              1 = 78.36\n",
      "              2 = 83.65\n",
      "------------------------\n",
      "Macro-F1 = 86.974\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.50\n",
      "              1 = 80.04\n",
      "              2 = 77.68\n",
      "------------------------\n",
      "Macro-F1 = 85.408\n",
      "\n",
      "== eval epoch 38/40 \"f1-macro\" train / dev / test | 90.68 / 86.97 / 85.41.\n",
      "## [BEST epoch], 276 seconds.\n",
      "\n",
      "-- train epoch 39/40, batch 339/339 (100.00%), loss = 58.46.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.60\n",
      "              1 = 80.80\n",
      "              2 = 75.90\n",
      "------------------------\n",
      "Macro-F1 = 85.104\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.79\n",
      "              1 = 75.84\n",
      "              2 = 80.26\n",
      "------------------------\n",
      "Macro-F1 = 84.965\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.44\n",
      "              1 = 76.30\n",
      "              2 = 73.31\n",
      "------------------------\n",
      "Macro-F1 = 82.684\n",
      "\n",
      "== eval epoch 39/40 \"f1-macro\" train / dev / test | 85.10 / 84.96 / 82.68.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=86.97), 295 seconds].\n",
      "\n",
      "-- train epoch 40/40, batch 339/339 (100.00%), loss = 63.38.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 99.08\n",
      "              1 = 87.21\n",
      "              2 = 86.61\n",
      "------------------------\n",
      "Macro-F1 = 90.967\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.95\n",
      "              1 = 79.35\n",
      "              2 = 85.20\n",
      "------------------------\n",
      "Macro-F1 = 87.836\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.64\n",
      "              1 = 79.51\n",
      "              2 = 80.43\n",
      "------------------------\n",
      "Macro-F1 = 86.194\n",
      "\n",
      "== eval epoch 40/40 \"f1-macro\" train / dev / test | 90.97 / 87.84 / 86.19.\n",
      "## [BEST epoch], 319 seconds.\n",
      "\n",
      "Evaluation\n",
      "\n",
      "<__main__.ARGS object at 0x7b0821b0f970>\n",
      "\n",
      "         epoch  |     train loss | f1-macro-train |   f1-macro-dev |  f1-macro-test \n",
      "--------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |          23.14 |          22.94 |          23.75 \n",
      "              1 |         349.11 |          42.97 |          38.96 |          42.77 \n",
      "              2 |         203.55 |          68.89 |          69.98 |          67.59 \n",
      "              3 |         165.07 |          68.13 |          68.11 |          66.72 \n",
      "              4 |         151.14 |          70.00 |          69.89 |          69.81 \n",
      "              5 |         140.66 |          74.62 |          72.50 |          72.89 \n",
      "              6 |         103.58 |          74.58 |          71.22 |          71.94 \n",
      "              7 |         147.55 |          76.51 |          74.46 |          74.03 \n",
      "              8 |         121.09 |          77.91 |          76.41 |          74.37 \n",
      "              9 |         120.97 |          73.98 |          71.11 |          73.74 \n",
      "             10 |         120.89 |          76.99 |          76.34 |          72.32 \n",
      "             11 |         113.42 |          78.47 |          80.06 |          76.74 \n",
      "             12 |          86.82 |          77.52 |          76.62 |          75.79 \n",
      "             13 |         110.25 |          81.64 |          82.11 |          80.39 \n",
      "             14 |          93.98 |          77.30 |          78.00 |          76.47 \n",
      "             15 |          85.22 |          81.80 |          79.15 |          77.97 \n",
      "             16 |          89.44 |          79.84 |          77.00 |          76.00 \n",
      "             17 |          70.55 |          80.99 |          79.14 |          78.04 \n",
      "             18 |          75.42 |          82.80 |          83.54 |          79.48 \n",
      "             19 |          90.05 |          84.61 |          82.81 |          79.89 \n",
      "             20 |          84.65 |          82.25 |          81.71 |          78.97 \n",
      "             21 |          64.07 |          86.54 |          83.36 |          82.69 \n",
      "             22 |          81.76 |          86.77 |          83.85 |          82.48 \n",
      "             23 |          80.23 |          84.13 |          83.76 |          79.93 \n",
      "             24 |          63.96 |          85.09 |          82.05 |          79.53 \n",
      "             25 |          56.99 |          82.14 |          80.25 |          79.80 \n",
      "             26 |          51.88 |          86.73 |          84.95 |          81.48 \n",
      "             27 |          52.14 |          84.38 |          84.75 |          80.47 \n",
      "             28 |          69.62 |          86.76 |          84.64 |          83.11 \n",
      "             29 |          58.78 |          85.37 |          82.08 |          82.47 \n",
      "             30 |          57.39 |          86.92 |          83.44 |          81.36 \n",
      "             31 |          63.50 |          86.81 |          86.19 |          82.49 \n",
      "             32 |          44.75 |          88.19 |          85.23 |          82.82 \n",
      "             33 |          54.94 |          89.33 |          86.50 |          83.26 \n",
      "             34 |          54.41 |          89.10 |          86.21 |          84.21 \n",
      "             35 |          55.63 |          89.45 |          86.41 |          85.34 \n",
      "             36 |          51.09 |          89.31 |          85.92 |          85.00 \n",
      "             37 |          61.96 |          90.07 |          86.15 |          85.09 \n",
      "             38 |          59.13 |          90.68 |          86.97 |          85.41 \n",
      "             39 |          58.46 |          85.10 |          84.96 |          82.68 \n",
      "             40 |          63.38 |          90.97 |          87.84 |          86.19 \n",
      "--------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 40, f1-macro, test = 86.19)\n",
      "--------------------------------------------------------------------------------------\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.64\n",
      "              1 = 79.51\n",
      "              2 = 80.43\n",
      "------------------------\n",
      "Macro-F1 = 86.194\n",
      "Input arguments:\n",
      "python3 main.py -f /tmp/tmpyugkcdq6.json --HistoryManager.hist_file=:memory:\n",
      "\n",
      "86.1939\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 32801,
     "sourceId": 42887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11686.556196,
   "end_time": "2023-12-02T06:11:59.453850",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T02:57:12.897654",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0284515a044d4d7882bb19b8ca7e9b41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03fe5afec5004a70b52eda6c2fde62a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a556514e4894e5db6023ad3300d42b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1039c3b2650e45b38d9e95d841605a2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1428a2a1087f4308a1f9900df0f5f9c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "148ce3cae2814ca3ad4d4cef978f8bfc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1725ba5b34ff4c78bfe8019287b6597e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18ab2976056842b6bde4b11133022cc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78c3dfaf57b549fda15bd41ff79ffc09",
       "max": 2279.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bf6fd80d15f941bcabf55c45e75cd819",
       "value": 2279.0
      }
     },
     "1d764aa7e583461f9916b8c7d0afd794": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d89b5a7043c428b91c34796e56b31dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_edfcbede07e7405d875a2e7dc2eba7ce",
       "max": 924.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d63d5b3ed8a4442a91891cb942728df4",
       "value": 924.0
      }
     },
     "1feca346be814ff6b5ca5aca6b59267e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_24a84c9cad8343a4bdeeea4d0ccf4d2c",
       "placeholder": "​",
       "style": "IPY_MODEL_4c28cab561fe43e59ab388844474417b",
       "value": "Downloading data: "
      }
     },
     "23dac8dbd11e4d43995109869016519a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2822ef1a52c24ac9a78970c38c4e840e",
       "max": 1549.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50dc45edef564f2f803d33baf68164f2",
       "value": 1549.0
      }
     },
     "24a84c9cad8343a4bdeeea4d0ccf4d2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "256bf3e58b7c44adbc8c01698c7ebe88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfc4524085cd4261b71de56f4fc4963a",
       "placeholder": "​",
       "style": "IPY_MODEL_0a556514e4894e5db6023ad3300d42b6",
       "value": " 865/924 [00:00&lt;00:00, 4354.65 examples/s]"
      }
     },
     "2822ef1a52c24ac9a78970c38c4e840e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2895b2d5a0ec4594923f96634b922d91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4e6ba44e70e4a2bb4b5931ce2b9b339",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_332a1764c7524dd59661587756c3fc43",
       "value": 3.0
      }
     },
     "2a1b2f31da604c2a94b2c744f8807ce7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2b40f7e4862b464e81f3158d77cf94f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2cf6677a2e304234b78dc3208f362725": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_03fe5afec5004a70b52eda6c2fde62a4",
       "placeholder": "​",
       "style": "IPY_MODEL_d419f8e756f0411485462ba110ba4eb7",
       "value": "Downloading data: "
      }
     },
     "2d5dc7790cac406b8b11dbf4c5a01d50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e838a9ebd334586bde03ddbaedff382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7754d8ba57ba48b6875c3d801a1a898b",
       "placeholder": "​",
       "style": "IPY_MODEL_450159b7674847a79de82a9a852a3014",
       "value": " 5060/5433 [00:01&lt;00:00, 4630.39 examples/s]"
      }
     },
     "2faa6743beae44fca6b433e4b1ea4695": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "332a1764c7524dd59661587756c3fc43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "34d9d8a132264181be0a417c6262b8b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39c2404daa3d4f84af0439b3dec12051": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8decad7d252d4fc7878aacc1c063c4b3",
       "placeholder": "​",
       "style": "IPY_MODEL_3e46e675a4f54b61aa900d6bf6cbf748",
       "value": " 3.45k/? [00:00&lt;00:00, 249kB/s]"
      }
     },
     "3e46e675a4f54b61aa900d6bf6cbf748": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3fc400dfd18144f49bf5e64daf9bf513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "44b589eff76848629925576f18906a5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "450159b7674847a79de82a9a852a3014": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "46a1844794dd40b38e98865c6d61caef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b74b0924f90a4611a04732594754a447",
        "IPY_MODEL_47275612bba645b5a366e5e6b8c72123",
        "IPY_MODEL_b1c26f37219a4ae289b2610c61f3edf3"
       ],
       "layout": "IPY_MODEL_91a91c9b8d794df5976eb98147de8436"
      }
     },
     "47275612bba645b5a366e5e6b8c72123": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3dd6625678e43d987764e30a4e48da6",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dfb3913df8d6437fb7d79c481643c63f",
       "value": 3.0
      }
     },
     "4735526232484685935b86cd9f2f4b30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cce202cc91a8414f87f81588235e8ef6",
       "placeholder": "​",
       "style": "IPY_MODEL_fe7fde884e934c74bffc67107099e8a4",
       "value": "Downloading builder script: "
      }
     },
     "47bb3b6b6d71400db417dc75573c0e89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b8c94e2f40b4f0f927c0a1ec6df9249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b6302645f0b648f7ac6ae18225a249ea",
       "max": 52411.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7dae7ef372d242e8a28eb607e62315b0",
       "value": 52411.0
      }
     },
     "4c28cab561fe43e59ab388844474417b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4ce541248ce24eaab28fa27344b2e627": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "50dc45edef564f2f803d33baf68164f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51dedf34bb554800b12b770c71875aa2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "539147b31c094ff9b161c33d854bdf04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5bd80a2d17284a1697e6f8a849030264": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d89290e68d1446badfe7509d591e385": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6368c19a4f474d529325a45e5aeea287": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_72204a5aee8347e2b676fe555da87142",
       "placeholder": "​",
       "style": "IPY_MODEL_f183ba0036204869bb10e742bd9a42a7",
       "value": "100%"
      }
     },
     "66764fcd141b4f73b8ef2fa678b6f92c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_940d590d51a4436f9515b9d06aebd24d",
       "max": 51200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eaac5497c68249f9b410a5cfda7f6e2c",
       "value": 51200.0
      }
     },
     "69aa988fbe33439a84f7a1a9d092ce33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6a30f2928f574afebd791325c1e76bef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e43e89bbaba2420cbdb316770f683554",
       "placeholder": "​",
       "style": "IPY_MODEL_b2e6437bf6b04f69bccf2b9349df7a54",
       "value": "Generating test split:  91%"
      }
     },
     "6e8722fbc5f54fa9a7ffbce4ae465541": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72204a5aee8347e2b676fe555da87142": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75759dcb170a4cbca55381eadcacbc2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6a30f2928f574afebd791325c1e76bef",
        "IPY_MODEL_aa617ce12b97431fbf3f78f578d39d4c",
        "IPY_MODEL_76826b41a31c4b4fa2bab26c76cbfdab"
       ],
       "layout": "IPY_MODEL_7f0d16f0f76645bbb85f8f4d00398cf9"
      }
     },
     "76826b41a31c4b4fa2bab26c76cbfdab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef8af08c349a4f218a573130589218c7",
       "placeholder": "​",
       "style": "IPY_MODEL_1428a2a1087f4308a1f9900df0f5f9c8",
       "value": " 857/941 [00:00&lt;00:00, 4307.36 examples/s]"
      }
     },
     "76a3ea175a7d4980a3cf9c522de17572": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7754d8ba57ba48b6875c3d801a1a898b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78c3dfaf57b549fda15bd41ff79ffc09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7dae7ef372d242e8a28eb607e62315b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7ee8c7a920144d359df0083a14ecbba4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1725ba5b34ff4c78bfe8019287b6597e",
       "placeholder": "​",
       "style": "IPY_MODEL_b601def476f94b7789cb924ca052015e",
       "value": "Downloading metadata: "
      }
     },
     "7f0d16f0f76645bbb85f8f4d00398cf9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "87a305f2fb78470cbfdd61481c97a855": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2cf6677a2e304234b78dc3208f362725",
        "IPY_MODEL_9bbf96058275468b82c49e8fff3a1e4e",
        "IPY_MODEL_fc94587d67114026bc360f744320857c"
       ],
       "layout": "IPY_MODEL_5d89290e68d1446badfe7509d591e385"
      }
     },
     "898f44ae973e48dbaf00c135b28779a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a0cadb80ac6f44f7baeb71495cc6dfb8",
        "IPY_MODEL_c07ec5f767ca4babbd88a8d741547af7",
        "IPY_MODEL_f65f84a4ce3344fb871ae32b2a8e0747"
       ],
       "layout": "IPY_MODEL_539147b31c094ff9b161c33d854bdf04"
      }
     },
     "8ccab89007db4bd9ae0084770af626a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8decad7d252d4fc7878aacc1c063c4b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91a91c9b8d794df5976eb98147de8436": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "940d590d51a4436f9515b9d06aebd24d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98e6ca19bb7a4c61a1f2cc9ed264ed15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c8cd767c8b6c4c4fb57671f7fb4d9529",
       "placeholder": "​",
       "style": "IPY_MODEL_3fc400dfd18144f49bf5e64daf9bf513",
       "value": " 3/3 [00:00&lt;00:00, 149.92it/s]"
      }
     },
     "9b1c6cc49cfb478f92dd30d9a72e8347": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f2873fe4c30043ba8771c194e33c17ba",
        "IPY_MODEL_4b8c94e2f40b4f0f927c0a1ec6df9249",
        "IPY_MODEL_9bcbb1df35054eea9d564053ddae2e4e"
       ],
       "layout": "IPY_MODEL_1039c3b2650e45b38d9e95d841605a2f"
      }
     },
     "9bb0fb2125ec451594badb443660dd57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_34d9d8a132264181be0a417c6262b8b3",
       "placeholder": "​",
       "style": "IPY_MODEL_d48478ac6e5e4d0d866f23102c284d8e",
       "value": "Generating train split:  93%"
      }
     },
     "9bbf96058275468b82c49e8fff3a1e4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_148ce3cae2814ca3ad4d4cef978f8bfc",
       "max": 283883.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad88f47d710e4d9e800d2b939edd9ec7",
       "value": 283883.0
      }
     },
     "9bcbb1df35054eea9d564053ddae2e4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4b6c96742ed41a785a8090892159340",
       "placeholder": "​",
       "style": "IPY_MODEL_d3cc1948a1df4337823f00adf1114b3d",
       "value": " 206k/? [00:00&lt;00:00, 12.8MB/s]"
      }
     },
     "9f7dff592ae841b9a908cead58ef0389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a0cadb80ac6f44f7baeb71495cc6dfb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a913fb25a66d4e86b3b34536ed51634c",
       "placeholder": "​",
       "style": "IPY_MODEL_f23b9382f80d497d9d43fb2b418b994a",
       "value": "Downloading data files: 100%"
      }
     },
     "a0d1d72190c7442cabab1d9af8decf21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4c1a5aea6464fa384fb4f4dbf344041": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4735526232484685935b86cd9f2f4b30",
        "IPY_MODEL_18ab2976056842b6bde4b11133022cc4",
        "IPY_MODEL_de7d57079b9f419e8525ad65c249848d"
       ],
       "layout": "IPY_MODEL_a0d1d72190c7442cabab1d9af8decf21"
      }
     },
     "a4f1d03799a34f99a62427fd466b1708": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76a3ea175a7d4980a3cf9c522de17572",
       "placeholder": "​",
       "style": "IPY_MODEL_fec1a804fce241f1b58cebba73fa897a",
       "value": "Generating validation split:  94%"
      }
     },
     "a53abf1d1e6244f3bcf64d98e8c27313": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1feca346be814ff6b5ca5aca6b59267e",
        "IPY_MODEL_66764fcd141b4f73b8ef2fa678b6f92c",
        "IPY_MODEL_a879318951084eaa845402b6250ddb7b"
       ],
       "layout": "IPY_MODEL_6e8722fbc5f54fa9a7ffbce4ae465541"
      }
     },
     "a879318951084eaa845402b6250ddb7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2b40f7e4862b464e81f3158d77cf94f2",
       "placeholder": "​",
       "style": "IPY_MODEL_e34df439af35411b96b9edcb9caa0804",
       "value": " 200k/? [00:00&lt;00:00, 11.8MB/s]"
      }
     },
     "a913fb25a66d4e86b3b34536ed51634c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa617ce12b97431fbf3f78f578d39d4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d5dc7790cac406b8b11dbf4c5a01d50",
       "max": 941.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9f7dff592ae841b9a908cead58ef0389",
       "value": 941.0
      }
     },
     "ab713d1a9aa24cc386a42f60b8ffc63f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9bb0fb2125ec451594badb443660dd57",
        "IPY_MODEL_ffe00a1c7c834ff7aeee4027fb8e495e",
        "IPY_MODEL_2e838a9ebd334586bde03ddbaedff382"
       ],
       "layout": "IPY_MODEL_fdb3013f43bc4265b1b45894ebe2ff45"
      }
     },
     "ad88f47d710e4d9e800d2b939edd9ec7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b1c26f37219a4ae289b2610c61f3edf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d764aa7e583461f9916b8c7d0afd794",
       "placeholder": "​",
       "style": "IPY_MODEL_c848e4c071ed4fceb250144c5d3850a3",
       "value": " 3/3 [00:00&lt;00:00, 216.76it/s]"
      }
     },
     "b1d20499968946d1a5f1ef242825f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4f1d03799a34f99a62427fd466b1708",
        "IPY_MODEL_1d89b5a7043c428b91c34796e56b31dd",
        "IPY_MODEL_256bf3e58b7c44adbc8c01698c7ebe88"
       ],
       "layout": "IPY_MODEL_51dedf34bb554800b12b770c71875aa2"
      }
     },
     "b2e6437bf6b04f69bccf2b9349df7a54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4b6c96742ed41a785a8090892159340": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b601def476f94b7789cb924ca052015e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6302645f0b648f7ac6ae18225a249ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b74b0924f90a4611a04732594754a447": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5bd80a2d17284a1697e6f8a849030264",
       "placeholder": "​",
       "style": "IPY_MODEL_bb1b91c7ffe84452a704d0f6135f022e",
       "value": "Extracting data files: 100%"
      }
     },
     "bb1b91c7ffe84452a704d0f6135f022e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bf6fd80d15f941bcabf55c45e75cd819": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bf957628ea904a748b4cb394624fd4c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c07ec5f767ca4babbd88a8d741547af7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e32dc472db2b4be0bbcaed0aac6c93a9",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eabd5e7e0ae34b80b211a30c7b1c3bc2",
       "value": 3.0
      }
     },
     "c6b2d1c988c94e3195e09b3ea86ba923": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ee8c7a920144d359df0083a14ecbba4",
        "IPY_MODEL_23dac8dbd11e4d43995109869016519a",
        "IPY_MODEL_39c2404daa3d4f84af0439b3dec12051"
       ],
       "layout": "IPY_MODEL_bf957628ea904a748b4cb394624fd4c7"
      }
     },
     "c848e4c071ed4fceb250144c5d3850a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8cd767c8b6c4c4fb57671f7fb4d9529": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cce202cc91a8414f87f81588235e8ef6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d23c02a1e1854d10b080b983b63b23d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3cc1948a1df4337823f00adf1114b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3dd6625678e43d987764e30a4e48da6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d419f8e756f0411485462ba110ba4eb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d48478ac6e5e4d0d866f23102c284d8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d63d5b3ed8a4442a91891cb942728df4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dbdbe042b4164ac9b4785875a5d3166b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de7d57079b9f419e8525ad65c249848d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dbdbe042b4164ac9b4785875a5d3166b",
       "placeholder": "​",
       "style": "IPY_MODEL_8ccab89007db4bd9ae0084770af626a0",
       "value": " 5.83k/? [00:00&lt;00:00, 384kB/s]"
      }
     },
     "df814bd695f341f9808e7459a9f3919e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6368c19a4f474d529325a45e5aeea287",
        "IPY_MODEL_2895b2d5a0ec4594923f96634b922d91",
        "IPY_MODEL_98e6ca19bb7a4c61a1f2cc9ed264ed15"
       ],
       "layout": "IPY_MODEL_47bb3b6b6d71400db417dc75573c0e89"
      }
     },
     "dfb3913df8d6437fb7d79c481643c63f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dfc4524085cd4261b71de56f4fc4963a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e32dc472db2b4be0bbcaed0aac6c93a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e34df439af35411b96b9edcb9caa0804": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e43e89bbaba2420cbdb316770f683554": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaac5497c68249f9b410a5cfda7f6e2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eabd5e7e0ae34b80b211a30c7b1c3bc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "edfcbede07e7405d875a2e7dc2eba7ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef8af08c349a4f218a573130589218c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f183ba0036204869bb10e742bd9a42a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f23b9382f80d497d9d43fb2b418b994a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f2873fe4c30043ba8771c194e33c17ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fdfe4f438aa449369cc584891612da8a",
       "placeholder": "​",
       "style": "IPY_MODEL_d23c02a1e1854d10b080b983b63b23d6",
       "value": "Downloading data: "
      }
     },
     "f4e6ba44e70e4a2bb4b5931ce2b9b339": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f65f84a4ce3344fb871ae32b2a8e0747": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2faa6743beae44fca6b433e4b1ea4695",
       "placeholder": "​",
       "style": "IPY_MODEL_4ce541248ce24eaab28fa27344b2e627",
       "value": " 3/3 [00:01&lt;00:00,  1.69it/s]"
      }
     },
     "fc94587d67114026bc360f744320857c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44b589eff76848629925576f18906a5d",
       "placeholder": "​",
       "style": "IPY_MODEL_69aa988fbe33439a84f7a1a9d092ce33",
       "value": " 1.14M/? [00:00&lt;00:00, 36.2MB/s]"
      }
     },
     "fdb3013f43bc4265b1b45894ebe2ff45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "fdfe4f438aa449369cc584891612da8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe7fde884e934c74bffc67107099e8a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fec1a804fce241f1b58cebba73fa897a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ffe00a1c7c834ff7aeee4027fb8e495e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0284515a044d4d7882bb19b8ca7e9b41",
       "max": 5433.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2a1b2f31da604c2a94b2c744f8807ce7",
       "value": 5433.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1379d016",
   "metadata": {
    "papermill": {
     "duration": 0.011187,
     "end_time": "2023-12-02T02:08:39.008656",
     "exception": false,
     "start_time": "2023-12-02T02:08:38.997469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1613aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:39.031321Z",
     "iopub.status.busy": "2023-12-02T02:08:39.030949Z",
     "iopub.status.idle": "2023-12-02T02:08:43.889685Z",
     "shell.execute_reply": "2023-12-02T02:08:43.888872Z"
    },
    "papermill": {
     "duration": 4.872932,
     "end_time": "2023-12-02T02:08:43.892157",
     "exception": false,
     "start_time": "2023-12-02T02:08:39.019225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import sys\n",
    "import math\n",
    "from math import ceil, floor\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22895532",
   "metadata": {
    "papermill": {
     "duration": 0.010073,
     "end_time": "2023-12-02T02:08:43.912733",
     "exception": false,
     "start_time": "2023-12-02T02:08:43.902660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71c7f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:43.934503Z",
     "iopub.status.busy": "2023-12-02T02:08:43.934015Z",
     "iopub.status.idle": "2023-12-02T02:08:43.948050Z",
     "shell.execute_reply": "2023-12-02T02:08:43.947339Z"
    },
    "papermill": {
     "duration": 0.027143,
     "end_time": "2023-12-02T02:08:43.949900",
     "exception": false,
     "start_time": "2023-12-02T02:08:43.922757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info(t, name=''):\n",
    "    print(name, '|', t.type(), '|', t.shape)\n",
    "\n",
    "\n",
    "def flatten(list_in):\n",
    "    return [list(itertools.chain.from_iterable(list_item)) for list_item in list_in]\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_words_num(word_sequences):\n",
    "    return sum(len(word_seq) for word_seq in word_sequences)\n",
    "\n",
    "\n",
    "def get_datetime_str():\n",
    "    d = datetime.datetime.now()\n",
    "    return '%02d_%02d_%02d_%02d-%02d_%02d' % (d.year, d.month, d.day, d.hour, d.minute, d.second)\n",
    "\n",
    "\n",
    "def get_sequences_by_indices(sequences, indices):\n",
    "    return [sequences[i] for i in indices]\n",
    "\n",
    "\n",
    "def argsort(seq):\n",
    "    return sorted(range(len(seq)), key=seq.__getitem__)\n",
    "\n",
    "\n",
    "def argsort_sequences_by_lens(list_in):\n",
    "    data_num = len(list_in)\n",
    "    sort_indices = argsort([-len(item) for item in list_in])\n",
    "    reverse_sort_indices = [-1 for _ in range(data_num)]\n",
    "    for i in range(data_num):\n",
    "        reverse_sort_indices[sort_indices[i]] = i\n",
    "    return sort_indices, reverse_sort_indices\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_score, _ = torch.max(x, -1)\n",
    "    max_score_broadcast = max_score.unsqueeze(-1).expand_as(x)\n",
    "    return max_score + torch.log(torch.sum(torch.exp(x - max_score_broadcast), -1))\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def get_input_arguments():\n",
    "    return 'python3 main.py ' + ' '.join([arg for arg in sys.argv[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299ba8b",
   "metadata": {
    "papermill": {
     "duration": 0.010583,
     "end_time": "2023-12-02T02:08:43.970743",
     "exception": false,
     "start_time": "2023-12-02T02:08:43.960160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c2f755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:43.993894Z",
     "iopub.status.busy": "2023-12-02T02:08:43.993584Z",
     "iopub.status.idle": "2023-12-02T02:08:44.004221Z",
     "shell.execute_reply": "2023-12-02T02:08:44.003247Z"
    },
    "papermill": {
     "duration": 0.024683,
     "end_time": "2023-12-02T02:08:44.006231",
     "exception": false,
     "start_time": "2023-12-02T02:08:43.981548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataIONCBI():\n",
    "    \"\"\"\n",
    "    DataIONCBI is an input/output data wrapper for NCBI dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_name='ncbi_disease', train_no=None, dev_no=None, test_no=None):\n",
    "        self.NCBIDataset = load_dataset(dataset_name)\n",
    "        self.train_no = train_no\n",
    "        self.dev_no = dev_no\n",
    "        self.test_no = test_no\n",
    "    \n",
    "    def read_train_dev_test(self, args):\n",
    "        word_sequences_train, tag_sequences_train = self.read_data('train', verbose=args.verbose, exp_no=self.train_no)\n",
    "        word_sequences_dev, tag_sequences_dev = self.read_data('validation', verbose=args.verbose, exp_no=self.dev_no)\n",
    "        word_sequences_test, tag_sequences_test = self.read_data('test', verbose=args.verbose, exp_no=self.test_no)\n",
    "        return word_sequences_train, tag_sequences_train, word_sequences_dev, tag_sequences_dev, word_sequences_test, tag_sequences_test\n",
    "\n",
    "    def read_data(self, mode, verbose=True, exp_no=None):\n",
    "        dataset = self.NCBIDataset[mode]\n",
    "        word_sequences = list()\n",
    "        tag_sequences = list()\n",
    "        for i, row in enumerate(dataset):\n",
    "            if len(row['tokens']) == 0 or len(row['ner_tags']) == 0:\n",
    "                continue\n",
    "            word_sequences.append(row['tokens'])\n",
    "            tag_sequences.append(row['ner_tags'])\n",
    "            if exp_no:\n",
    "                if i>= exp_no-1:\n",
    "                    break\n",
    "            \n",
    "        if verbose:\n",
    "            print('Loading from %s: %d samples, %d words.' % (mode, len(word_sequences), get_words_num(word_sequences)))\n",
    "        return word_sequences, tag_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2a321",
   "metadata": {
    "papermill": {
     "duration": 0.010938,
     "end_time": "2023-12-02T02:08:44.027856",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.016918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379b183e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.049828Z",
     "iopub.status.busy": "2023-12-02T02:08:44.049556Z",
     "iopub.status.idle": "2023-12-02T02:08:44.071520Z",
     "shell.execute_reply": "2023-12-02T02:08:44.070720Z"
    },
    "papermill": {
     "duration": 0.035415,
     "end_time": "2023-12-02T02:08:44.073349",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.037934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetsBank():\n",
    "    \"\"\"DatasetsBank provides storing the train/dev/test data subsets and sampling batches from the train dataset.\"\"\"\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.unique_words_list = list()\n",
    "\n",
    "    def __add_to_unique_words_list(self, word_sequences):\n",
    "        for word_seq in word_sequences:\n",
    "            for word in word_seq:\n",
    "                if word not in self.unique_words_list:\n",
    "                    self.unique_words_list.append(word)\n",
    "        if self.verbose:\n",
    "            print('DatasetsBank: len(unique_words_list) = %d unique words.' % (len(self.unique_words_list)))\n",
    "\n",
    "    def add_train_sequences(self, word_sequences_train, tag_sequences_train):\n",
    "        self.train_data_num = len(word_sequences_train)\n",
    "        self.word_sequences_train = word_sequences_train\n",
    "        self.tag_sequences_train = tag_sequences_train\n",
    "        self.__add_to_unique_words_list(word_sequences_train)\n",
    "\n",
    "    def add_dev_sequences(self, word_sequences_dev, tag_sequences_dev):\n",
    "        self.word_sequences_dev = word_sequences_dev\n",
    "        self.tag_sequences_dev = tag_sequences_dev\n",
    "        self.__add_to_unique_words_list(word_sequences_dev)\n",
    "\n",
    "    def add_test_sequences(self, word_sequences_test, tag_sequences_test):\n",
    "        self.word_sequences_test = word_sequences_test\n",
    "        self.tag_sequences_test = tag_sequences_test\n",
    "        self.__add_to_unique_words_list(word_sequences_test)\n",
    "\n",
    "    def __get_train_batch(self, batch_indices):\n",
    "        word_sequences_train_batch = [self.word_sequences_train[i] for i in batch_indices]\n",
    "        tag_sequences_train_batch = [self.tag_sequences_train[i] for i in batch_indices]\n",
    "        return word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "    def get_train_batches(self, batch_size):\n",
    "        random_indices = np.random.permutation(np.arange(self.train_data_num))\n",
    "        for k in range(self.train_data_num // batch_size): # oh yes, we drop the last batch\n",
    "            batch_indices = random_indices[k:k + batch_size].tolist()\n",
    "            word_sequences_train_batch, tag_sequences_train_batch = self.__get_train_batch(batch_indices)\n",
    "            yield word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "\n",
    "class DatasetsBankSorted():\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.unique_words_list = list()\n",
    "\n",
    "    def __add_to_unique_words_list(self, word_sequences):\n",
    "        for word_seq in word_sequences:\n",
    "            for word in word_seq:\n",
    "                if word not in self.unique_words_list:\n",
    "                    self.unique_words_list.append(word)\n",
    "        if self.verbose:\n",
    "            print('DatasetsBank: len(unique_words_list) = %d unique words.' % (len(self.unique_words_list)))\n",
    "\n",
    "    def add_train_sequences(self, word_sequences_train, tag_sequences_train):\n",
    "        sort_indices, _ = argsort_sequences_by_lens(word_sequences_train)\n",
    "        self.word_sequences_train = get_sequences_by_indices(word_sequences_train, sort_indices)\n",
    "        self.tag_sequences_train = get_sequences_by_indices(tag_sequences_train, sort_indices)\n",
    "        self.train_data_num = len(word_sequences_train)\n",
    "        self.__add_to_unique_words_list(word_sequences_train)\n",
    "\n",
    "    def add_dev_sequences(self, word_sequences_dev, tag_sequences_dev):\n",
    "        self.word_sequences_dev = word_sequences_dev\n",
    "        self.tag_sequences_dev = tag_sequences_dev\n",
    "        self.__add_to_unique_words_list(word_sequences_dev)\n",
    "\n",
    "    def add_test_sequences(self, word_sequences_test, tag_sequences_test):\n",
    "        self.word_sequences_test = word_sequences_test\n",
    "        self.tag_sequences_test = tag_sequences_test\n",
    "        self.__add_to_unique_words_list(word_sequences_test)\n",
    "\n",
    "    def __get_train_batch(self, batch_size, batch_no, rand_seed=0):\n",
    "        i = batch_no * batch_size + rand_seed\n",
    "        j = min((batch_no + 1) * batch_size, self.train_data_num + 1) + rand_seed\n",
    "        return self.word_sequences_train[i:j], self.tag_sequences_train[i:j]\n",
    "\n",
    "    def get_train_batches(self, batch_size):\n",
    "        rand_seed = randint(0, batch_size - 1)\n",
    "        batch_num = self.train_data_num // batch_size\n",
    "        random_indices = np.random.permutation(np.arange(batch_num - 1)).tolist()\n",
    "        for k in random_indices:\n",
    "            yield self.__get_train_batch(batch_size, batch_no=k, rand_seed=rand_seed)\n",
    "\n",
    "    def __get_train_batch_regularized(self, batch_size, rand_batch_size, batch_no):\n",
    "        i = batch_no * batch_size\n",
    "        j = min((batch_no + 1) * batch_size, self.train_data_num + 1)\n",
    "        word_sequences_train_batch = self.word_sequences_train[i:j]\n",
    "        tag_sequences_train_batch = self.tag_sequences_train[i:j]\n",
    "        for k in range(rand_batch_size):\n",
    "            r = randint(0, self.train_data_num)\n",
    "            word_sequences_train_batch.append(self.word_sequences_train[r])\n",
    "            tag_sequences_train_batch.append(self.tag_sequences_train[r])\n",
    "        return word_sequences_train_batch, tag_sequences_train_batch\n",
    "\n",
    "    def get_train_batches_regularized(self, batch_size):\n",
    "        batch_num = self.train_data_num // batch_size\n",
    "        random_indices = np.random.permutation(np.arange(batch_num)).tolist()\n",
    "        for k in random_indices:\n",
    "            yield self.__get_train_batch_regularized(batch_size-2, rand_batch_size=2, batch_no=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a782a07",
   "metadata": {
    "papermill": {
     "duration": 0.010108,
     "end_time": "2023-12-02T02:08:44.093639",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.083531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sequence Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f9c66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.115677Z",
     "iopub.status.busy": "2023-12-02T02:08:44.115396Z",
     "iopub.status.idle": "2023-12-02T02:08:44.134260Z",
     "shell.execute_reply": "2023-12-02T02:08:44.133539Z"
    },
    "papermill": {
     "duration": 0.03214,
     "end_time": "2023-12-02T02:08:44.136202",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.104062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBase():\n",
    "    \"\"\"\n",
    "    SeqIndexerBase is a base abstract class for sequence indexers. It converts list of lists of string items\n",
    "    to the list of lists of integer indices and back. Items could be either words, tags or characters.\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu=-1, check_for_lowercase=True, zero_digits=False, pad='<pad>', unk='<unk>',\n",
    "                 load_embeddings=False, embeddings_dim=0, verbose=False):\n",
    "        self.gpu = gpu\n",
    "        self.check_for_lowercase = check_for_lowercase\n",
    "        self.zero_digits = zero_digits\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.load_embeddings = load_embeddings\n",
    "        self.embeddings_dim = embeddings_dim\n",
    "        self.verbose = verbose\n",
    "        self.out_of_vocabulary_list = list()\n",
    "        self.item2idx_dict = dict()\n",
    "        self.idx2item_dict = dict()\n",
    "        if load_embeddings:\n",
    "            self.embeddings_loaded = False\n",
    "            self.embedding_vectors_list = list()\n",
    "        if pad is not None:\n",
    "            self.pad_idx = self.add_item(pad)\n",
    "            if load_embeddings:\n",
    "                self.add_emb_vector(self.generate_zero_emb_vector())\n",
    "        if unk is not None:\n",
    "            self.unk_idx = self.add_item(unk)\n",
    "            if load_embeddings:\n",
    "                self.add_emb_vector(self.generate_random_emb_vector())\n",
    "\n",
    "    def get_items_list(self):\n",
    "        return list(self.item2idx_dict.keys())\n",
    "\n",
    "    def get_items_count(self):\n",
    "        return len(self.get_items_list())\n",
    "\n",
    "    def item_exists(self, item):\n",
    "        return item in self.item2idx_dict.keys()\n",
    "\n",
    "    def add_item(self, item):\n",
    "        idx = len(self.get_items_list())\n",
    "        self.item2idx_dict[item] = idx\n",
    "        self.idx2item_dict[idx] = item\n",
    "        return idx\n",
    "\n",
    "    def get_class_num(self):\n",
    "        if self.pad is not None and self.unk is not None:\n",
    "            return self.get_items_count() - 2\n",
    "        if self.pad is not None or self.unk is not None:\n",
    "            return self.get_items_count() - 1\n",
    "        return self.get_items_count()\n",
    "\n",
    "    def items2idx(self, item_sequences):\n",
    "        idx_sequences = []\n",
    "        for item_seq in item_sequences:\n",
    "            idx_seq = list()\n",
    "            for item in item_seq:\n",
    "                if item in self.item2idx_dict:\n",
    "                    idx_seq.append(self.item2idx_dict[item])\n",
    "                else:\n",
    "                    if self.unk is not None:\n",
    "                        idx_seq.append(self.item2idx_dict[self.unk])\n",
    "                    else:\n",
    "                        idx_seq.append(self.item2idx_dict[self.pad])\n",
    "            idx_sequences.append(idx_seq)\n",
    "        return idx_sequences\n",
    "\n",
    "    def idx2items(self, idx_sequences):\n",
    "        item_sequences = []\n",
    "        for idx_seq in idx_sequences:\n",
    "            item_seq = [self.idx2item_dict[idx] for idx in idx_seq]\n",
    "            item_sequences.append(item_seq)\n",
    "        return item_sequences\n",
    "\n",
    "    def items2tensor(self, item_sequences, align='left', word_len=-1):\n",
    "        idx = self.items2idx(item_sequences)\n",
    "        return self.idx2tensor(idx, align, word_len)\n",
    "\n",
    "    def idx2tensor(self, idx_sequences, align='left', word_len=-1):\n",
    "        batch_size = len(idx_sequences)\n",
    "        if word_len == -1:\n",
    "            word_len = max([len(idx_seq) for idx_seq in idx_sequences])\n",
    "        tensor = torch.zeros(batch_size, word_len, dtype=torch.long)\n",
    "        for k, idx_seq in enumerate(idx_sequences):\n",
    "            curr_seq_len = len(idx_seq)\n",
    "            if curr_seq_len > word_len:\n",
    "                idx_seq = [idx_seq[i] for i in range(word_len)]\n",
    "                curr_seq_len = word_len\n",
    "            if align == 'left':\n",
    "                tensor[k, :curr_seq_len] = torch.LongTensor(np.asarray(idx_seq))\n",
    "            elif align == 'center':\n",
    "                start_idx = (word_len - curr_seq_len) // 2\n",
    "                tensor[k, start_idx:start_idx+curr_seq_len] = torch.LongTensor(np.asarray(idx_seq))\n",
    "            else:\n",
    "                raise ValueError('Unknown align string.')\n",
    "        if self.gpu >= 0:\n",
    "            tensor = tensor.cuda(device=self.gpu)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217a6b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.158433Z",
     "iopub.status.busy": "2023-12-02T02:08:44.158156Z",
     "iopub.status.idle": "2023-12-02T02:08:44.168537Z",
     "shell.execute_reply": "2023-12-02T02:08:44.167835Z"
    },
    "papermill": {
     "duration": 0.023317,
     "end_time": "2023-12-02T02:08:44.170348",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.147031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBaseEmbeddings(SeqIndexerBase):\n",
    "    \"\"\"\n",
    "    SeqIndexerBaseEmbeddings is a basic abstract sequence indexers class that implements work qith embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu, check_for_lowercase, zero_digits, pad, unk, load_embeddings, embeddings_dim, verbose):\n",
    "        SeqIndexerBase.__init__(self, gpu, check_for_lowercase, zero_digits, pad, unk, load_embeddings, embeddings_dim,\n",
    "                                verbose)\n",
    "    @staticmethod\n",
    "    def load_embeddings_from_file(emb_fn, emb_delimiter, verbose=True):\n",
    "        for k, line in enumerate(open(emb_fn, 'r')):\n",
    "            values = line.split(emb_delimiter)\n",
    "            if len(values) < 5:\n",
    "                continue\n",
    "            word = values[0]\n",
    "            emb_vector = list(map(lambda t: float(t), filter(lambda n: n and not n.isspace(), values[1:])))\n",
    "            if verbose:\n",
    "                if k % 100000 == 0:\n",
    "                    print('Reading embeddings file %s, line = %d' % (emb_fn, k))\n",
    "            yield word, emb_vector\n",
    "\n",
    "    def generate_zero_emb_vector(self):\n",
    "        if self.embeddings_dim == 0:\n",
    "            raise ValueError('embeddings_dim is not known.')\n",
    "        return [0 for _ in range(self.embeddings_dim)]\n",
    "\n",
    "    def generate_random_emb_vector(self):\n",
    "        if self.embeddings_dim == 0:\n",
    "            raise ValueError('embeddings_dim is not known.')\n",
    "        return np.random.uniform(-np.sqrt(3.0 / self.embeddings_dim), np.sqrt(3.0 / self.embeddings_dim),\n",
    "                                 self.embeddings_dim).tolist()\n",
    "\n",
    "    def add_emb_vector(self, emb_vector):\n",
    "        self.embedding_vectors_list.append(emb_vector)\n",
    "\n",
    "    def get_loaded_embeddings_tensor(self):\n",
    "        return torch.FloatTensor(np.asarray(self.embedding_vectors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cece1146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.192535Z",
     "iopub.status.busy": "2023-12-02T02:08:44.192256Z",
     "iopub.status.idle": "2023-12-02T02:08:44.214466Z",
     "shell.execute_reply": "2023-12-02T02:08:44.213662Z"
    },
    "papermill": {
     "duration": 0.035397,
     "end_time": "2023-12-02T02:08:44.216222",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.180825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerWord(SeqIndexerBaseEmbeddings):\n",
    "    \"\"\"SeqIndexerWord converts list of lists of words as strings to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu=-1, check_for_lowercase=True, embeddings_dim=0, verbose=True):\n",
    "        SeqIndexerBaseEmbeddings.__init__(self, gpu=gpu, check_for_lowercase=check_for_lowercase, zero_digits=True,\n",
    "                                          pad='<pad>', unk='<unk>', load_embeddings=True, embeddings_dim=embeddings_dim,\n",
    "                                          verbose=verbose)\n",
    "        self.original_words_num = 0\n",
    "        self.lowercase_words_num = 0\n",
    "        self.zero_digits_replaced_num = 0\n",
    "        self.zero_digits_replaced_lowercase_num = 0\n",
    "        self.capitalize_word_num = 0\n",
    "        self.uppercase_word_num = 0\n",
    "\n",
    "    def load_items_from_embeddings_file_and_unique_words_list(self, emb_fn, emb_delimiter, emb_load_all,\n",
    "                                                              unique_words_list):\n",
    "        embeddings_full_list = SeqIndexerBaseEmbeddings.load_embeddings_from_file(emb_fn,emb_delimiter,verbose=True)\n",
    "        # Get the full list of available case-sensitive words from text file with pretrained embeddings\n",
    "        \n",
    "        embeddings_words_list = [emb_word for emb_word, _ in embeddings_full_list]\n",
    "        # Create reverse mapping word from the embeddings file -> list of unique words from the dataset\n",
    "        emb_word_dict2unique_word_list = dict()\n",
    "        out_of_vocabulary_words_list = list()\n",
    "        for unique_word in unique_words_list:\n",
    "            emb_word = self.get_embeddings_word(unique_word, embeddings_words_list)\n",
    "            if emb_word is None:\n",
    "                out_of_vocabulary_words_list.append(unique_word)\n",
    "            else:\n",
    "                if emb_word not in emb_word_dict2unique_word_list:\n",
    "                    emb_word_dict2unique_word_list[emb_word] = [unique_word]\n",
    "                else:\n",
    "                    emb_word_dict2unique_word_list[emb_word].append(unique_word)\n",
    "        # Add pretrained embeddings for unique_words\n",
    "        for emb_word, emb_vec in embeddings_full_list:\n",
    "            if emb_word in emb_word_dict2unique_word_list:\n",
    "                for unique_word in emb_word_dict2unique_word_list[emb_word]:\n",
    "                    self.add_word_emb_vec(unique_word, emb_vec)\n",
    "        if self.verbose:\n",
    "            print('\\nload_vocabulary_from_embeddings_file_and_unique_words_list:')\n",
    "            print('    First 50 OOV words:')\n",
    "            for i, oov_word in enumerate(out_of_vocabulary_words_list):\n",
    "                print('        out_of_vocabulary_words_list[%d] = %s' % (i, oov_word))\n",
    "                if i > 49:\n",
    "                    break\n",
    "            print(' -- len(out_of_vocabulary_words_list) = %d' % len(out_of_vocabulary_words_list))\n",
    "            print(' -- original_words_num = %d' % self.original_words_num)\n",
    "            print(' -- lowercase_words_num = %d' % self.lowercase_words_num)\n",
    "            print(' -- zero_digits_replaced_num = %d' % self.zero_digits_replaced_num)\n",
    "            print(' -- zero_digits_replaced_lowercase_num = %d' % self.zero_digits_replaced_lowercase_num)\n",
    "        # Load all embeddings\n",
    "        if emb_load_all:\n",
    "            loaded_words_list = self.get_items_list()\n",
    "            load_all_words_num_before = len(loaded_words_list)\n",
    "            load_all_words_lower_num = 0\n",
    "            load_all_words_upper_num = 0\n",
    "            load_all_words_capitalize_num = 0\n",
    "            for emb_word, emb_vec in embeddings_full_list:\n",
    "                if emb_word in loaded_words_list:\n",
    "                    continue\n",
    "                if emb_word.lower() not in loaded_words_list and emb_word.lower() not in embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.lower(), emb_vec)\n",
    "                    load_all_words_lower_num += 1\n",
    "                if emb_word.upper() not in loaded_words_list and emb_word.upper() not in embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.upper(), emb_vec)\n",
    "                    load_all_words_upper_num += 1\n",
    "                if emb_word.capitalize() not in loaded_words_list and emb_word.capitalize() not in \\\n",
    "                        embeddings_words_list:\n",
    "                    self.add_word_emb_vec(emb_word.capitalize(), emb_vec)\n",
    "                    load_all_words_capitalize_num += 1\n",
    "                self.add_item(emb_word)\n",
    "                self.add_emb_vector(emb_vec)\n",
    "            load_all_words_num_after = len(self.get_items_list())\n",
    "            if self.verbose:\n",
    "                print(' ++ load_all_words_num_before = %d ' % load_all_words_num_before)\n",
    "                print(' ++ load_all_words_lower_num = %d ' % load_all_words_lower_num)\n",
    "                print(' ++ load_all_words_num_after = %d ' % load_all_words_num_after)\n",
    "\n",
    "    def get_embeddings_word(self, word, embeddings_word_list):\n",
    "        if word in embeddings_word_list:\n",
    "            self.original_words_num += 1\n",
    "            return word\n",
    "        elif self.check_for_lowercase and word.lower() in embeddings_word_list:\n",
    "            self.lowercase_words_num += 1\n",
    "            return word.lower()\n",
    "        elif self.zero_digits and re.sub('\\d', '0', word) in embeddings_word_list:\n",
    "            self.zero_digits_replaced_num += 1\n",
    "            return re.sub('\\d', '0', word)\n",
    "        elif self.check_for_lowercase and self.zero_digits and re.sub('\\d', '0', word.lower()) in embeddings_word_list:\n",
    "            self.zero_digits_replaced_lowercase_num += 1\n",
    "            return re.sub('\\d', '0', word.lower())\n",
    "        return None\n",
    "\n",
    "    def add_word_emb_vec(self, word, emb_vec):\n",
    "        self.add_item(word)\n",
    "        self.add_emb_vector(emb_vec)\n",
    "\n",
    "    def get_unique_characters_list(self, verbose=False, init_by_printable_characters=True):\n",
    "        if init_by_printable_characters:\n",
    "            unique_characters_set = set(string.printable)\n",
    "        else:\n",
    "            unique_characters_set = set()\n",
    "        if verbose:\n",
    "            cnt = 0\n",
    "        for n, word in enumerate(self.get_items_list()):\n",
    "            len_delta = len(unique_characters_set)\n",
    "            unique_characters_set = unique_characters_set.union(set(word))\n",
    "            if verbose and len(unique_characters_set) > len_delta:\n",
    "                cnt += 1\n",
    "                print('n = %d/%d (%d) %s' % (n, len(self.get_items_list), cnt, word))\n",
    "        return list(unique_characters_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d208deb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.238171Z",
     "iopub.status.busy": "2023-12-02T02:08:44.237903Z",
     "iopub.status.idle": "2023-12-02T02:08:44.244565Z",
     "shell.execute_reply": "2023-12-02T02:08:44.243786Z"
    },
    "papermill": {
     "duration": 0.019591,
     "end_time": "2023-12-02T02:08:44.246360",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.226769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerTag(SeqIndexerBase):\n",
    "    \"\"\"SeqIndexerTag converts list of lists of string tags to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        SeqIndexerBase.__init__(self, gpu=gpu, check_for_lowercase=False, zero_digits=False,\n",
    "                                      pad='<pad>', unk=None, load_embeddings=False, verbose=True)\n",
    "\n",
    "    def add_tag(self, tag):\n",
    "        if not self.item_exists(tag):\n",
    "            self.add_item(tag)\n",
    "\n",
    "    def load_items_from_tag_sequences(self, tag_sequences):\n",
    "        assert self.load_embeddings == False\n",
    "        for tag_seq in tag_sequences:\n",
    "            for tag in tag_seq:\n",
    "                self.add_tag(tag)\n",
    "        if self.verbose:\n",
    "            print('\\nload_vocabulary_from_tag_sequences:')\n",
    "            print(' -- class_num = %d' % self.get_class_num())\n",
    "            print(' --', self.item2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4fa1ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.268560Z",
     "iopub.status.busy": "2023-12-02T02:08:44.268233Z",
     "iopub.status.idle": "2023-12-02T02:08:44.274312Z",
     "shell.execute_reply": "2023-12-02T02:08:44.273509Z"
    },
    "papermill": {
     "duration": 0.019306,
     "end_time": "2023-12-02T02:08:44.276107",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.256801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqIndexerBaseChar(SeqIndexerBaseEmbeddings):\n",
    "    \"\"\"SeqIndexerBaseChar converts list of lists of characters to list of lists of integer indices and back.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        SeqIndexerBaseEmbeddings.__init__(self, gpu=gpu, check_for_lowercase=False, zero_digits=False, pad='<pad>',\n",
    "                                          unk='<unk>', load_embeddings=False, embeddings_dim=0, verbose=True)\n",
    "\n",
    "    def add_char(self, c):\n",
    "        if not self.item_exists(c):\n",
    "            self.add_item(c)\n",
    "\n",
    "    def get_char_tensor(self, curr_char_seq, word_len):\n",
    "        return SeqIndexerBaseEmbeddings.items2tensor(self, curr_char_seq, align='center', word_len=word_len)  # curr_seq_len x word_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52547186",
   "metadata": {
    "papermill": {
     "duration": 0.010496,
     "end_time": "2023-12-02T02:08:44.297064",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.286568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40743a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.319602Z",
     "iopub.status.busy": "2023-12-02T02:08:44.319290Z",
     "iopub.status.idle": "2023-12-02T02:08:44.326626Z",
     "shell.execute_reply": "2023-12-02T02:08:44.325838Z"
    },
    "papermill": {
     "duration": 0.020872,
     "end_time": "2023-12-02T02:08:44.328439",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.307567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBase(nn.Module):\n",
    "    \"\"\"Abstract base class for all type of layers.\"\"\"\n",
    "    def __init__(self, gpu):\n",
    "        super(LayerBase, self).__init__()\n",
    "        self.gpu = gpu\n",
    "\n",
    "    def tensor_ensure_gpu(self, tensor):\n",
    "        if self.is_cuda():\n",
    "            return tensor.cuda(device=self.gpu)\n",
    "        else:\n",
    "            return tensor.cpu()\n",
    "\n",
    "    def apply_mask(self, input_tensor, mask_tensor):\n",
    "        input_tensor = self.tensor_ensure_gpu(input_tensor)\n",
    "        mask_tensor = self.tensor_ensure_gpu(mask_tensor)\n",
    "        return input_tensor*mask_tensor.unsqueeze(-1).expand_as(input_tensor)\n",
    "\n",
    "    def get_seq_len_list_from_mask_tensor(self, mask_tensor):\n",
    "        batch_size = mask_tensor.shape[0]\n",
    "        return [int(mask_tensor[k].sum().item()) for k in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dca3317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.351038Z",
     "iopub.status.busy": "2023-12-02T02:08:44.350740Z",
     "iopub.status.idle": "2023-12-02T02:08:44.360611Z",
     "shell.execute_reply": "2023-12-02T02:08:44.359738Z"
    },
    "papermill": {
     "duration": 0.023316,
     "end_time": "2023-12-02T02:08:44.362418",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.339102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBiRNNBase(LayerBase):\n",
    "    \"\"\"LayerBiRNNBase is abstract base class for all bidirectional recurrent layers.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, gpu):\n",
    "        super(LayerBiRNNBase, self).__init__(gpu)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = hidden_dim * 2\n",
    "\n",
    "    def sort_by_seq_len_list(self, seq_len_list):\n",
    "        data_num = len(seq_len_list)\n",
    "        sort_indices = sorted(range(len(seq_len_list)), key=seq_len_list.__getitem__, reverse=True)\n",
    "        reverse_sort_indices = [-1 for _ in range(data_num)]\n",
    "        for i in range(data_num):\n",
    "            reverse_sort_indices[sort_indices[i]] = i\n",
    "        sort_index = self.tensor_ensure_gpu(torch.tensor(sort_indices, dtype=torch.long))\n",
    "        reverse_sort_index = self.tensor_ensure_gpu(torch.tensor(reverse_sort_indices, dtype=torch.long))\n",
    "        return sorted(seq_len_list, reverse=True), sort_index, reverse_sort_index\n",
    "\n",
    "    def pack(self, input_tensor, mask_tensor):\n",
    "        seq_len_list = self.get_seq_len_list_from_mask_tensor(mask_tensor)\n",
    "        sorted_seq_len_list, sort_index, reverse_sort_index = self.sort_by_seq_len_list(seq_len_list)\n",
    "        input_tensor_sorted = torch.index_select(input_tensor, dim=0, index=sort_index)\n",
    "        return pack_padded_sequence(input_tensor_sorted, lengths=sorted_seq_len_list, batch_first=True), \\\n",
    "               reverse_sort_index\n",
    "\n",
    "    def unpack(self, output_packed, max_seq_len, reverse_sort_index):\n",
    "        output_tensor_sorted, _ = pad_packed_sequence(output_packed, batch_first=True, total_length=max_seq_len)\n",
    "        output_tensor = torch.index_select(output_tensor_sorted, dim=0, index=reverse_sort_index)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f504a1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.384861Z",
     "iopub.status.busy": "2023-12-02T02:08:44.384595Z",
     "iopub.status.idle": "2023-12-02T02:08:44.391757Z",
     "shell.execute_reply": "2023-12-02T02:08:44.390910Z"
    },
    "papermill": {
     "duration": 0.020506,
     "end_time": "2023-12-02T02:08:44.393575",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.373069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerWordEmbeddings(LayerBase):\n",
    "    \"\"\"LayerWordEmbeddings implements word embeddings.\"\"\"\n",
    "    def __init__(self, word_seq_indexer, gpu, freeze_word_embeddings=False, pad_idx=0):\n",
    "        super(LayerWordEmbeddings, self).__init__(gpu)\n",
    "        embeddings_tensor = word_seq_indexer.get_loaded_embeddings_tensor()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=embeddings_tensor, freeze=freeze_word_embeddings)\n",
    "        self.embeddings.padding_idx = pad_idx\n",
    "        self.word_seq_indexer = word_seq_indexer\n",
    "        self.freeze_embeddings = freeze_word_embeddings\n",
    "        self.embeddings_num = embeddings_tensor.shape[0]\n",
    "        self.embeddings_dim = embeddings_tensor.shape[1]\n",
    "        self.output_dim = self.embeddings_dim\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.embeddings.weight.is_cuda\n",
    "\n",
    "    def forward(self, word_sequences):\n",
    "        input_tensor = self.tensor_ensure_gpu(self.word_seq_indexer.items2tensor(word_sequences)) # shape: batch_size x max_seq_len\n",
    "        word_embeddings_feature = self.embeddings(input_tensor) # shape: batch_size x max_seq_len x output_dim\n",
    "        return word_embeddings_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe0799f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.416065Z",
     "iopub.status.busy": "2023-12-02T02:08:44.415792Z",
     "iopub.status.idle": "2023-12-02T02:08:44.425721Z",
     "shell.execute_reply": "2023-12-02T02:08:44.424901Z"
    },
    "papermill": {
     "duration": 0.023268,
     "end_time": "2023-12-02T02:08:44.427648",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.404380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharEmbeddings(LayerBase):\n",
    "    \"\"\"LayerCharEmbeddings implements character-level embeddings.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, freeze_char_embeddings=False, word_len=20, unique_characters_list=None):\n",
    "        super(LayerCharEmbeddings, self).__init__(gpu)\n",
    "        self.gpu = gpu\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.freeze_char_embeddings = freeze_char_embeddings\n",
    "        self.word_len = word_len # standard len to pad\n",
    "        # Init character sequences indexer\n",
    "        self.char_seq_indexer = SeqIndexerBaseChar(gpu=gpu)\n",
    "        if unique_characters_list is None:\n",
    "            unique_characters_list = list(string.printable)\n",
    "        for c in unique_characters_list:\n",
    "            self.char_seq_indexer.add_char(c)\n",
    "        # Init character embedding\n",
    "        self.embeddings = nn.Embedding(num_embeddings=self.char_seq_indexer.get_items_count(),\n",
    "                                       embedding_dim=char_embeddings_dim,\n",
    "                                       padding_idx=0)\n",
    "        # nn.init.uniform_(self.embeddings.weight, -0.5, 0.5) # Option: Ma, 2016\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.embeddings.weight.is_cuda\n",
    "\n",
    "    def forward(self, word_sequences):\n",
    "        batch_num = len(word_sequences)\n",
    "        max_seq_len = max([len(word_seq) for word_seq in word_sequences])\n",
    "        char_sequences = [[[c for c in word] for word in word_seq] for word_seq in word_sequences]\n",
    "        input_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.word_len, dtype=torch.long))\n",
    "        for n, curr_char_seq in enumerate(char_sequences):\n",
    "            curr_seq_len = len(curr_char_seq)\n",
    "            curr_char_seq_tensor = self.char_seq_indexer.get_char_tensor(curr_char_seq, self.word_len) # curr_seq_len x word_len\n",
    "            input_tensor[n, :curr_seq_len, :] = curr_char_seq_tensor\n",
    "        char_embeddings_feature = self.embeddings(input_tensor)\n",
    "        return char_embeddings_feature.permute(0, 1, 3, 2) # shape: batch_num x max_seq_len x char_embeddings_dim x word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2eacb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.450043Z",
     "iopub.status.busy": "2023-12-02T02:08:44.449550Z",
     "iopub.status.idle": "2023-12-02T02:08:44.459713Z",
     "shell.execute_reply": "2023-12-02T02:08:44.458856Z"
    },
    "papermill": {
     "duration": 0.02341,
     "end_time": "2023-12-02T02:08:44.461645",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.438235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharCNN(LayerBase):\n",
    "    \"\"\"LayerCharCNN implements character-level convolutional 1D layer.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, filter_num, char_window_size, word_len):\n",
    "        super(LayerCharCNN, self).__init__(gpu)\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.char_cnn_filter_num = filter_num\n",
    "        self.char_window_size = char_window_size\n",
    "        self.word_len = word_len\n",
    "        self.output_dim = char_embeddings_dim * filter_num\n",
    "        self.conv1 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[0],\n",
    "                               groups=char_embeddings_dim,\n",
    "                               padding=\"same\")\n",
    "        self.conv2 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[1],\n",
    "                               groups=char_embeddings_dim, \n",
    "                               padding=\"same\")\n",
    "        self.conv3 = nn.Conv1d(in_channels=char_embeddings_dim,\n",
    "                               out_channels=char_embeddings_dim,\n",
    "                               kernel_size=char_window_size[2],\n",
    "                               groups=char_embeddings_dim, \n",
    "                               padding=\"same\")\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.conv1.weight.is_cuda\n",
    "\n",
    "    def forward(self, char_embeddings_feature): # batch_num x max_seq_len x char_embeddings_dim x word_len\n",
    "        batch_num, max_seq_len, char_embeddings_dim, word_len = char_embeddings_feature.shape\n",
    "        max_pooling_out = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.output_dim, dtype=torch.float))\n",
    "        for k in range(max_seq_len):\n",
    "            conv_out1 = self.conv1(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out2 = self.conv2(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out3 = self.conv3(char_embeddings_feature[:, k, :, :])\n",
    "            conv_out = torch.cat((conv_out1, conv_out2, conv_out3), dim=1)\n",
    "            max_pooling_out[:, k, :], _ = torch.max(conv_out, dim=2)\n",
    "        return max_pooling_out # shape: batch_num x max_seq_len x filter_num*char_embeddings_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6acfa40d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.484164Z",
     "iopub.status.busy": "2023-12-02T02:08:44.483898Z",
     "iopub.status.idle": "2023-12-02T02:08:44.491866Z",
     "shell.execute_reply": "2023-12-02T02:08:44.491069Z"
    },
    "papermill": {
     "duration": 0.021448,
     "end_time": "2023-12-02T02:08:44.493823",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.472375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCharBiLSTM(LayerBase):\n",
    "    \"\"\"LayerCharCNN implements character-level convolutional 1D layer.\"\"\"\n",
    "    def __init__(self, gpu, char_embeddings_dim, char_hidden_dim):\n",
    "        super(LayerCharBiLSTM, self).__init__(gpu)\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.char_hidden_dim = char_hidden_dim\n",
    "        self.output_dim = 2 * char_hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=char_embeddings_dim,\n",
    "                            hidden_size=char_hidden_dim,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.lstm.weight_hh_l0.is_cuda\n",
    "\n",
    "    def forward(self, char_embeddings_feature): # batch_num x max_seq_len x char_embeddings_dim x word_len\n",
    "        batch_num, max_seq_len, char_embeddings_dim, word_len = char_embeddings_feature.shape\n",
    "        output_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, self.output_dim, dtype=torch.float))\n",
    "        for k in range(max_seq_len):\n",
    "            input_packed = char_embeddings_feature[:,k,:,:].permute(0,2,1)\n",
    "            output_pack, _ =  self.lstm(input_packed)\n",
    "            output_tensor[:,k,:] = output_pack[:,-1,:]\n",
    "        return output_tensor  # shape: batch_size x max_seq_len x hidden_dim*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863fda00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.516767Z",
     "iopub.status.busy": "2023-12-02T02:08:44.516467Z",
     "iopub.status.idle": "2023-12-02T02:08:44.528345Z",
     "shell.execute_reply": "2023-12-02T02:08:44.527506Z"
    },
    "papermill": {
     "duration": 0.025259,
     "end_time": "2023-12-02T02:08:44.530218",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.504959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerBiLSTM(LayerBiRNNBase):\n",
    "    \"\"\"BiLSTM layer implements standard bidirectional LSTM recurrent layer\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, gpu):\n",
    "        super(LayerBiLSTM, self).__init__(input_dim, hidden_dim, gpu)\n",
    "        self.num_layers = 1\n",
    "        self.num_directions = 2\n",
    "        rnn = nn.LSTM(input_size=input_dim,\n",
    "                      hidden_size=hidden_dim,\n",
    "                      num_layers=1,\n",
    "                      batch_first=True,\n",
    "                      bidirectional=True)\n",
    "        self.rnn = rnn\n",
    "\n",
    "    def lstm_custom_init(self):\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_hh_l0)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_hh_l0_reverse)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_ih_l0)\n",
    "        nn.init.xavier_uniform_(self.rnn.weight_ih_l0_reverse)\n",
    "        self.rnn.bias_hh_l0.data.fill_(0)\n",
    "        self.rnn.bias_hh_l0_reverse.data.fill_(0)\n",
    "        self.rnn.bias_ih_l0.data.fill_(0)\n",
    "        self.rnn.bias_ih_l0_reverse.data.fill_(0)\n",
    "        # Init forget gates to 1\n",
    "        for names in self.rnn._all_weights:\n",
    "            for name in filter(lambda n: 'bias' in n, names):\n",
    "                bias = getattr(self.rnn, name)\n",
    "                n = bias.size(0)\n",
    "                start, end = n // 4, n // 2\n",
    "                bias.data[start:end].fill_(1.)\n",
    "\n",
    "    def forward(self, input_tensor, mask_tensor): #input_tensor shape: batch_size x max_seq_len x dim\n",
    "        batch_size, max_seq_len, _ = input_tensor.shape\n",
    "        input_packed, reverse_sort_index = self.pack(input_tensor, mask_tensor)\n",
    "        h0 = self.tensor_ensure_gpu(torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim))\n",
    "        c0 = self.tensor_ensure_gpu(torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim))\n",
    "        output_packed, _ = self.rnn(input_packed, (h0, c0))\n",
    "        output_tensor = self.unpack(output_packed, max_seq_len, reverse_sort_index)\n",
    "        return output_tensor  # shape: batch_size x max_seq_len x hidden_dim*2\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.rnn.weight_hh_l0.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5727835c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.553199Z",
     "iopub.status.busy": "2023-12-02T02:08:44.552926Z",
     "iopub.status.idle": "2023-12-02T02:08:44.561753Z",
     "shell.execute_reply": "2023-12-02T02:08:44.560904Z"
    },
    "papermill": {
     "duration": 0.027507,
     "end_time": "2023-12-02T02:08:44.568662",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.541155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerAttention(LayerBase):\n",
    "    def __init__(self, gpu, hidden_dim):\n",
    "        super(LayerAttention, self).__init__(gpu)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.att_weights = nn.Parameter(torch.Tensor(1, self.hidden_dim))\n",
    "        self.output_dim = hidden_dim\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_dim)\n",
    "        for weight in self.att_weights:\n",
    "            nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.att_weights.is_cuda\n",
    "\n",
    "    def forward(self, input_tensor, mask_tensor):\n",
    "        batch_size, max_len = input_tensor.size()[:2]\n",
    "        # apply attention layer\n",
    "        weights = torch.bmm(input_tensor,\n",
    "                            self.att_weights  # (1, hidden_dim)\n",
    "                            .permute(1, 0)  # (hidden_dim, 1)\n",
    "                            .unsqueeze(0)  # (1, hidden_dim, 1)\n",
    "                            .repeat(batch_size, 1, 1) # (batch_size, hidden_dim, 1)\n",
    "                            ) # (batch_size, max_seq_len, 1)\n",
    "        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-1)\n",
    "        # apply mask and renormalize attention scores (weights)\n",
    "        masked = attentions * mask_tensor\n",
    "        _sums = masked.sum(-1).unsqueeze(-1)  # sums per row\n",
    "        attentions = masked.div(_sums)\n",
    "        # apply attention weights\n",
    "        weighted = torch.mul(input_tensor, attentions.unsqueeze(-1).expand_as(input_tensor))\n",
    "        # get the final fixed vector representations of the sentences\n",
    "        representations = weighted.sum(1).squeeze()\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c44fdff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.592268Z",
     "iopub.status.busy": "2023-12-02T02:08:44.591950Z",
     "iopub.status.idle": "2023-12-02T02:08:44.622650Z",
     "shell.execute_reply": "2023-12-02T02:08:44.621792Z"
    },
    "papermill": {
     "duration": 0.044846,
     "end_time": "2023-12-02T02:08:44.624495",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.579649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerCRF(LayerBase):\n",
    "    \"\"\"LayerCRF implements Conditional Random Fields (Ma.et.al., 2016 style)\"\"\"\n",
    "    def __init__(self, gpu, states_num, pad_idx, sos_idx, tag_seq_indexer, verbose=True):\n",
    "        super(LayerCRF, self).__init__(gpu)\n",
    "        self.states_num = states_num\n",
    "        self.pad_idx = pad_idx\n",
    "        self.sos_idx = sos_idx\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.tag_seq_indexer.add_tag('<sos>')\n",
    "        self.verbose = verbose\n",
    "        # Transition matrix contains log probabilities from state j to state i\n",
    "        self.transition_matrix = nn.Parameter(torch.zeros(states_num, states_num, dtype=torch.float))\n",
    "        nn.init.normal_(self.transition_matrix, -1, 0.1)\n",
    "        # Default initialization\n",
    "        self.transition_matrix.data[self.sos_idx, :] = -9999.0\n",
    "        self.transition_matrix.data[:, self.pad_idx] = -9999.0\n",
    "        self.transition_matrix.data[self.pad_idx, :] = -9999.0\n",
    "        self.transition_matrix.data[self.pad_idx, self.pad_idx] = 0.0\n",
    "\n",
    "    def get_empirical_transition_matrix(self, tag_sequences_train, tag_seq_indexer=None):\n",
    "        if tag_seq_indexer is None:\n",
    "            tag_seq_indexer = self.tag_seq_indexer\n",
    "        empirical_transition_matrix = torch.zeros(self.states_num, self.states_num, dtype=torch.long)\n",
    "        for tag_seq in tag_sequences_train:\n",
    "            try:\n",
    "                s = tag_seq_indexer.item2idx_dict[tag_seq[0]]\n",
    "            except:\n",
    "                print(tag_seq)\n",
    "            empirical_transition_matrix[s, self.sos_idx] += 1\n",
    "            for n, tag in enumerate(tag_seq):\n",
    "                if n + 1 >= len(tag_seq):\n",
    "                    break\n",
    "                next_tag = tag_seq[n + 1]\n",
    "                j = tag_seq_indexer.item2idx_dict[tag]\n",
    "                i = tag_seq_indexer.item2idx_dict[next_tag]\n",
    "                empirical_transition_matrix[i, j] += 1\n",
    "        return empirical_transition_matrix\n",
    "\n",
    "    def init_transition_matrix_empirical(self, tag_sequences_train):\n",
    "        # Calculate statistics for tag transitions\n",
    "        empirical_transition_matrix = self.get_empirical_transition_matrix(tag_sequences_train)\n",
    "        # Initialize\n",
    "        for i in range(self.tag_seq_indexer.get_items_count()):\n",
    "            for j in range(self.tag_seq_indexer.get_items_count()):\n",
    "                if empirical_transition_matrix[i, j] == 0:\n",
    "                    self.transition_matrix.data[i, j] = -9999.0\n",
    "                #self.transition_matrix.data[i, j] = torch.log(empirical_transition_matrix[i, j].float() + 10**-32)\n",
    "        if self.verbose:\n",
    "            print('Empirical transition matrix from the train dataset:')\n",
    "            self.pretty_print_transition_matrix(empirical_transition_matrix)\n",
    "            print('\\nInitialized transition matrix:')\n",
    "            self.pretty_print_transition_matrix(self.transition_matrix.data)\n",
    "\n",
    "    def pretty_print_transition_matrix(self, transition_matrix, tag_seq_indexer=None):\n",
    "        if tag_seq_indexer is None:\n",
    "            tag_seq_indexer = self.tag_seq_indexer\n",
    "        str = '%10s' % ''\n",
    "        for i in range(tag_seq_indexer.get_items_count()):\n",
    "            str += '%10s' % tag_seq_indexer.idx2item_dict[i]\n",
    "        str += '\\n'\n",
    "        for i in range(tag_seq_indexer.get_items_count()):\n",
    "            str += '\\n%10s' % tag_seq_indexer.idx2item_dict[i]\n",
    "            for j in range(tag_seq_indexer.get_items_count()):\n",
    "                str += '%10s' % ('%1.1f' % transition_matrix[i, j])\n",
    "        print(str)\n",
    "\n",
    "    def is_cuda(self):\n",
    "        return self.transition_matrix.is_cuda\n",
    "\n",
    "    def numerator(self, features_rnn_compressed, states_tensor, mask_tensor):\n",
    "        # features_input_tensor: batch_num x max_seq_len x states_num\n",
    "        # states_tensor: batch_num x max_seq_len\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_num, max_seq_len = mask_tensor.shape\n",
    "        score = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "        start_states_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, 1, dtype=torch.long).fill_(self.sos_idx))\n",
    "        states_tensor = torch.cat([start_states_tensor, states_tensor], 1)\n",
    "        for n in range(max_seq_len):\n",
    "            curr_mask = mask_tensor[:, n]\n",
    "            curr_emission = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "            curr_transition = self.tensor_ensure_gpu(torch.zeros(batch_num, dtype=torch.float))\n",
    "            for k in range(batch_num):\n",
    "                curr_emission[k] = features_rnn_compressed[k, n, states_tensor[k, n + 1]].unsqueeze(0)\n",
    "                curr_states_seq = states_tensor[k]\n",
    "                curr_transition[k] = self.transition_matrix[curr_states_seq[n + 1], curr_states_seq[n]].unsqueeze(0)\n",
    "            score = score + curr_emission*curr_mask + curr_transition*curr_mask\n",
    "        return score\n",
    "\n",
    "    def denominator(self, features_rnn_compressed, mask_tensor):\n",
    "        # features_rnn_compressed: batch x max_seq_len x states_num\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_num, max_seq_len = mask_tensor.shape\n",
    "        score = self.tensor_ensure_gpu(torch.zeros(batch_num, self.states_num, dtype=torch.float).fill_(-9999.0))\n",
    "        score[:, self.sos_idx] = 0.\n",
    "        for n in range(max_seq_len):\n",
    "            curr_mask = mask_tensor[:, n].unsqueeze(-1).expand_as(score)\n",
    "            curr_score = score.unsqueeze(1).expand(-1, *self.transition_matrix.size())\n",
    "            curr_emission = features_rnn_compressed[:, n].unsqueeze(-1).expand_as(curr_score)\n",
    "            curr_transition = self.transition_matrix.unsqueeze(0).expand_as(curr_score)\n",
    "            #curr_score = torch.logsumexp(curr_score + curr_emission + curr_transition, dim=2)\n",
    "            curr_score = log_sum_exp(curr_score + curr_emission + curr_transition)\n",
    "            score = curr_score * curr_mask + score * (1 - curr_mask)\n",
    "        #score = torch.logsumexp(score, dim=1)\n",
    "        score = log_sum_exp(score)\n",
    "        return score\n",
    "\n",
    "    def decode_viterbi(self, features_rnn_compressed, mask_tensor):\n",
    "        # features_rnn_compressed: batch x max_seq_len x states_num\n",
    "        # mask_tensor: batch_num x max_seq_len\n",
    "        batch_size, max_seq_len = mask_tensor.shape\n",
    "        seq_len_list = [int(mask_tensor[k].sum().item()) for k in range(batch_size)]\n",
    "        # Step 1. Calculate scores & backpointers\n",
    "        score = self.tensor_ensure_gpu(torch.Tensor(batch_size, self.states_num).fill_(-9999.))\n",
    "        score[:, self.sos_idx] = 0.0\n",
    "        backpointers = self.tensor_ensure_gpu(torch.LongTensor(batch_size, max_seq_len, self.states_num))\n",
    "        for n in range(max_seq_len):\n",
    "            curr_emissions = features_rnn_compressed[:, n]\n",
    "            curr_score = self.tensor_ensure_gpu(torch.Tensor(batch_size, self.states_num))\n",
    "            curr_backpointers = self.tensor_ensure_gpu(torch.LongTensor(batch_size, self.states_num))\n",
    "            for curr_state in range(self.states_num):\n",
    "                T = self.transition_matrix[curr_state, :].unsqueeze(0).expand(batch_size, self.states_num)\n",
    "                max_values, max_indices = torch.max(score + T, 1)\n",
    "                curr_score[:, curr_state] = max_values\n",
    "                curr_backpointers[:, curr_state] = max_indices\n",
    "            curr_mask = mask_tensor[:, n].unsqueeze(1).expand(batch_size, self.states_num)\n",
    "            score = score * (1 - curr_mask) + (curr_score + curr_emissions) * curr_mask\n",
    "            backpointers[:, n, :] = curr_backpointers # shape: batch_size x max_seq_len x state_num\n",
    "        best_score_batch, last_best_state_batch = torch.max(score, 1)\n",
    "        # Step 2. Find the best path\n",
    "        best_path_batch = [[state] for state in last_best_state_batch.tolist()]\n",
    "        for k in range(batch_size):\n",
    "            curr_best_state = last_best_state_batch[k]\n",
    "            curr_seq_len = seq_len_list[k]\n",
    "            for n in reversed(range(1, curr_seq_len)):\n",
    "                curr_best_state = backpointers[k, n, curr_best_state].item()\n",
    "                best_path_batch[k].insert(0, curr_best_state)\n",
    "        return best_path_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80a26c",
   "metadata": {
    "papermill": {
     "duration": 0.014306,
     "end_time": "2023-12-02T02:08:44.706960",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.692654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f0441c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.732256Z",
     "iopub.status.busy": "2023-12-02T02:08:44.731776Z",
     "iopub.status.idle": "2023-12-02T02:08:44.758336Z",
     "shell.execute_reply": "2023-12-02T02:08:44.757424Z"
    },
    "papermill": {
     "duration": 0.042052,
     "end_time": "2023-12-02T02:08:44.760345",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.718293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerBase(nn.Module):\n",
    "    \"\"\"TaggerBase is an abstract class for tagger models. It implements the tagging functionality for\n",
    "    different types of inputs (sequences of tokens, sequences of integer indices, tensors). Auxiliary class\n",
    "    SequencesIndexer is used for input and output data formats conversions. Abstract method `forward` is used in order\n",
    "    to make these predictions, it have to be implemented in ancestors.\"\"\"\n",
    "    def __init__(self,  word_seq_indexer, tag_seq_indexer, gpu, batch_size):\n",
    "        super(TaggerBase, self).__init__()\n",
    "        self.word_seq_indexer = word_seq_indexer\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.gpu = gpu\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def tensor_ensure_gpu(self, tensor):\n",
    "        if self.gpu >= 0:\n",
    "            return tensor.cuda(device=self.gpu)\n",
    "        else:\n",
    "            return tensor\n",
    "\n",
    "    def self_ensure_gpu(self):\n",
    "        if self.gpu >= 0:\n",
    "            self.cuda(device=self.gpu)\n",
    "        else:\n",
    "            self.cpu()\n",
    "\n",
    "    def save_tagger(self, checkpoint_fn):\n",
    "        self.cpu()\n",
    "        torch.save(self, checkpoint_fn)\n",
    "        self.self_ensure_gpu()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        pass\n",
    "\n",
    "    def predict_idx_from_words(self, word_sequences):\n",
    "        self.eval()\n",
    "        outputs_tensor = self.forward(word_sequences) # batch_size x num_class+1 x max_seq_len\n",
    "        output_idx_sequences = list()\n",
    "        for k in range(len(word_sequences)):\n",
    "            idx_seq = list()\n",
    "            for l in range(len(word_sequences[k])):\n",
    "                curr_output = outputs_tensor[k, 1:, l] # ignore the first component of output\n",
    "                max_no = curr_output.argmax(dim=0)\n",
    "                idx_seq.append(max_no.item() + 1)\n",
    "            output_idx_sequences.append(idx_seq)\n",
    "        return output_idx_sequences\n",
    "\n",
    "    def predict_tags_from_words(self, word_sequences, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = self.batch_size\n",
    "        print('\\n')\n",
    "        batch_num = math.floor(len(word_sequences) / batch_size)\n",
    "        if len(word_sequences) > 0 and len(word_sequences) < batch_size:\n",
    "            batch_num = 1\n",
    "        output_tag_sequences = list()\n",
    "        for n in range(batch_num):\n",
    "            i = n*batch_size\n",
    "            if n < batch_num - 1:\n",
    "                j = (n + 1)*batch_size\n",
    "            else:\n",
    "                j = len(word_sequences)\n",
    "            curr_output_idx = self.predict_idx_from_words(word_sequences[i:j])\n",
    "            curr_output_tag_sequences = self.tag_seq_indexer.idx2items(curr_output_idx)\n",
    "            output_tag_sequences.extend(curr_output_tag_sequences)\n",
    "            print('\\r++ predicting, batch %d/%d (%1.2f%%).' % (n + 1, batch_num, math.ceil(n * 100.0 / batch_num)),\n",
    "                  end='', flush=True)\n",
    "        return output_tag_sequences\n",
    "\n",
    "    def get_mask_from_word_sequences(self, word_sequences):\n",
    "        batch_num = len(word_sequences)\n",
    "        max_seq_len = max([len(word_seq) for word_seq in word_sequences])\n",
    "        mask_tensor = self.tensor_ensure_gpu(torch.zeros(batch_num, max_seq_len, dtype=torch.float))\n",
    "        for k, word_seq in enumerate(word_sequences):\n",
    "            mask_tensor[k, :len(word_seq)] = 1\n",
    "        return mask_tensor # batch_size x max_seq_len\n",
    "\n",
    "    def apply_mask(self, input_tensor, mask_tensor):\n",
    "        input_tensor = self.tensor_ensure_gpu(input_tensor)\n",
    "        mask_tensor = self.tensor_ensure_gpu(mask_tensor)\n",
    "        return input_tensor*mask_tensor.unsqueeze(-1).expand_as(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d5f8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.784779Z",
     "iopub.status.busy": "2023-12-02T02:08:44.784377Z",
     "iopub.status.idle": "2023-12-02T02:08:44.811140Z",
     "shell.execute_reply": "2023-12-02T02:08:44.810219Z"
    },
    "papermill": {
     "duration": 0.041307,
     "end_time": "2023-12-02T02:08:44.813141",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.771834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerBiRNNCNNCRF(TaggerBase):\n",
    "    \"\"\"TaggerBiRNNCNNCRF is a model for sequences tagging that includes recurrent network + conv layer + CRF.\"\"\"\n",
    "    def __init__(self, word_seq_indexer, tag_seq_indexer, class_num, batch_size=1, rnn_hidden_dim=100,\n",
    "                 emb_dim = 200, freeze_word_embeddings=False, dropout_ratio=0.5, rnn_type='GRU', gpu=-1,\n",
    "                 freeze_char_embeddings = False, char_embeddings_dim=100, word_len=20, char_cnn_filter_num=30,\n",
    "                 char_window_size=3):\n",
    "        super(TaggerBiRNNCNNCRF, self).__init__(word_seq_indexer, tag_seq_indexer, gpu, batch_size)\n",
    "        self.tag_seq_indexer = tag_seq_indexer\n",
    "        self.class_num = class_num\n",
    "        self.rnn_hidden_dim = rnn_hidden_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.freeze_embeddings = freeze_word_embeddings\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.rnn_type = rnn_type\n",
    "        self.gpu = gpu\n",
    "        self.word_embeddings_layer = LayerWordEmbeddings(word_seq_indexer, gpu, freeze_word_embeddings)\n",
    "        self.freeze_char_embeddings = freeze_char_embeddings\n",
    "        self.char_embeddings_dim = char_embeddings_dim\n",
    "        self.word_len = word_len\n",
    "        self.char_cnn_filter_num = char_cnn_filter_num\n",
    "        self.char_window_size = char_window_size\n",
    "        self.word_embeddings_layer = LayerWordEmbeddings(word_seq_indexer, gpu, freeze_word_embeddings)\n",
    "        self.char_embeddings_layer = LayerCharEmbeddings(gpu, char_embeddings_dim, freeze_char_embeddings,\n",
    "                                                         word_len, word_seq_indexer.get_unique_characters_list())\n",
    "        self.char_cnn_layer = LayerCharCNN(gpu, char_embeddings_dim, char_cnn_filter_num, char_window_size,\n",
    "                                           word_len)\n",
    "        self.char_lstm_layer = LayerCharBiLSTM(gpu,char_embeddings_dim,char_embeddings_dim)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "        if rnn_type == 'GRU':\n",
    "            self.birnn_layer = LayerBiGRU(input_dim=self.emb_dim,\n",
    "                                          hidden_dim=rnn_hidden_dim,\n",
    "                                          gpu=gpu)\n",
    "        elif rnn_type == 'LSTM':\n",
    "            self.birnn_layer = LayerBiLSTM(input_dim=self.emb_dim,\n",
    "                                           hidden_dim=rnn_hidden_dim,\n",
    "                                           gpu=gpu)\n",
    "        else:\n",
    "            raise ValueError('Unknown rnn_type = %s, must be either \"LSTM\" or \"GRU\"')\n",
    "        self.lin_layer1 = nn.Linear(in_features=self.word_embeddings_layer.output_dim + self.char_cnn_layer.output_dim + self.char_lstm_layer.output_dim, \n",
    "                                    out_features=self.emb_dim)\n",
    "        self.att_layer = LayerAttention(gpu=gpu, hidden_dim=self.birnn_layer.output_dim)\n",
    "        self.lin_layer2 = nn.Linear(in_features=self.birnn_layer.output_dim + self.att_layer.output_dim, out_features=class_num + 2)\n",
    "        self.crf_layer = LayerCRF(gpu, states_num=class_num + 2, pad_idx=tag_seq_indexer.pad_idx, sos_idx=class_num + 1,\n",
    "                                  tag_seq_indexer=tag_seq_indexer)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        if gpu >= 0:\n",
    "            self.cuda(device=self.gpu)\n",
    "\n",
    "    def _forward_birnn(self, word_sequences):\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences)\n",
    "        z_word_embed = self.word_embeddings_layer(word_sequences)\n",
    "        z_word_embed_d = self.dropout(z_word_embed)\n",
    "        z_char_embed = self.char_embeddings_layer(word_sequences)\n",
    "        z_char_cnn = self.char_cnn_layer(z_char_embed)\n",
    "        z_char_cnn_d = self.dropout(z_char_cnn)\n",
    "        z_char_lstm = self.char_lstm_layer(z_char_embed)\n",
    "        z_char_lstm_d = self.dropout(z_char_lstm)\n",
    "        z = torch.cat((z_word_embed_d, z_char_cnn_d, z_char_lstm_d), dim=2)\n",
    "        z = self.lin_layer1(z)\n",
    "        rnn_output_h = self.apply_mask(self.birnn_layer(z, mask), mask)\n",
    "        att_rnn_output = self.att_layer(rnn_output_h, mask)\n",
    "        features_rnn_att = torch.cat((rnn_output_h, att_rnn_output), dim=2)\n",
    "        features_rnn_compressed = self.lin_layer2(features_rnn_att)\n",
    "        return self.apply_mask(features_rnn_compressed, mask)\n",
    "\n",
    "    def get_loss(self, word_sequences_train_batch, tag_sequences_train_batch):\n",
    "        targets_tensor_train_batch = self.tag_seq_indexer.items2tensor(tag_sequences_train_batch)\n",
    "        features_rnn = self._forward_birnn(word_sequences_train_batch) # batch_num x max_seq_len x class_num\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences_train_batch)  # batch_num x max_seq_len\n",
    "        numerator = self.crf_layer.numerator(features_rnn, targets_tensor_train_batch, mask)\n",
    "        denominator = self.crf_layer.denominator(features_rnn, mask)\n",
    "        nll_loss = -torch.mean(numerator - denominator)\n",
    "        return nll_loss\n",
    "\n",
    "    def predict_idx_from_words(self, word_sequences, no=-1):\n",
    "        self.eval()\n",
    "        features_rnn_compressed_masked  = self._forward_birnn(word_sequences)\n",
    "        mask = self.get_mask_from_word_sequences(word_sequences)\n",
    "        idx_sequences = self.crf_layer.decode_viterbi(features_rnn_compressed_masked, mask)\n",
    "        return idx_sequences\n",
    "\n",
    "    def predict_tags_from_words(self, word_sequences, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = self.batch_size\n",
    "        print('\\n')\n",
    "        batch_num = math.floor(len(word_sequences) / batch_size)\n",
    "        if len(word_sequences) > 0 and len(word_sequences) < batch_size:\n",
    "            batch_num = 1\n",
    "        output_tag_sequences = list()\n",
    "        for n in range(batch_num):\n",
    "            i = n*batch_size\n",
    "            if n < batch_num - 1:\n",
    "                j = (n + 1)*batch_size\n",
    "            else:\n",
    "                j = len(word_sequences)\n",
    "            if batch_size == 1:\n",
    "                curr_output_idx = self.predict_idx_from_words(word_sequences[i:j], n)\n",
    "            else:\n",
    "                curr_output_idx = self.predict_idx_from_words(word_sequences[i:j], -1)\n",
    "            curr_output_tag_sequences = self.tag_seq_indexer.idx2items(curr_output_idx)\n",
    "            output_tag_sequences.extend(curr_output_tag_sequences)\n",
    "            print('\\r++ predicting, batch %d/%d (%1.2f%%).' % (n + 1, batch_num, math.ceil(n * 100.0 / batch_num)),\n",
    "                  end='', flush=True)\n",
    "        return output_tag_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98057288",
   "metadata": {
    "papermill": {
     "duration": 0.011208,
     "end_time": "2023-12-02T02:08:44.837527",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.826319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fce2119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.868247Z",
     "iopub.status.busy": "2023-12-02T02:08:44.867582Z",
     "iopub.status.idle": "2023-12-02T02:08:44.875854Z",
     "shell.execute_reply": "2023-12-02T02:08:44.874880Z"
    },
    "papermill": {
     "duration": 0.028965,
     "end_time": "2023-12-02T02:08:44.877935",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.848970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorBase():\n",
    "    \"\"\"EvaluatorBase is abstract base class for all evaluators\"\"\"\n",
    "    def get_evaluation_score_train_dev_test(self, tagger, datasets_bank, batch_size=-1):\n",
    "        if batch_size == -1:\n",
    "            batch_size = tagger.batch_size\n",
    "        score_train, _ = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                       word_sequences=datasets_bank.word_sequences_train,\n",
    "                                                       targets_tag_sequences=datasets_bank.tag_sequences_train,\n",
    "                                                       batch_size=batch_size)\n",
    "        score_dev, _ = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                     word_sequences=datasets_bank.word_sequences_dev,\n",
    "                                                     targets_tag_sequences=datasets_bank.tag_sequences_dev,\n",
    "                                                     batch_size=batch_size)\n",
    "        score_test, msg_test = self.predict_evaluation_score(tagger=tagger,\n",
    "                                                             word_sequences=datasets_bank.word_sequences_test,\n",
    "                                                             targets_tag_sequences=datasets_bank.tag_sequences_test,\n",
    "                                                             batch_size=batch_size)\n",
    "        return score_train, score_dev, score_test, msg_test\n",
    "\n",
    "    def predict_evaluation_score(self, tagger, word_sequences, targets_tag_sequences, batch_size):\n",
    "        outputs_tag_sequences = tagger.predict_tags_from_words(word_sequences, batch_size)\n",
    "        return self.get_evaluation_score(targets_tag_sequences, outputs_tag_sequences, word_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17f28dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.902545Z",
     "iopub.status.busy": "2023-12-02T02:08:44.902152Z",
     "iopub.status.idle": "2023-12-02T02:08:44.920093Z",
     "shell.execute_reply": "2023-12-02T02:08:44.919257Z"
    },
    "papermill": {
     "duration": 0.032416,
     "end_time": "2023-12-02T02:08:44.921956",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.889540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorF1MacroTokenLevel(EvaluatorBase):\n",
    "    def __init__(self):\n",
    "        self.tag_list = None\n",
    "        self.tag2idx = dict()\n",
    "\n",
    "    def __init_tag_list(self, targets_tag_sequences):\n",
    "        if self.tag_list is not None:\n",
    "            return\n",
    "        self.tag_list = list()\n",
    "        for tag_seq in targets_tag_sequences:\n",
    "            for t in tag_seq:\n",
    "                if t not in self.tag_list:\n",
    "                    self.tag_list.append(t)\n",
    "                    self.tag2idx[t] = len(self.tag_list)\n",
    "        self.tag_list.sort()\n",
    "\n",
    "    def tag_seq_2_idx_list(self, tag_seq):\n",
    "        return [self.tag2idx[t] for t in tag_seq]\n",
    "\n",
    "    def __get_zeros_tag_dict(self):\n",
    "        return {tag: 0 for tag in self.tag_list}\n",
    "\n",
    "    def __add_dict(self, dict1, dict2):\n",
    "        for tag in self.tag_list:\n",
    "            dict1[tag] += dict2[tag]\n",
    "        return dict1\n",
    "\n",
    "    def __div_dict(self, dict, d):\n",
    "        for tag in self.tag_list:\n",
    "            dict[tag] /= d\n",
    "        return dict\n",
    "\n",
    "    def __get_M_F1_msg(self, F1):\n",
    "        msg = '\\nF1 scores\\n'\n",
    "        msg += '-' * 24 + '\\n'\n",
    "        sum_M_F1 = 0\n",
    "        for tag in self.tag_list:\n",
    "            sum_M_F1 += F1[tag]\n",
    "            msg += '%15s = %1.2f\\n' % (tag, F1[tag])\n",
    "        M_F1 = sum_M_F1 / len(F1)\n",
    "        msg += '-'*24 + '\\n'\n",
    "        msg += 'Macro-F1 = %1.3f' % M_F1\n",
    "        return M_F1, msg\n",
    "\n",
    "    def __add_to_dict(self, dict_in, tag, val):\n",
    "        if tag in dict_in:\n",
    "            dict_in[tag] += val\n",
    "        else:\n",
    "            dict_in[tag] = val\n",
    "        return dict_in\n",
    "\n",
    "    \"\"\"EvaluatorF1MacroTagComponents is macro-F1 scores evaluator for each class of BOI-like tags.\"\"\"\n",
    "    def get_evaluation_score(self, targets_tag_sequences, outputs_tag_sequences, word_sequences=None):\n",
    "        # Create list of tags\n",
    "        self.__init_tag_list(targets_tag_sequences)\n",
    "        # Init values\n",
    "        TP = self.__get_zeros_tag_dict()\n",
    "        FP = self.__get_zeros_tag_dict()\n",
    "        FN = self.__get_zeros_tag_dict()\n",
    "        F1 = self.__get_zeros_tag_dict()\n",
    "        for targets_seq, outputs_tag_seq in zip(targets_tag_sequences, outputs_tag_sequences):\n",
    "            for t, o in zip(targets_seq, outputs_tag_seq):\n",
    "                if t == o:\n",
    "                    TP = self.__add_to_dict(TP, t, 1)\n",
    "                else:\n",
    "                    FN = self.__add_to_dict(FN, t, 1)\n",
    "                    FP = self.__add_to_dict(FP, o, 1)\n",
    "        # Calculate F1 for each tag\n",
    "        for tag in self.tag_list:\n",
    "            F1[tag] = (2 * TP[tag] / max(2 * TP[tag] + FP[tag] + FN[tag], 1)) * 100\n",
    "        # Calculate Macro-F1 score and prepare the message\n",
    "        M_F1, msg = self.__get_M_F1_msg(F1)\n",
    "        print(msg)\n",
    "        #self.validate_M_F1_scikitlearn( targets_tag_sequences, outputs_tag_sequences)\n",
    "        return M_F1, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0082e2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:44.945976Z",
     "iopub.status.busy": "2023-12-02T02:08:44.945698Z",
     "iopub.status.idle": "2023-12-02T02:08:44.951915Z",
     "shell.execute_reply": "2023-12-02T02:08:44.950975Z"
    },
    "papermill": {
     "duration": 0.020861,
     "end_time": "2023-12-02T02:08:44.954253",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.933392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorAccuracyTokenLevel(EvaluatorBase):\n",
    "    \"\"\"EvaluatorAccuracyTokenLevel is token-level accuracy evaluator for each class of BOI-like tags.\"\"\"\n",
    "    def get_evaluation_score(self, targets_tag_sequences, outputs_tag_sequences, word_sequences=None):\n",
    "        cnt = 0\n",
    "        match = 0\n",
    "        for target_seq, output_seq in zip(targets_tag_sequences, outputs_tag_sequences):\n",
    "            for t, o in zip(target_seq, output_seq):\n",
    "                cnt += 1\n",
    "                if t == o:\n",
    "                    match += 1\n",
    "        acc = match*100.0/cnt\n",
    "        msg = '*** Token-level accuracy: %1.2f%% ***' % acc\n",
    "        return acc, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddfd00",
   "metadata": {
    "papermill": {
     "duration": 0.011487,
     "end_time": "2023-12-02T02:08:44.980776",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.969289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c08bdc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.006451Z",
     "iopub.status.busy": "2023-12-02T02:08:45.005634Z",
     "iopub.status.idle": "2023-12-02T02:08:45.021070Z",
     "shell.execute_reply": "2023-12-02T02:08:45.020228Z"
    },
    "papermill": {
     "duration": 0.030591,
     "end_time": "2023-12-02T02:08:45.023227",
     "exception": false,
     "start_time": "2023-12-02T02:08:44.992636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Report():\n",
    "    def __init__(self, fn, args, score_names):\n",
    "        \"\"\"Report stores evaluation results during the training process as text files.\"\"\"\n",
    "        self.fn = fn\n",
    "        self.args = args\n",
    "        self.score_num = len(score_names)\n",
    "        self.text = 'Evaluation\\n\\n'\n",
    "        self.text += '\\n'.join([hp for hp in str(args).replace('Namespace(', '').replace(')', '').split(', ')])\n",
    "        header = '\\n\\n %14s |' % 'epoch '\n",
    "        for n, score_name in enumerate(score_names):\n",
    "            header += ' %14s ' % score_name\n",
    "            if n < len(score_names) - 1: header += '|'\n",
    "        self.text += header\n",
    "        self.blank_line = '\\n' + '-' * len(header)\n",
    "        self.text += self.blank_line\n",
    "\n",
    "    def write_epoch_scores(self, epoch, scores):\n",
    "        self.text += '\\n %14s |' % ('%d'% epoch)\n",
    "        for n, score in enumerate(scores):\n",
    "            self.text += ' %14s ' % ('%1.2f' % score)\n",
    "            if n < len(scores) - 1: self.text += '|'\n",
    "        self.__save()\n",
    "\n",
    "    def write_final_score(self, final_score_str):\n",
    "        self.text += self.blank_line\n",
    "        self.text += '\\n%s' % final_score_str\n",
    "        self.__save()\n",
    "\n",
    "    def write_msg(self, msg):\n",
    "        self.text += self.blank_line\n",
    "        self.text += msg\n",
    "        self.__save()\n",
    "\n",
    "    def write_input_arguments(self):\n",
    "        self.text += '\\nInput arguments:\\n%s' % get_input_arguments()\n",
    "        self.__save()\n",
    "\n",
    "    def write_final_line_score(self, final_score):\n",
    "        self.text += '\\n\\n%1.4f' % final_score\n",
    "        self.__save()\n",
    "\n",
    "    def __save(self):\n",
    "        if self.fn is not None:\n",
    "            with open(self.fn, mode='w') as text_file:\n",
    "                text_file.write(self.text)\n",
    "\n",
    "    def make_print(self):\n",
    "        print(self.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0748677",
   "metadata": {
    "papermill": {
     "duration": 0.013635,
     "end_time": "2023-12-02T02:08:45.050231",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.036596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caa72c58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.077768Z",
     "iopub.status.busy": "2023-12-02T02:08:45.076803Z",
     "iopub.status.idle": "2023-12-02T02:08:45.083656Z",
     "shell.execute_reply": "2023-12-02T02:08:45.082750Z"
    },
    "papermill": {
     "duration": 0.022538,
     "end_time": "2023-12-02T02:08:45.085955",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.063417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataIOFactory():\n",
    "    \"\"\"DataIOFactory contains wrappers to create various data readers/writers.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.data_io == 'ncbi_disease':\n",
    "            return DataIONCBI(dataset_name = args.data_io, \n",
    "                              train_no = args.train_no, \n",
    "                              dev_no = args.dev_no,\n",
    "                              test_no = args.test_no\n",
    "                             )\n",
    "        else:\n",
    "            raise ValueError('Unknown DataIO %s.' % args.data_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c77447d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.116162Z",
     "iopub.status.busy": "2023-12-02T02:08:45.115372Z",
     "iopub.status.idle": "2023-12-02T02:08:45.121347Z",
     "shell.execute_reply": "2023-12-02T02:08:45.120474Z"
    },
    "papermill": {
     "duration": 0.020633,
     "end_time": "2023-12-02T02:08:45.123257",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.102624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetsBankFactory():\n",
    "    \"\"\"DatasetsBankFactory contains wrappers to create various datasets banks.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.dataset_sort:\n",
    "            datasets_bank = DatasetsBankSorted(verbose=True)\n",
    "        else:\n",
    "            datasets_bank = DatasetsBank(verbose=True)\n",
    "        return datasets_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f73d6905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.148279Z",
     "iopub.status.busy": "2023-12-02T02:08:45.147688Z",
     "iopub.status.idle": "2023-12-02T02:08:45.160058Z",
     "shell.execute_reply": "2023-12-02T02:08:45.159231Z"
    },
    "papermill": {
     "duration": 0.026863,
     "end_time": "2023-12-02T02:08:45.161909",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.135046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggerFactory():\n",
    "    \"\"\"TaggerFactory contains wrappers to create various tagger models.\"\"\"\n",
    "    @staticmethod\n",
    "    def load(checkpoint_fn, gpu=-1):\n",
    "        if not os.path.isfile(checkpoint_fn):\n",
    "            raise ValueError('Can''t find tagger in file \"%s\". Please, run the main script with non-empty \\\n",
    "                             \"--save-best-path\" param to create it.' % checkpoint_fn)\n",
    "        tagger = torch.load(checkpoint_fn)\n",
    "        tagger.gpu = gpu\n",
    "\n",
    "        tagger.word_seq_indexer.gpu = gpu # hotfix\n",
    "        tagger.tag_seq_indexer.gpu = gpu # hotfix\n",
    "        if hasattr(tagger, 'char_embeddings_layer'):# very hot hotfix\n",
    "            tagger.char_embeddings_layer.char_seq_indexer.gpu = gpu # hotfix\n",
    "        tagger.self_ensure_gpu()\n",
    "        return tagger\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create(args, word_seq_indexer, tag_seq_indexer, tag_sequences_train):\n",
    "        if args.model == 'BiRNNCNNCRF':\n",
    "            tagger = TaggerBiRNNCNNCRF(word_seq_indexer=word_seq_indexer,\n",
    "                                       tag_seq_indexer=tag_seq_indexer,\n",
    "                                       class_num=tag_seq_indexer.get_class_num(),\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       rnn_hidden_dim=args.rnn_hidden_dim,\n",
    "                                       emb_dim=args.emb_dim,\n",
    "                                       freeze_word_embeddings=args.freeze_word_embeddings,\n",
    "                                       dropout_ratio=args.dropout_ratio,\n",
    "                                       rnn_type=args.rnn_type,\n",
    "                                       gpu=args.gpu,\n",
    "                                       freeze_char_embeddings=args.freeze_char_embeddings,\n",
    "                                       char_embeddings_dim=args.char_embeddings_dim,\n",
    "                                       word_len=args.word_len,\n",
    "                                       char_cnn_filter_num=args.char_cnn_filter_num,\n",
    "                                       char_window_size=args.char_window_size)\n",
    "            tagger.crf_layer.init_transition_matrix_empirical(tag_sequences_train)\n",
    "        else:\n",
    "            raise ValueError('Unknown tagger model')\n",
    "        return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76823381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.186723Z",
     "iopub.status.busy": "2023-12-02T02:08:45.186081Z",
     "iopub.status.idle": "2023-12-02T02:08:45.193690Z",
     "shell.execute_reply": "2023-12-02T02:08:45.192831Z"
    },
    "papermill": {
     "duration": 0.022735,
     "end_time": "2023-12-02T02:08:45.196208",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.173473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvaluatorFactory():\n",
    "    \"\"\"EvaluatorFactory contains wrappers to create various evaluators.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args):\n",
    "        if args.evaluator == 'f1-connl':\n",
    "            return EvaluatorF1MicroSpansConnl()\n",
    "        elif args.evaluator == 'f1-alpha-match-10':\n",
    "            return EvaluatorF1MicroSpansAlphaMatch10()\n",
    "        elif args.evaluator == 'f1-alpha-match-05':\n",
    "            return EvaluatorF1MicroSpansAlphaMatch05()\n",
    "        elif args.evaluator == 'f1-macro':\n",
    "            return EvaluatorF1MacroTokenLevel()\n",
    "        elif args.evaluator == 'f05-macro':\n",
    "            return EvaluatorF05MacroTokenLevel()\n",
    "        elif args.evaluator == 'token-acc':\n",
    "            return EvaluatorAccuracyTokenLevel()\n",
    "        else:\n",
    "            raise ValueError('Unknown evaluator %s.' % args.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464955a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.225590Z",
     "iopub.status.busy": "2023-12-02T02:08:45.224960Z",
     "iopub.status.idle": "2023-12-02T02:08:45.233343Z",
     "shell.execute_reply": "2023-12-02T02:08:45.232513Z"
    },
    "papermill": {
     "duration": 0.023138,
     "end_time": "2023-12-02T02:08:45.235297",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.212159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptimizerFactory():\n",
    "    \"\"\"OptimizerFactory contains wrappers to create various optimizers.\"\"\"\n",
    "    @staticmethod\n",
    "    def create(args, tagger):\n",
    "        if args.opt == 'sgd':\n",
    "            optimizer = optim.SGD(list(tagger.parameters()), lr=args.lr, momentum=args.momentum)\n",
    "        elif args.opt == 'adam':\n",
    "            optimizer = optim.Adam(list(tagger.parameters()), lr=args.lr, \n",
    "                                   betas=(0.9, 0.999),\n",
    "                                   weight_decay = args.weight_decay\n",
    "                                  )\n",
    "        else:\n",
    "            raise ValueError('Unknown optimizer, must be one of \"sgd\"/\"adam\".')\n",
    "        scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: args.lr_decay ** epoch)\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe85386",
   "metadata": {
    "papermill": {
     "duration": 0.011334,
     "end_time": "2023-12-02T02:08:45.258448",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.247114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a0a72c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.283617Z",
     "iopub.status.busy": "2023-12-02T02:08:45.282901Z",
     "iopub.status.idle": "2023-12-02T02:08:45.294252Z",
     "shell.execute_reply": "2023-12-02T02:08:45.293283Z"
    },
    "papermill": {
     "duration": 0.026154,
     "end_time": "2023-12-02T02:08:45.296271",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.270117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> CONFIG DONE\n"
     ]
    }
   ],
   "source": [
    "class ARGS:\n",
    "    seed = 101\n",
    "    verbose = True\n",
    "    debug = False\n",
    "    data_io = \"ncbi_disease\"\n",
    "    train_no = None\n",
    "    dev_no = None\n",
    "    test_no = None\n",
    "    model = 'BiRNNCNNCRF'\n",
    "    rnn_type = 'LSTM'\n",
    "    load = None\n",
    "    epoch_num = 10\n",
    "    min_epoch_num = 1\n",
    "    batch_size = 16\n",
    "    gpu = 0\n",
    "    check_for_lowercase = True\n",
    "    emb_fn = \"/kaggle/input/glove6b/glove.6B.200d.txt\"\n",
    "    emb_dim = 200\n",
    "    emb_delimiter = ' '\n",
    "    emb_load_all = False\n",
    "    freeze_word_embeddings = False\n",
    "    rnn_hidden_dim = 200\n",
    "    ## Character CNN config\n",
    "    word_len = 20\n",
    "    char_embeddings_dim = 100\n",
    "    freeze_char_embeddings = False\n",
    "    char_window_size = [4,3,2]\n",
    "    char_cnn_filter_num =len(char_window_size)\n",
    "    \n",
    "    dropout_ratio = 0.5\n",
    "    dataset_sort = False\n",
    "    word_seq_indexer = None\n",
    "    evaluator = 'f1-macro'\n",
    "    opt = 'adam'\n",
    "    lr = 0.001 # in paper\n",
    "    lr_decay = 0.95\n",
    "    weight_decay = 5e-4\n",
    "    momentum = 0.95\n",
    "    patience = 4 # in paper\n",
    "    report_fn = '%s_report.txt' % get_datetime_str()\n",
    "    clip_grad = 5\n",
    "    save = '%s_tagger.hdf5' % get_datetime_str()\n",
    "    save_best = True\n",
    "    \n",
    "args = ARGS()\n",
    "print('> CONFIG DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe8653a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.321568Z",
     "iopub.status.busy": "2023-12-02T02:08:45.321208Z",
     "iopub.status.idle": "2023-12-02T02:08:45.333604Z",
     "shell.execute_reply": "2023-12-02T02:08:45.332528Z"
    },
    "papermill": {
     "duration": 0.027116,
     "end_time": "2023-12-02T02:08:45.335477",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.308361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = args.seed):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc3f5e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.361389Z",
     "iopub.status.busy": "2023-12-02T02:08:45.361035Z",
     "iopub.status.idle": "2023-12-02T02:08:45.385032Z",
     "shell.execute_reply": "2023-12-02T02:08:45.384237Z"
    },
    "papermill": {
     "duration": 0.039371,
     "end_time": "2023-12-02T02:08:45.386993",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.347622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if args.gpu >= 0:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "    \n",
    "    # Load text data as lists of lists of words (sequences) and corresponding list of lists of tags\n",
    "    data_io = DataIOFactory.create(args)\n",
    "    word_sequences_train, tag_sequences_train, word_sequences_dev, tag_sequences_dev, word_sequences_test, tag_sequences_test = data_io.read_train_dev_test(args)\n",
    "    \n",
    "    ## Dataset\n",
    "    datasets_bank = DatasetsBankFactory.create(args)\n",
    "    datasets_bank.add_train_sequences(word_sequences_train, tag_sequences_train)\n",
    "    datasets_bank.add_dev_sequences(word_sequences_dev, tag_sequences_dev)\n",
    "    datasets_bank.add_test_sequences(word_sequences_test, tag_sequences_test)\n",
    "    \n",
    "    # Word_seq_indexer converts lists of lists of words to lists of lists of integer indices and back\n",
    "    word_seq_indexer = SeqIndexerWord(gpu=args.gpu, check_for_lowercase=args.check_for_lowercase,\n",
    "                                      embeddings_dim=args.emb_dim, verbose=True)\n",
    "    word_seq_indexer.load_items_from_embeddings_file_and_unique_words_list(emb_fn=args.emb_fn,\n",
    "                                                                           emb_delimiter=args.emb_delimiter,\n",
    "                                                                           emb_load_all=args.emb_load_all,\n",
    "                                                                           unique_words_list=datasets_bank.unique_words_list)\n",
    "\n",
    "    \n",
    "    if args.word_seq_indexer is not None and not isfile(args.word_seq_indexer):\n",
    "        torch.save(word_seq_indexer, args.word_seq_indexer)\n",
    "    # Tag_seq_indexer converts lists of lists of tags to lists of lists of integer indices and back\n",
    "    tag_seq_indexer = SeqIndexerTag(gpu=args.gpu)\n",
    "    tag_seq_indexer.load_items_from_tag_sequences(tag_sequences_train)\n",
    "    # Create or load pre-trained tagger\n",
    "    if args.load is None:\n",
    "        tagger = TaggerFactory.create(args, word_seq_indexer, tag_seq_indexer, tag_sequences_train)\n",
    "    else:\n",
    "        tagger = TaggerFactory.load(args.load, args.gpu)\n",
    "    # Create evaluator\n",
    "    evaluator = EvaluatorFactory.create(args)\n",
    "    # Create optimizer\n",
    "    optimizer, scheduler = OptimizerFactory.create(args, tagger)\n",
    "    # Prepare report and temporary variables for \"save best\" strategy\n",
    "    report = Report(args.report_fn, args, score_names=('train loss', '%s-train' % args.evaluator,\n",
    "                                                       '%s-dev' % args.evaluator, '%s-test' % args.evaluator))\n",
    "    # Initialize training variables\n",
    "    iterations_num = floor(datasets_bank.train_data_num / args.batch_size)\n",
    "    best_dev_score = -1\n",
    "    best_epoch = -1\n",
    "    best_test_score = -1\n",
    "    best_test_msg = 'N\\A'\n",
    "    patience_counter = 0\n",
    "    print('\\nStart training...\\n')\n",
    "    for epoch in range(0, args.epoch_num + 1):\n",
    "        time_start = time.time()\n",
    "        loss_sum = 0\n",
    "        if epoch > 0:\n",
    "            tagger.train()\n",
    "            if args.lr_decay > 0:\n",
    "                scheduler.step()\n",
    "            for i, (word_sequences_train_batch, tag_sequences_train_batch) in \\\n",
    "                    enumerate(datasets_bank.get_train_batches(args.batch_size)):\n",
    "                tagger.train()\n",
    "                tagger.zero_grad()\n",
    "                loss = tagger.get_loss(word_sequences_train_batch, tag_sequences_train_batch)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(tagger.parameters(), args.clip_grad)\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item()\n",
    "                if i % 1 == 0:\n",
    "                    print('\\r-- train epoch %d/%d, batch %d/%d (%1.2f%%), loss = %1.2f.' % (epoch, args.epoch_num,\n",
    "                                                                                         i + 1, iterations_num,\n",
    "                                                                                         ceil(i*100.0/iterations_num),\n",
    "                                                                                         loss_sum*100 / iterations_num),\n",
    "                                                                                         end='', flush=True)\n",
    "        # Evaluate tagger\n",
    "        train_score, dev_score, test_score, test_msg = evaluator.get_evaluation_score_train_dev_test(tagger,\n",
    "                                                                                                     datasets_bank,\n",
    "                                                                                                     batch_size=100)\n",
    "        print('\\n== eval epoch %d/%d \"%s\" train / dev / test | %1.2f / %1.2f / %1.2f.' % (epoch, args.epoch_num,\n",
    "                                                                                        args.evaluator, train_score,\n",
    "                                                                                        dev_score, test_score))\n",
    "        report.write_epoch_scores(epoch, (loss_sum*100 / iterations_num, train_score, dev_score, test_score))\n",
    "        # Early stopping\n",
    "        if dev_score > best_dev_score:\n",
    "            best_dev_score = dev_score\n",
    "            best_test_score = test_score\n",
    "            best_epoch = epoch\n",
    "            best_test_msg = test_msg\n",
    "            patience_counter = 0\n",
    "            if args.save is not None and args.save_best:\n",
    "                tagger.save_tagger(args.save)\n",
    "            print('## [BEST epoch], %d seconds.\\n' % (time.time() - time_start))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print('## [no improvement micro-f1 on DEV during the last %d epochs (best_f1_dev=%1.2f), %d seconds].\\n' %\n",
    "                                                                                            (patience_counter,\n",
    "                                                                                             best_dev_score,\n",
    "                                                                                             (time.time()-time_start)))\n",
    "        if patience_counter > args.patience and epoch > args.min_epoch_num:\n",
    "            break\n",
    "    # Save final trained tagger to disk, if it is not already saved according to \"save best\"\n",
    "    if args.save is not None and not args.save_best:\n",
    "        tagger.save_tagger(args.save)\n",
    "    # Show and save the final scores\n",
    "    if args.save_best:\n",
    "        report.write_final_score('Final eval on test, \"save best\", best epoch on dev %d, %s, test = %1.2f)' %\n",
    "                                 (best_epoch, args.evaluator, best_test_score))\n",
    "        report.write_msg(best_test_msg)\n",
    "        report.write_input_arguments()\n",
    "        report.write_final_line_score(best_test_score)\n",
    "    else:\n",
    "        report.write_final_score('Final eval on test, %s test = %1.2f)' % (args.evaluator, test_score))\n",
    "        report.write_msg(test_msg)\n",
    "        report.write_input_arguments()\n",
    "        report.write_final_line_score(test_score)\n",
    "    if args.verbose:\n",
    "        report.make_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42b91c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T02:08:45.413262Z",
     "iopub.status.busy": "2023-12-02T02:08:45.412967Z",
     "iopub.status.idle": "2023-12-02T02:54:52.579054Z",
     "shell.execute_reply": "2023-12-02T02:54:52.577979Z"
    },
    "papermill": {
     "duration": 2767.181817,
     "end_time": "2023-12-02T02:54:52.581203",
     "exception": false,
     "start_time": "2023-12-02T02:08:45.399386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d237a2e184454f9f800180cac9e19adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bbbbffb3af4442a83c3f3fb0497773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ncbi_disease/ncbi_disease (download: 1.47 MiB, generated: 3.04 MiB, post-processed: Unknown size, total: 4.52 MiB) to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321be4a6b2b54f98a19d210be0b1de33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d85fb136c654e52908110f64b1f98ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde610e2eee74903b9158d0adcc8ad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bebd05ad024d28bba302ca85c2f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec84e465d5ce420dadd1363669a91bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a652144bc1644108b3e35f3091a57bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba74234faf4e4623aebe95d34b457ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/924 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff647e20e85044b59e7a90c33f323c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ncbi_disease downloaded and prepared to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f186827c58642a19cda94b64d216dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from train: 5432 samples, 136086 words.\n",
      "Loading from validation: 923 samples, 23969 words.\n",
      "Loading from test: 940 samples, 24497 words.\n",
      "DatasetsBank: len(unique_words_list) = 9284 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 10056 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 10818 unique words.\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 0\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 100000\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 200000\n",
      "Reading embeddings file /kaggle/input/glove6b/glove.6B.200d.txt, line = 300000\n",
      "\n",
      "load_vocabulary_from_embeddings_file_and_unique_words_list:\n",
      "    First 50 OOV words:\n",
      "        out_of_vocabulary_words_list[0] = APC2\n",
      "        out_of_vocabulary_words_list[1] = 3beta\n",
      "        out_of_vocabulary_words_list[2] = axin\n",
      "        out_of_vocabulary_words_list[3] = conductin\n",
      "        out_of_vocabulary_words_list[4] = betacatenin\n",
      "        out_of_vocabulary_words_list[5] = 19p13\n",
      "        out_of_vocabulary_words_list[6] = MSH2\n",
      "        out_of_vocabulary_words_list[7] = nt943\n",
      "        out_of_vocabulary_words_list[8] = D2S288\n",
      "        out_of_vocabulary_words_list[9] = penetrances\n",
      "        out_of_vocabulary_words_list[10] = epsilon2epsilon3\n",
      "        out_of_vocabulary_words_list[11] = bacteremic\n",
      "        out_of_vocabulary_words_list[12] = gonococcal\n",
      "        out_of_vocabulary_words_list[13] = immunochemical\n",
      "        out_of_vocabulary_words_list[14] = Opsonization\n",
      "        out_of_vocabulary_words_list[15] = nonaffected\n",
      "        out_of_vocabulary_words_list[16] = dihydropyrimidine\n",
      "        out_of_vocabulary_words_list[17] = Dihydropyrimidine\n",
      "        out_of_vocabulary_words_list[18] = uraciluria\n",
      "        out_of_vocabulary_words_list[19] = 298delTCAT\n",
      "        out_of_vocabulary_words_list[20] = 1897delC\n",
      "        out_of_vocabulary_words_list[21] = IVS14\n",
      "        out_of_vocabulary_words_list[22] = 85T\n",
      "        out_of_vocabulary_words_list[23] = 703C\n",
      "        out_of_vocabulary_words_list[24] = 2658G\n",
      "        out_of_vocabulary_words_list[25] = 2983G\n",
      "        out_of_vocabulary_words_list[26] = FHF2\n",
      "        out_of_vocabulary_words_list[27] = Borjeson\n",
      "        out_of_vocabulary_words_list[28] = Forssman\n",
      "        out_of_vocabulary_words_list[29] = Xq26\n",
      "        out_of_vocabulary_words_list[30] = BFLS\n",
      "        out_of_vocabulary_words_list[31] = syndromal\n",
      "        out_of_vocabulary_words_list[32] = q26\n",
      "        out_of_vocabulary_words_list[33] = q26q28\n",
      "        out_of_vocabulary_words_list[34] = DXS155\n",
      "        out_of_vocabulary_words_list[35] = DXS294\n",
      "        out_of_vocabulary_words_list[36] = DXS730\n",
      "        out_of_vocabulary_words_list[37] = SSCP\n",
      "        out_of_vocabulary_words_list[38] = Drash\n",
      "        out_of_vocabulary_words_list[39] = nonneoplastic\n",
      "        out_of_vocabulary_words_list[40] = pseudohermaphroditism\n",
      "        out_of_vocabulary_words_list[41] = exonic\n",
      "        out_of_vocabulary_words_list[42] = tmT396\n",
      "        out_of_vocabulary_words_list[43] = ZF3\n",
      "        out_of_vocabulary_words_list[44] = nontargeted\n",
      "        out_of_vocabulary_words_list[45] = DMT1\n",
      "        out_of_vocabulary_words_list[46] = saturations\n",
      "        out_of_vocabulary_words_list[47] = quantitated\n",
      "        out_of_vocabulary_words_list[48] = Neurophysiologic\n",
      "        out_of_vocabulary_words_list[49] = axonopathy\n",
      "        out_of_vocabulary_words_list[50] = Lorenzos\n",
      " -- len(out_of_vocabulary_words_list) = 2179\n",
      " -- original_words_num = 6458\n",
      " -- lowercase_words_num = 2138\n",
      " -- zero_digits_replaced_num = 42\n",
      " -- zero_digits_replaced_lowercase_num = 1\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 3\n",
      " -- {'<pad>': 0, 0: 1, 1: 2, 2: 3}\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         0         1         2     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0\n",
      "         0       0.0  114616.0    2263.0    2859.0    5081.0\n",
      "         1       0.0    4780.0       1.0      13.0     351.0\n",
      "         2       0.0       0.0    2879.0    3243.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         0         1         2     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         0   -9999.0      -1.1      -1.0      -1.1      -1.1\n",
      "         1   -9999.0      -0.8      -1.1      -0.9      -1.1\n",
      "         2   -9999.0   -9999.0      -0.9      -1.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 32.33\n",
      "              1 = 7.36\n",
      "              2 = 8.72\n",
      "------------------------\n",
      "Macro-F1 = 16.138\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 32.27\n",
      "              1 = 6.59\n",
      "              2 = 9.17\n",
      "------------------------\n",
      "Macro-F1 = 16.010\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 32.97\n",
      "              1 = 7.91\n",
      "              2 = 8.83\n",
      "------------------------\n",
      "Macro-F1 = 16.567\n",
      "\n",
      "== eval epoch 0/10 \"f1-macro\" train / dev / test | 16.14 / 16.01 / 16.57.\n",
      "## [BEST epoch], 23 seconds.\n",
      "\n",
      "-- train epoch 1/10, batch 339/339 (100.00%), loss = 367.11.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.42\n",
      "              1 = 39.84\n",
      "              2 = 26.42\n",
      "------------------------\n",
      "Macro-F1 = 54.228\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.67\n",
      "              1 = 33.97\n",
      "              2 = 33.63\n",
      "------------------------\n",
      "Macro-F1 = 54.757\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.56\n",
      "              1 = 42.94\n",
      "              2 = 30.85\n",
      "------------------------\n",
      "Macro-F1 = 56.782\n",
      "\n",
      "== eval epoch 1/10 \"f1-macro\" train / dev / test | 54.23 / 54.76 / 56.78.\n",
      "## [BEST epoch], 253 seconds.\n",
      "\n",
      "-- train epoch 2/10, batch 339/339 (100.00%), loss = 181.17.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.75\n",
      "              1 = 54.54\n",
      "              2 = 52.11\n",
      "------------------------\n",
      "Macro-F1 = 67.803\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.34\n",
      "              1 = 51.36\n",
      "              2 = 61.93\n",
      "------------------------\n",
      "Macro-F1 = 70.208\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.81\n",
      "              1 = 53.50\n",
      "              2 = 52.27\n",
      "------------------------\n",
      "Macro-F1 = 67.525\n",
      "\n",
      "== eval epoch 2/10 \"f1-macro\" train / dev / test | 67.80 / 70.21 / 67.53.\n",
      "## [BEST epoch], 245 seconds.\n",
      "\n",
      "-- train epoch 3/10, batch 339/339 (100.00%), loss = 157.67.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.32\n",
      "              1 = 58.10\n",
      "              2 = 59.48\n",
      "------------------------\n",
      "Macro-F1 = 71.632\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.54\n",
      "              1 = 49.18\n",
      "              2 = 64.00\n",
      "------------------------\n",
      "Macro-F1 = 70.240\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.18\n",
      "              1 = 54.82\n",
      "              2 = 58.19\n",
      "------------------------\n",
      "Macro-F1 = 70.062\n",
      "\n",
      "== eval epoch 3/10 \"f1-macro\" train / dev / test | 71.63 / 70.24 / 70.06.\n",
      "## [BEST epoch], 252 seconds.\n",
      "\n",
      "-- train epoch 4/10, batch 339/339 (100.00%), loss = 141.06.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.24\n",
      "              1 = 61.35\n",
      "              2 = 57.84\n",
      "------------------------\n",
      "Macro-F1 = 72.146\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.50\n",
      "              1 = 51.69\n",
      "              2 = 59.91\n",
      "------------------------\n",
      "Macro-F1 = 69.701\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.98\n",
      "              1 = 55.91\n",
      "              2 = 53.72\n",
      "------------------------\n",
      "Macro-F1 = 68.871\n",
      "\n",
      "== eval epoch 4/10 \"f1-macro\" train / dev / test | 72.15 / 69.70 / 68.87.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=70.24), 265 seconds].\n",
      "\n",
      "-- train epoch 5/10, batch 339/339 (100.00%), loss = 119.87.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.51\n",
      "              1 = 67.71\n",
      "              2 = 64.18\n",
      "------------------------\n",
      "Macro-F1 = 76.467\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.98\n",
      "              1 = 62.94\n",
      "              2 = 69.63\n",
      "------------------------\n",
      "Macro-F1 = 76.851\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.62\n",
      "              1 = 65.49\n",
      "              2 = 66.43\n",
      "------------------------\n",
      "Macro-F1 = 76.515\n",
      "\n",
      "== eval epoch 5/10 \"f1-macro\" train / dev / test | 76.47 / 76.85 / 76.51.\n",
      "## [BEST epoch], 279 seconds.\n",
      "\n",
      "-- train epoch 6/10, batch 339/339 (100.00%), loss = 106.16.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.27\n",
      "              1 = 65.22\n",
      "              2 = 60.92\n",
      "------------------------\n",
      "Macro-F1 = 74.467\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.07\n",
      "              1 = 53.88\n",
      "              2 = 58.11\n",
      "------------------------\n",
      "Macro-F1 = 69.686\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.12\n",
      "              1 = 59.76\n",
      "              2 = 57.52\n",
      "------------------------\n",
      "Macro-F1 = 71.466\n",
      "\n",
      "== eval epoch 6/10 \"f1-macro\" train / dev / test | 74.47 / 69.69 / 71.47.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.85), 256 seconds].\n",
      "\n",
      "-- train epoch 7/10, batch 339/339 (100.00%), loss = 138.08.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.06\n",
      "              1 = 66.42\n",
      "              2 = 59.09\n",
      "------------------------\n",
      "Macro-F1 = 74.189\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.65\n",
      "              1 = 62.17\n",
      "              2 = 66.40\n",
      "------------------------\n",
      "Macro-F1 = 75.403\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 96.44\n",
      "              1 = 60.93\n",
      "              2 = 51.59\n",
      "------------------------\n",
      "Macro-F1 = 69.655\n",
      "\n",
      "== eval epoch 7/10 \"f1-macro\" train / dev / test | 74.19 / 75.40 / 69.65.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=76.85), 291 seconds].\n",
      "\n",
      "-- train epoch 8/10, batch 339/339 (100.00%), loss = 129.59.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.00\n",
      "              1 = 72.01\n",
      "              2 = 66.78\n",
      "------------------------\n",
      "Macro-F1 = 78.930\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.12\n",
      "              1 = 62.52\n",
      "              2 = 68.31\n",
      "------------------------\n",
      "Macro-F1 = 76.315\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.77\n",
      "              1 = 66.26\n",
      "              2 = 62.25\n",
      "------------------------\n",
      "Macro-F1 = 75.426\n",
      "\n",
      "== eval epoch 8/10 \"f1-macro\" train / dev / test | 78.93 / 76.32 / 75.43.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=76.85), 254 seconds].\n",
      "\n",
      "-- train epoch 9/10, batch 339/339 (100.00%), loss = 113.22.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.37\n",
      "              1 = 66.69\n",
      "              2 = 64.44\n",
      "------------------------\n",
      "Macro-F1 = 76.167\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.72\n",
      "              1 = 64.28\n",
      "              2 = 69.18\n",
      "------------------------\n",
      "Macro-F1 = 77.056\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.35\n",
      "              1 = 65.65\n",
      "              2 = 64.78\n",
      "------------------------\n",
      "Macro-F1 = 75.927\n",
      "\n",
      "== eval epoch 9/10 \"f1-macro\" train / dev / test | 76.17 / 77.06 / 75.93.\n",
      "## [BEST epoch], 258 seconds.\n",
      "\n",
      "-- train epoch 10/10, batch 339/339 (100.00%), loss = 123.10.\n",
      "\n",
      "++ predicting, batch 54/54 (99.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.97\n",
      "              1 = 69.02\n",
      "              2 = 65.84\n",
      "------------------------\n",
      "Macro-F1 = 77.612\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 98.19\n",
      "              1 = 62.91\n",
      "              2 = 68.44\n",
      "------------------------\n",
      "Macro-F1 = 76.516\n",
      "\n",
      "\n",
      "++ predicting, batch 9/9 (89.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.67\n",
      "              1 = 62.48\n",
      "              2 = 58.76\n",
      "------------------------\n",
      "Macro-F1 = 72.969\n",
      "\n",
      "== eval epoch 10/10 \"f1-macro\" train / dev / test | 77.61 / 76.52 / 72.97.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=77.06), 265 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "<__main__.ARGS object at 0x78838799e0e0>\n",
      "\n",
      "         epoch  |     train loss | f1-macro-train |   f1-macro-dev |  f1-macro-test \n",
      "--------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |          16.14 |          16.01 |          16.57 \n",
      "              1 |         367.11 |          54.23 |          54.76 |          56.78 \n",
      "              2 |         181.17 |          67.80 |          70.21 |          67.53 \n",
      "              3 |         157.67 |          71.63 |          70.24 |          70.06 \n",
      "              4 |         141.06 |          72.15 |          69.70 |          68.87 \n",
      "              5 |         119.87 |          76.47 |          76.85 |          76.51 \n",
      "              6 |         106.16 |          74.47 |          69.69 |          71.47 \n",
      "              7 |         138.08 |          74.19 |          75.40 |          69.65 \n",
      "              8 |         129.59 |          78.93 |          76.32 |          75.43 \n",
      "              9 |         113.22 |          76.17 |          77.06 |          75.93 \n",
      "             10 |         123.10 |          77.61 |          76.52 |          72.97 \n",
      "--------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 9, f1-macro, test = 75.93)\n",
      "--------------------------------------------------------------------------------------\n",
      "F1 scores\n",
      "------------------------\n",
      "              0 = 97.35\n",
      "              1 = 65.65\n",
      "              2 = 64.78\n",
      "------------------------\n",
      "Macro-F1 = 75.927\n",
      "Input arguments:\n",
      "python3 main.py -f /tmp/tmpyo_mxky3.json --HistoryManager.hist_file=:memory:\n",
      "\n",
      "75.9273\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 32801,
     "sourceId": 42887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2778.760236,
   "end_time": "2023-12-02T02:54:54.368197",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T02:08:35.607961",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "027f01defd54496dbb1f6a8d59cb0927": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "032a0e637d954172a1921ea614ba3d6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90d799b31b5b4418aee9b8b963845b19",
       "placeholder": "",
       "style": "IPY_MODEL_c8abd306a80947678298c33e1a3d5b30",
       "value": " 5.83k/? [00:00&lt;00:00, 427kB/s]"
      }
     },
     "04c8dbc60ab04e8b8abefffcb80331ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06012072129c44729fb25fae7b0cba48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07e0e92255ac49939d41a17c22659723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0854e9817dc64468ba47846119381521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "09a97e0d591c4fe19b841f5f98bd6f99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_869a5162c8cd4b0391541431b3f43c82",
       "placeholder": "",
       "style": "IPY_MODEL_a82d9ffe83944f50b78fd34eb90341e5",
       "value": "Downloading metadata: "
      }
     },
     "0aedd21b358243abbfda76b5d847caa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c94fc3847e2f43f5a58f1393d12a35df",
       "placeholder": "",
       "style": "IPY_MODEL_612feb5b4dcf4fce9b9d9f209562e0d1",
       "value": " 3/3 [00:01&lt;00:00,  1.59it/s]"
      }
     },
     "0c34ce4a18424ef5bdc9db504c99b61d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0ccc8ed480bf49b082b6d7dfd95a8e10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "0d9190ea6f5d438ea8ab00462091379c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e10cfa6f8e44b74912a91738d802b67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f186827c58642a19cda94b64d216dad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67b473e52f094bf58364c55410281452",
        "IPY_MODEL_dc604a77c1ae4619960d364ae8ae5090",
        "IPY_MODEL_90d4b82b8cc246a28439b4b54dea79e2"
       ],
       "layout": "IPY_MODEL_07e0e92255ac49939d41a17c22659723"
      }
     },
     "117503f48a9a4fe8a80886587d80acdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1665d9e19c84404fa72b554867557889": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8268cca1a8541db876e9fce2811a285",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6a05c336cee8456481555d7042fc494a",
       "value": 3.0
      }
     },
     "17256ca1104247b1980baa44da8d0b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_04c8dbc60ab04e8b8abefffcb80331ad",
       "max": 941.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d4cb49cf73d4a35b45f97e2f628e0ac",
       "value": 941.0
      }
     },
     "190d542f9aa14f88b9e6a2f071441ce3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b6a41a575d7e4b43952caada02f7fd97",
       "placeholder": "",
       "style": "IPY_MODEL_0854e9817dc64468ba47846119381521",
       "value": " 200k/? [00:00&lt;00:00, 12.8MB/s]"
      }
     },
     "1d4cb49cf73d4a35b45f97e2f628e0ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "22587eb84ada4e159173dc7418d43a1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2270957141c2499eb4647863763e397d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_38f92bf58bbd4d14ba37eb2fedf0823f",
       "placeholder": "",
       "style": "IPY_MODEL_7f40bf21dd6b40e99c933285e9902c18",
       "value": "Downloading data: "
      }
     },
     "25f1c37b800f4413a33eee15c2bce4b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28d25a619be04710b59bea9b521408f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2b2bbd0d0c38424fa1e3cea0a3212fcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fee1b9b69ba41c5b0391b1a36617733",
       "placeholder": "",
       "style": "IPY_MODEL_69624ea21a2946a4995842f61457b3b1",
       "value": " 206k/? [00:00&lt;00:00, 11.7MB/s]"
      }
     },
     "2ceb184492fe473cbf09cd587b722c10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a7ad70d5d8704839be057b3846f07fe1",
       "max": 283883.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9760f3faedbc43ea8654bf78558b3948",
       "value": 283883.0
      }
     },
     "2d5799a4fd224265b8b90d8f75478330": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "321be4a6b2b54f98a19d210be0b1de33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9c632b2acfa846fd92a16f8046fc334a",
        "IPY_MODEL_4f4e834db5e84263b12f38a65f397c58",
        "IPY_MODEL_0aedd21b358243abbfda76b5d847caa3"
       ],
       "layout": "IPY_MODEL_bc2866d8f8574ef387f21fb26cd6d942"
      }
     },
     "32e922801da441b38b51fb98136ee16d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b054533a11fd4cc787c094653bc8d2c7",
       "max": 1549.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0c34ce4a18424ef5bdc9db504c99b61d",
       "value": 1549.0
      }
     },
     "38f92bf58bbd4d14ba37eb2fedf0823f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a9f021a415a4d9082475665eceba12f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9c97f3cee5b4172b805bf2ef3b8eb35",
       "max": 2279.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b0512c71d53540438df22ce8006fab28",
       "value": 2279.0
      }
     },
     "3b34ef8e1fe9434293c3b9e072f30047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_027f01defd54496dbb1f6a8d59cb0927",
       "placeholder": "",
       "style": "IPY_MODEL_a65215d6d1b64390acb3437a169adbcd",
       "value": "Downloading builder script: "
      }
     },
     "3d85fb136c654e52908110f64b1f98ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2270957141c2499eb4647863763e397d",
        "IPY_MODEL_2ceb184492fe473cbf09cd587b722c10",
        "IPY_MODEL_5d55bb42c1554037a53a569640c882e4"
       ],
       "layout": "IPY_MODEL_117503f48a9a4fe8a80886587d80acdc"
      }
     },
     "43d53ab52e70435fa64e7de4fb4a0f4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "47d5f6d5242e45328641e9f6e91b661c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a69b85ec5984bf99202876f00830403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c674c67efa94284ab02787dd77a1c29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f4e834db5e84263b12f38a65f397c58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22587eb84ada4e159173dc7418d43a1f",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_47d5f6d5242e45328641e9f6e91b661c",
       "value": 3.0
      }
     },
     "4fee1b9b69ba41c5b0391b1a36617733": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50bc82c5b23f447e905a66b45467b30a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51bbbbffb3af4442a83c3f3fb0497773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_09a97e0d591c4fe19b841f5f98bd6f99",
        "IPY_MODEL_32e922801da441b38b51fb98136ee16d",
        "IPY_MODEL_c954876ca10d4f218f0de096d12f5313"
       ],
       "layout": "IPY_MODEL_0d9190ea6f5d438ea8ab00462091379c"
      }
     },
     "5d55bb42c1554037a53a569640c882e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_753e954e0cf94807b700024b8d36e04f",
       "placeholder": "",
       "style": "IPY_MODEL_28d25a619be04710b59bea9b521408f3",
       "value": " 1.14M/? [00:00&lt;00:00, 25.7MB/s]"
      }
     },
     "612feb5b4dcf4fce9b9d9f209562e0d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "61573e04b9c042b0aa142f69e6aa4f72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67b473e52f094bf58364c55410281452": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73241fa69f344ec3baa75892e54c5c84",
       "placeholder": "",
       "style": "IPY_MODEL_f0b159368f744054a852cbeadf2ce97a",
       "value": "100%"
      }
     },
     "68b5bf5e8ba1444a97b2e963db7f1190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e950f487d27b4b4dba96e967af0468a4",
       "placeholder": "",
       "style": "IPY_MODEL_6cab4ac18bd64d06b0fe7db6f17551ed",
       "value": " 5321/5433 [00:01&lt;00:00, 4563.32 examples/s]"
      }
     },
     "69624ea21a2946a4995842f61457b3b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6a05c336cee8456481555d7042fc494a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6ac7f6a410cd4e36875f8b88685cf28c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_faa83f8b4a814d3eb7246dd64abb9683",
       "placeholder": "",
       "style": "IPY_MODEL_7891f8f7e4af4fb3bac12ebc1fa48735",
       "value": " 3/3 [00:00&lt;00:00, 195.13it/s]"
      }
     },
     "6b385ecddc4942e0a939e997db4ea1a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa65ef828e9c486a8830724116e061e9",
       "placeholder": "",
       "style": "IPY_MODEL_61573e04b9c042b0aa142f69e6aa4f72",
       "value": " 847/941 [00:00&lt;00:00, 4269.20 examples/s]"
      }
     },
     "6cab4ac18bd64d06b0fe7db6f17551ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6ccd758c2b9b49a9bcf36b82d3662936": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6e3158753da04cd585f9103348760f30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "727c17ad085b47d3808911a9395786e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7aa65da4443141569196bc1ea8e37555",
       "placeholder": "",
       "style": "IPY_MODEL_c257c05dd6b64332833c727ff0d01f1c",
       "value": "Downloading data: "
      }
     },
     "73241fa69f344ec3baa75892e54c5c84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "753e954e0cf94807b700024b8d36e04f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7891f8f7e4af4fb3bac12ebc1fa48735": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "79a21de2681747a8978e4ad823f021db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "79c88ef0a5234022b7d009f9c6e8c9b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7aa65da4443141569196bc1ea8e37555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f40bf21dd6b40e99c933285e9902c18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7f6e717f4503421d8399e8ce668de3a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_abc82880ecc54e80a623fc2f404c7cfd",
       "max": 51200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d00c3415019746689970461d6182a94a",
       "value": 51200.0
      }
     },
     "8132b37923b345e6bb414685f0cb5dbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c674c67efa94284ab02787dd77a1c29",
       "max": 924.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb0a619315564455b190b0a02e3a5a25",
       "value": 924.0
      }
     },
     "84472c705fd4475f821e4cf755d3e2e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ba30e0fed2434516b30b768efe079bac",
       "placeholder": "",
       "style": "IPY_MODEL_79a21de2681747a8978e4ad823f021db",
       "value": "Downloading data: "
      }
     },
     "865821054dba4e768f76b4f8974268b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0e10cfa6f8e44b74912a91738d802b67",
       "max": 52411.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ccd758c2b9b49a9bcf36b82d3662936",
       "value": 52411.0
      }
     },
     "869a5162c8cd4b0391541431b3f43c82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bc740efa46743bab17d4d6f635a1d02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_06012072129c44729fb25fae7b0cba48",
       "max": 5433.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a7fc223ddf8a40b7a06e447a765b074c",
       "value": 5433.0
      }
     },
     "90d4b82b8cc246a28439b4b54dea79e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d84a81aad8d1404da2a7feb43d7c34e2",
       "placeholder": "",
       "style": "IPY_MODEL_a881f2a4d36d4d87b5786ec4a9198165",
       "value": " 3/3 [00:00&lt;00:00, 147.57it/s]"
      }
     },
     "90d799b31b5b4418aee9b8b963845b19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9117f7f2d91b48bf93eb7f6f5dbde028": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "968fc9edd2ab4a3aabee518dbd459baf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9760f3faedbc43ea8654bf78558b3948": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "98684324fa414412815be7284d054963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c632b2acfa846fd92a16f8046fc334a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e3158753da04cd585f9103348760f30",
       "placeholder": "",
       "style": "IPY_MODEL_43d53ab52e70435fa64e7de4fb4a0f4e",
       "value": "Downloading data files: 100%"
      }
     },
     "9de39dae09ab4d2199f45be60d45a1f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0e6327f13914a49ac95007e702796b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "a2497cdf880942078ce60f4cc93eb346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4186c90d34748e095b282789319352a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a478baa763d54ecaa85b59a9907cf700": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a652144bc1644108b3e35f3091a57bf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aa1402e2c4514280905c9b89c345b2a2",
        "IPY_MODEL_8bc740efa46743bab17d4d6f635a1d02",
        "IPY_MODEL_68b5bf5e8ba1444a97b2e963db7f1190"
       ],
       "layout": "IPY_MODEL_a0e6327f13914a49ac95007e702796b2"
      }
     },
     "a65215d6d1b64390acb3437a169adbcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a7ad70d5d8704839be057b3846f07fe1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7fc223ddf8a40b7a06e447a765b074c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a82d9ffe83944f50b78fd34eb90341e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a881f2a4d36d4d87b5786ec4a9198165": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aa1402e2c4514280905c9b89c345b2a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50bc82c5b23f447e905a66b45467b30a",
       "placeholder": "",
       "style": "IPY_MODEL_4a69b85ec5984bf99202876f00830403",
       "value": "Generating train split:  98%"
      }
     },
     "abc82880ecc54e80a623fc2f404c7cfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afe0cab19b1544b497c40ee91dc0ca63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "b0512c71d53540438df22ce8006fab28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b054533a11fd4cc787c094653bc8d2c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b619518190354116ac29ad4c2fb93152": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6a41a575d7e4b43952caada02f7fd97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba30e0fed2434516b30b768efe079bac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba74234faf4e4623aebe95d34b457ab1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cd2ca633543a49b6915bb6349626c4ec",
        "IPY_MODEL_8132b37923b345e6bb414685f0cb5dbd",
        "IPY_MODEL_c64a2a6cdc6d4dab9bc03654ab264461"
       ],
       "layout": "IPY_MODEL_0ccc8ed480bf49b082b6d7dfd95a8e10"
      }
     },
     "bc2866d8f8574ef387f21fb26cd6d942": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c257c05dd6b64332833c727ff0d01f1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c41a893d8e3d4762b04a36adf970522e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c64a2a6cdc6d4dab9bc03654ab264461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_98684324fa414412815be7284d054963",
       "placeholder": "",
       "style": "IPY_MODEL_c41a893d8e3d4762b04a36adf970522e",
       "value": " 754/924 [00:00&lt;00:00, 3793.23 examples/s]"
      }
     },
     "c7bb8e842bc140fea216ba0e34ee30e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8abd306a80947678298c33e1a3d5b30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c94fc3847e2f43f5a58f1393d12a35df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c954876ca10d4f218f0de096d12f5313": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b619518190354116ac29ad4c2fb93152",
       "placeholder": "",
       "style": "IPY_MODEL_a4186c90d34748e095b282789319352a",
       "value": " 3.45k/? [00:00&lt;00:00, 278kB/s]"
      }
     },
     "c9c97f3cee5b4172b805bf2ef3b8eb35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb0a619315564455b190b0a02e3a5a25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cd2ca633543a49b6915bb6349626c4ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a478baa763d54ecaa85b59a9907cf700",
       "placeholder": "",
       "style": "IPY_MODEL_9117f7f2d91b48bf93eb7f6f5dbde028",
       "value": "Generating validation split:  82%"
      }
     },
     "cd5de6cb20d94257bab464b3d7ce6734": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2497cdf880942078ce60f4cc93eb346",
       "placeholder": "",
       "style": "IPY_MODEL_c7bb8e842bc140fea216ba0e34ee30e2",
       "value": "Extracting data files: 100%"
      }
     },
     "cfe4d6797c554ecdbaab47431a19309e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d00c3415019746689970461d6182a94a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d237a2e184454f9f800180cac9e19adf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3b34ef8e1fe9434293c3b9e072f30047",
        "IPY_MODEL_3a9f021a415a4d9082475665eceba12f",
        "IPY_MODEL_032a0e637d954172a1921ea614ba3d6d"
       ],
       "layout": "IPY_MODEL_e3b6c14562624a60bf226c51b8e20d9a"
      }
     },
     "d3ecfc2adc6c41eba1e0bd79585c1fdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9de39dae09ab4d2199f45be60d45a1f7",
       "placeholder": "",
       "style": "IPY_MODEL_f70553958307477189877a073550d752",
       "value": "Generating test split:  90%"
      }
     },
     "d84a81aad8d1404da2a7feb43d7c34e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc604a77c1ae4619960d364ae8ae5090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_79c88ef0a5234022b7d009f9c6e8c9b9",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_968fc9edd2ab4a3aabee518dbd459baf",
       "value": 3.0
      }
     },
     "e3b6c14562624a60bf226c51b8e20d9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e950f487d27b4b4dba96e967af0468a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec84e465d5ce420dadd1363669a91bbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cd5de6cb20d94257bab464b3d7ce6734",
        "IPY_MODEL_1665d9e19c84404fa72b554867557889",
        "IPY_MODEL_6ac7f6a410cd4e36875f8b88685cf28c"
       ],
       "layout": "IPY_MODEL_cfe4d6797c554ecdbaab47431a19309e"
      }
     },
     "f0b159368f744054a852cbeadf2ce97a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f6bebd05ad024d28bba302ca85c2f6a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_727c17ad085b47d3808911a9395786e1",
        "IPY_MODEL_865821054dba4e768f76b4f8974268b5",
        "IPY_MODEL_2b2bbd0d0c38424fa1e3cea0a3212fcf"
       ],
       "layout": "IPY_MODEL_2d5799a4fd224265b8b90d8f75478330"
      }
     },
     "f70553958307477189877a073550d752": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f8268cca1a8541db876e9fce2811a285": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa65ef828e9c486a8830724116e061e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "faa83f8b4a814d3eb7246dd64abb9683": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fde610e2eee74903b9158d0adcc8ad4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_84472c705fd4475f821e4cf755d3e2e4",
        "IPY_MODEL_7f6e717f4503421d8399e8ce668de3a6",
        "IPY_MODEL_190d542f9aa14f88b9e6a2f071441ce3"
       ],
       "layout": "IPY_MODEL_25f1c37b800f4413a33eee15c2bce4b2"
      }
     },
     "ff647e20e85044b59e7a90c33f323c08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3ecfc2adc6c41eba1e0bd79585c1fdf",
        "IPY_MODEL_17256ca1104247b1980baa44da8d0b86",
        "IPY_MODEL_6b385ecddc4942e0a939e997db4ea1a7"
       ],
       "layout": "IPY_MODEL_afe0cab19b1544b497c40ee91dc0ca63"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
